pre loading model
WAKE SLEEP ITERATION 0
generator epoch 0 loss: 3.412496578543527                 accuracy: 0.2964285612106323
generator epoch 1 loss: 3.025302268763951                 accuracy: 0.38285714387893677
generator epoch 2 loss: 2.7267375244140624                 accuracy: 0.3499999940395355
generator epoch 3 loss: 2.6861409214564733                 accuracy: 0.3992857038974762
generator epoch 4 loss: 2.6528992780412946                 accuracy: 0.39499998092651367
generator epoch 5 loss: 2.621532092285156                 accuracy: 0.4350000023841858
generator epoch 6 loss: 2.591502157156808                 accuracy: 0.4164285659790039
generator epoch 7 loss: 2.5584418910435267                 accuracy: 0.44857141375541687
generator epoch 8 loss: 2.520771236746652                 accuracy: 0.4357142746448517
generator epoch 9 loss: 2.489882050432478                 accuracy: 0.47428572177886963
generator epoch 10 loss: 2.463954609026228                 accuracy: 0.459285706281662
generator epoch 11 loss: 2.4404362758091516                 accuracy: 0.4721428453922272
generator epoch 12 loss: 2.422791711425781                 accuracy: 0.4749999940395355
generator epoch 13 loss: 2.4058772007533484                 accuracy: 0.4835714101791382
generator epoch 14 loss: 2.3924781406947546                 accuracy: 0.4771428406238556
generator epoch 15 loss: 2.370784369768415                 accuracy: 0.48499998450279236
generator epoch 16 loss: 2.3553871599469867                 accuracy: 0.47785714268684387
generator epoch 17 loss: 2.3392268851143974                 accuracy: 0.5021428465843201
generator epoch 18 loss: 2.3189125331333704                 accuracy: 0.49071428179740906
generator epoch 19 loss: 2.3008897530691965                 accuracy: 0.5342857241630554
generator epoch 20 loss: 2.285648840332031                 accuracy: 0.5421428680419922
generator epoch 21 loss: 2.274052383858817                 accuracy: 0.5185714364051819
generator epoch 22 loss: 2.263178431919643                 accuracy: 0.5621428489685059
generator epoch 23 loss: 2.2456175589425222                 accuracy: 0.5514285564422607
generator epoch 24 loss: 2.2352143886021207                 accuracy: 0.5464285612106323
generator epoch 25 loss: 2.221107076590402                 accuracy: 0.5378571152687073
generator epoch 26 loss: 2.21090341796875                 accuracy: 0.5514285564422607
generator epoch 27 loss: 2.199395431082589                 accuracy: 0.5878571271896362
generator epoch 28 loss: 2.185166598074777                 accuracy: 0.5592857003211975
generator epoch 29 loss: 2.1765125191824777                 accuracy: 0.5849999785423279
generator epoch 30 loss: 2.1704108694893973                 accuracy: 0.5878571271896362
generator epoch 31 loss: 2.158667098563058                 accuracy: 0.5649999976158142
generator epoch 32 loss: 2.152248078264509                 accuracy: 0.5628571510314941
generator epoch 33 loss: 2.139484699358259                 accuracy: 0.5550000071525574
generator epoch 34 loss: 2.131067403738839                 accuracy: 0.574999988079071
generator epoch 35 loss: 2.122615253557478                 accuracy: 0.5657142996788025
generator epoch 36 loss: 2.1147598039899553                 accuracy: 0.5764285922050476
generator epoch 37 loss: 2.102318341936384                 accuracy: 0.5764285922050476
generator epoch 38 loss: 2.0989798496791297                 accuracy: 0.5785714387893677
generator epoch 39 loss: 2.0905908185686384                 accuracy: 0.5971428751945496
generator epoch 40 loss: 2.086078576660156                 accuracy: 0.5864285826683044
generator epoch 41 loss: 2.077874529157366                 accuracy: 0.6071428656578064
generator epoch 42 loss: 2.063940171595982                 accuracy: 0.5892857313156128
generator epoch 43 loss: 2.0564756051199775                 accuracy: 0.5978571176528931
generator epoch 44 loss: 2.0486935128348214                 accuracy: 0.6092857122421265
generator epoch 45 loss: 2.0453317975725445                 accuracy: 0.6671428680419922
generator epoch 46 loss: 2.0381191859654018                 accuracy: 0.6050000190734863
generator epoch 47 loss: 2.029454868861607                 accuracy: 0.6150000095367432
generator epoch 48 loss: 2.0172029401506695                 accuracy: 0.6464285850524902
generator epoch 49 loss: 2.0186208984375                 accuracy: 0.6007142663002014
generator epoch 50 loss: 2.0086562186104913                 accuracy: 0.5828571319580078
generator epoch 51 loss: 2.0029561087472096                 accuracy: 0.5964285731315613
generator epoch 52 loss: 1.997856516810826                 accuracy: 0.6235713958740234
generator epoch 53 loss: 1.989497966657366                 accuracy: 0.6028571128845215
generator epoch 54 loss: 1.9827209664481027                 accuracy: 0.6371428370475769
generator epoch 55 loss: 1.9796791085379464                 accuracy: 0.6442856788635254
generator epoch 56 loss: 1.9742738124302455                 accuracy: 0.6114285588264465
generator epoch 57 loss: 1.9696117710658483                 accuracy: 0.5964285731315613
generator epoch 58 loss: 1.9602447126116072                 accuracy: 0.5992857217788696
generator epoch 59 loss: 1.9564867571149553                 accuracy: 0.6471428275108337
generator epoch 60 loss: 1.9494250959123884                 accuracy: 0.6271428465843201
generator epoch 61 loss: 1.9458175537109375                 accuracy: 0.6507142782211304
generator epoch 62 loss: 1.937609312220982                 accuracy: 0.6521428227424622
generator epoch 63 loss: 1.9351003731863838                 accuracy: 0.6449999809265137
generator epoch 64 loss: 1.931787770298549                 accuracy: 0.6100000143051147
generator epoch 65 loss: 1.9212681605747768                 accuracy: 0.6321428418159485
generator epoch 66 loss: 1.9168679949079241                 accuracy: 0.639285683631897
generator epoch 67 loss: 1.9167910923549107                 accuracy: 0.6464285850524902
generator epoch 68 loss: 1.9081291469029018                 accuracy: 0.6514285802841187
generator epoch 69 loss: 1.9048802315848214                 accuracy: 0.6507142782211304
generator epoch 70 loss: 1.8990988542829241                 accuracy: 0.633571445941925
generator epoch 71 loss: 1.889066871861049                 accuracy: 0.6642857193946838
generator epoch 72 loss: 1.8875121721540178                 accuracy: 0.6449999809265137
generator epoch 73 loss: 1.8818821393694196                 accuracy: 0.647857129573822
generator epoch 74 loss: 1.8773680873325893                 accuracy: 0.6449999809265137
generator epoch 75 loss: 1.8664469796316965                 accuracy: 0.6535714268684387
generator epoch 76 loss: 1.8669246146065848                 accuracy: 0.6578571200370789
generator epoch 77 loss: 1.8632649919782367                 accuracy: 0.647857129573822
generator epoch 78 loss: 1.8597485735212054                 accuracy: 0.6607142686843872
generator epoch 79 loss: 1.8542235595703125                 accuracy: 0.6800000071525574
generator epoch 80 loss: 1.8494970720563617                 accuracy: 0.6328571438789368
generator epoch 81 loss: 1.8448996948242187                 accuracy: 0.6778571605682373
generator epoch 82 loss: 1.8383770961216517                 accuracy: 0.6835713982582092
generator epoch 83 loss: 1.8349658987862723                 accuracy: 0.6314285397529602
generator epoch 84 loss: 1.8296341918945314                 accuracy: 0.668571412563324
generator epoch 85 loss: 1.8229033970424107                 accuracy: 0.6871428489685059
generator epoch 86 loss: 1.8173568411690848                 accuracy: 0.6714285612106323
generator epoch 87 loss: 1.8164231340680803                 accuracy: 0.6800000071525574
generator epoch 88 loss: 1.8116893432617187                 accuracy: 0.6592857241630554
generator epoch 89 loss: 1.805952415248326                 accuracy: 0.6821428537368774
generator epoch 90 loss: 1.8026694370814733                 accuracy: 0.6650000214576721
generator epoch 91 loss: 1.7961967232840401                 accuracy: 0.6928571462631226
generator epoch 92 loss: 1.7921234322684152                 accuracy: 0.6671428680419922
generator epoch 93 loss: 1.7913267054966517                 accuracy: 0.6764285564422607
generator epoch 94 loss: 1.7855890520368303                 accuracy: 0.670714259147644
generator epoch 95 loss: 1.7745322893415179                 accuracy: 0.6971428394317627
generator epoch 96 loss: 1.7800488298688617                 accuracy: 0.6721428632736206
generator epoch 97 loss: 1.7683545218331473                 accuracy: 0.6592857241630554
generator epoch 98 loss: 1.7707648629324777                 accuracy: 0.699999988079071
generator epoch 99 loss: 1.76786771937779                 accuracy: 0.6871428489685059
generator epoch 100 loss: 1.7607065604073662                 accuracy: 0.7042856812477112
generator epoch 101 loss: 1.7551025983537947                 accuracy: 0.6928571462631226
generator epoch 102 loss: 1.7533690883091517                 accuracy: 0.6964285373687744
generator epoch 103 loss: 1.7463868512834821                 accuracy: 0.720714271068573
generator epoch 104 loss: 1.7390439400809152                 accuracy: 0.6957142949104309
generator epoch 105 loss: 1.7362890991210937                 accuracy: 0.7057142853736877
generator epoch 106 loss: 1.7376463745117188                 accuracy: 0.6992856860160828
generator epoch 107 loss: 1.7314042776925223                 accuracy: 0.727142870426178
generator epoch 108 loss: 1.7245177629743305                 accuracy: 0.6778571605682373
generator epoch 109 loss: 1.7283701607840403                 accuracy: 0.6935714483261108
generator epoch 110 loss: 1.7158820382254465                 accuracy: 0.7171428203582764
generator epoch 111 loss: 1.7152460065569197                 accuracy: 0.7107142806053162
generator epoch 112 loss: 1.7081390049525669                 accuracy: 0.7314285635948181
generator epoch 113 loss: 1.7087144199916295                 accuracy: 0.7228571176528931
generator epoch 114 loss: 1.7053689906529017                 accuracy: 0.7335714101791382
generator epoch 115 loss: 1.7007694562639508                 accuracy: 0.7164285778999329
generator epoch 116 loss: 1.696230135672433                 accuracy: 0.7049999833106995
generator epoch 117 loss: 1.6922693690708706                 accuracy: 0.7242857217788696
generator epoch 118 loss: 1.6892164341517857                 accuracy: 0.7028571367263794
generator epoch 119 loss: 1.6830534859793527                 accuracy: 0.7385714054107666
generator epoch 120 loss: 1.682781485421317                 accuracy: 0.7507143020629883
generator epoch 121 loss: 1.6799444859095982                 accuracy: 0.727142870426178
generator epoch 122 loss: 1.6765205758231028                 accuracy: 0.6892856955528259
generator epoch 123 loss: 1.6752410208565849                 accuracy: 0.7392857074737549
generator epoch 124 loss: 1.676543816266741                 accuracy: 0.7157142758369446
generator epoch 125 loss: 1.663102565220424                 accuracy: 0.741428554058075
generator epoch 126 loss: 1.663287339564732                 accuracy: 0.7185714244842529
generator epoch 127 loss: 1.6623490129743304                 accuracy: 0.6971428394317627
generator epoch 128 loss: 1.6527598388671876                 accuracy: 0.7328571081161499
generator epoch 129 loss: 1.6538169764927455                 accuracy: 0.7428571581840515
generator epoch 130 loss: 1.6494077200753348                 accuracy: 0.7635714411735535
generator epoch 131 loss: 1.648653751046317                 accuracy: 0.7350000143051147
generator epoch 132 loss: 1.642111288016183                 accuracy: 0.7542856931686401
generator epoch 133 loss: 1.634030916922433                 accuracy: 0.7328571081161499
generator epoch 134 loss: 1.6357798810686384                 accuracy: 0.7300000190734863
generator epoch 135 loss: 1.6325860979352678                 accuracy: 0.7507143020629883
generator epoch 136 loss: 1.6270944074358258                 accuracy: 0.7528571486473083
generator epoch 137 loss: 1.6235642647879465                 accuracy: 0.7549999952316284
generator epoch 138 loss: 1.625198175920759                 accuracy: 0.7364285588264465
generator epoch 139 loss: 1.620433096749442                 accuracy: 0.741428554058075
generator epoch 140 loss: 1.6195178379603794                 accuracy: 0.7492856979370117
generator epoch 141 loss: 1.6135738577706473                 accuracy: 0.7485713958740234
generator epoch 142 loss: 1.6111376604352678                 accuracy: 0.7407142519950867
generator epoch 143 loss: 1.609531972830636                 accuracy: 0.7428571581840515
generator epoch 144 loss: 1.6071141531808035                 accuracy: 0.7607142925262451
generator epoch 145 loss: 1.607837473842076                 accuracy: 0.7485713958740234
generator epoch 146 loss: 1.5980017246791294                 accuracy: 0.7285714149475098
generator epoch 147 loss: 1.5915232352120536                 accuracy: 0.7692856788635254
generator epoch 148 loss: 1.5973635750906807                 accuracy: 0.7464285492897034
generator epoch 149 loss: 1.5888129115513392                 accuracy: 0.7400000095367432
generator epoch 150 loss: 1.5840156459263393                 accuracy: 0.7771428227424622
generator epoch 151 loss: 1.584326016671317                 accuracy: 0.7721428275108337
generator epoch 152 loss: 1.5881847638811384                 accuracy: 0.7799999713897705
generator epoch 153 loss: 1.5801853480747767                 accuracy: 0.7521428465843201
generator epoch 154 loss: 1.574688987513951                 accuracy: 0.7799999713897705
generator epoch 155 loss: 1.575327866908482                 accuracy: 0.7635714411735535
generator epoch 156 loss: 1.5674277910505023                 accuracy: 0.7721428275108337
generator epoch 157 loss: 1.5657048453194755                 accuracy: 0.7614285349845886
generator epoch 158 loss: 1.560824653843471                 accuracy: 0.772857129573822
generator epoch 159 loss: 1.5611532679966518                 accuracy: 0.7528571486473083
generator epoch 160 loss: 1.5610866707938058                 accuracy: 0.7664285898208618
generator epoch 161 loss: 1.5578146144321987                 accuracy: 0.7599999904632568
generator epoch 162 loss: 1.5545734436035157                 accuracy: 0.7685714364051819
generator epoch 163 loss: 1.5514349155970981                 accuracy: 0.7907142639160156
generator epoch 164 loss: 1.5482943908691407                 accuracy: 0.8071428537368774
generator epoch 165 loss: 1.552570557512556                 accuracy: 0.7878571152687073
generator epoch 166 loss: 1.5439885628836496                 accuracy: 0.7607142925262451
generator epoch 167 loss: 1.5410724766322546                 accuracy: 0.7985714077949524
generator epoch 168 loss: 1.540140007672991                 accuracy: 0.7635714411735535
generator epoch 169 loss: 1.5354561872209822                 accuracy: 0.772857129573822
generator epoch 170 loss: 1.5376362574986049                 accuracy: 0.800000011920929
generator epoch 171 loss: 1.5345666251046317                 accuracy: 0.7614285349845886
generator epoch 172 loss: 1.5335611703055245                 accuracy: 0.7950000166893005
generator epoch 173 loss: 1.5261477713448661                 accuracy: 0.8007142543792725
generator epoch 174 loss: 1.5266691284179688                 accuracy: 0.7599999904632568
generator epoch 175 loss: 1.5222231096540177                 accuracy: 0.7907142639160156
generator epoch 176 loss: 1.522904541015625                 accuracy: 0.7378571629524231
generator epoch 177 loss: 1.515691162109375                 accuracy: 0.7835714221000671
generator epoch 178 loss: 1.5164946568080357                 accuracy: 0.7749999761581421
generator epoch 179 loss: 1.5174383361816406                 accuracy: 0.7807142734527588
generator epoch 180 loss: 1.513508079310826                 accuracy: 0.7485713958740234
generator epoch 181 loss: 1.5130424918038505                 accuracy: 0.7535713911056519
generator epoch 182 loss: 1.5153726981026785                 accuracy: 0.7907142639160156
generator epoch 183 loss: 1.5060165536063057                 accuracy: 0.8149999976158142
generator epoch 184 loss: 1.5057099792480468                 accuracy: 0.7885714173316956
generator epoch 185 loss: 1.5004348737444198                 accuracy: 0.8007142543792725
generator epoch 186 loss: 1.4973647844587055                 accuracy: 0.7799999713897705
generator epoch 187 loss: 1.4980238385881697                 accuracy: 0.7814285755157471
generator epoch 188 loss: 1.4972680995396206                 accuracy: 0.8028571605682373
generator epoch 189 loss: 1.4931991725376674                 accuracy: 0.802142858505249
generator epoch 190 loss: 1.4901029183523995                 accuracy: 0.8100000023841858
generator epoch 191 loss: 1.4932435956682477                 accuracy: 0.795714259147644
generator epoch 192 loss: 1.4863302978515625                 accuracy: 0.8128571510314941
generator epoch 193 loss: 1.4847612557547434                 accuracy: 0.8050000071525574
generator epoch 194 loss: 1.4820399196079799                 accuracy: 0.7878571152687073
generator epoch 195 loss: 1.4845241420200892                 accuracy: 0.7899999618530273
generator epoch 196 loss: 1.482042201450893                 accuracy: 0.8221428394317627
generator epoch 197 loss: 1.4822488316127231                 accuracy: 0.8057142496109009
generator epoch 198 loss: 1.4701253880092076                 accuracy: 0.802142858505249
generator epoch 199 loss: 1.4746247410365514                 accuracy: 0.800000011920929
generator epoch 200 loss: 1.4702860778808593                 accuracy: 0.8085713982582092
generator epoch 201 loss: 1.4675781485421318                 accuracy: 0.8257142901420593
generator epoch 202 loss: 1.4691682277134486                 accuracy: 0.8100000023841858
generator epoch 203 loss: 1.4694439392089844                 accuracy: 0.8271428346633911
generator epoch 204 loss: 1.4664799351283482                 accuracy: 0.8107143044471741
generator epoch 205 loss: 1.4669258675711496                 accuracy: 0.7685714364051819
generator epoch 206 loss: 1.4540918160574776                 accuracy: 0.779285728931427
generator epoch 207 loss: 1.4539545837402343                 accuracy: 0.7892857193946838
generator epoch 208 loss: 1.4592177664620536                 accuracy: 0.8092857003211975
generator epoch 209 loss: 1.451657163783482                 accuracy: 0.8285714387893677
generator epoch 210 loss: 1.4489617928641183                 accuracy: 0.8157142996788025
generator epoch 211 loss: 1.4487476100376675                 accuracy: 0.7928571105003357
generator epoch 212 loss: 1.449736385672433                 accuracy: 0.8357142806053162
generator epoch 213 loss: 1.443492236328125                 accuracy: 0.7928571105003357
generator epoch 214 loss: 1.442783949497768                 accuracy: 0.802142858505249
generator epoch 215 loss: 1.441719308907645                 accuracy: 0.8207142949104309
generator epoch 216 loss: 1.4491903294154576                 accuracy: 0.793571412563324
generator epoch 217 loss: 1.4408382228306362                 accuracy: 0.824999988079071
generator epoch 218 loss: 1.4456449637276785                 accuracy: 0.8328571319580078
generator epoch 219 loss: 1.4422769853864397                 accuracy: 0.8121428489685059
generator epoch 220 loss: 1.4350897068568638                 accuracy: 0.8078571557998657
generator epoch 221 loss: 1.437850892857143                 accuracy: 0.8157142996788025
generator epoch 222 loss: 1.4352877641950335                 accuracy: 0.7899999618530273
generator epoch 223 loss: 1.4371997148786273                 accuracy: 0.8192856907844543
generator epoch 224 loss: 1.4303342136928014                 accuracy: 0.8214285373687744
generator epoch 225 loss: 1.4305235273088728                 accuracy: 0.8214285373687744
generator epoch 226 loss: 1.4301954293387278                 accuracy: 0.8199999928474426
generator epoch 227 loss: 1.4248912266322544                 accuracy: 0.8271428346633911
generator epoch 228 loss: 1.4241011064801898                 accuracy: 0.8285714387893677
generator epoch 229 loss: 1.4230738577706474                 accuracy: 0.7842857241630554
generator epoch 230 loss: 1.4179218226841517                 accuracy: 0.795714259147644
generator epoch 231 loss: 1.415167586844308                 accuracy: 0.8178571462631226
generator epoch 232 loss: 1.4199828813825335                 accuracy: 0.8349999785423279
generator epoch 233 loss: 1.420305473109654                 accuracy: 0.8328571319580078
generator epoch 234 loss: 1.4143094482421874                 accuracy: 0.8135713934898376
generator epoch 235 loss: 1.4154714372907367                 accuracy: 0.8100000023841858
generator epoch 236 loss: 1.4134927507672992                 accuracy: 0.822857141494751
generator epoch 237 loss: 1.408591095842634                 accuracy: 0.8342856764793396
generator epoch 238 loss: 1.409687490408761                 accuracy: 0.8271428346633911
generator epoch 239 loss: 1.4112570295061384                 accuracy: 0.8328571319580078
generator epoch 240 loss: 1.4085700945172992                 accuracy: 0.8171428442001343
generator epoch 241 loss: 1.4117084943498883                 accuracy: 0.8307142853736877
generator epoch 242 loss: 1.4046401846749441                 accuracy: 0.8285714387893677
generator epoch 243 loss: 1.4065932582310268                 accuracy: 0.8121428489685059
generator epoch 244 loss: 1.3972122619628906                 accuracy: 0.8157142996788025
generator epoch 245 loss: 1.395438875906808                 accuracy: 0.8064285516738892
generator epoch 246 loss: 1.3985486589704241                 accuracy: 0.8128571510314941
generator epoch 247 loss: 1.39569968523298                 accuracy: 0.8442857265472412
generator epoch 248 loss: 1.3971396763392858                 accuracy: 0.8414285778999329
generator epoch 249 loss: 1.3918253435407366                 accuracy: 0.7964285612106323
generator epoch 250 loss: 1.3965689915248325                 accuracy: 0.8114285469055176
generator epoch 251 loss: 1.3920924246651785                 accuracy: 0.8364285826683044
generator epoch 252 loss: 1.393602689906529                 accuracy: 0.8100000023841858
generator epoch 253 loss: 1.3941456072126117                 accuracy: 0.837142825126648
generator epoch 254 loss: 1.391337824358259                 accuracy: 0.8292856812477112
generator epoch 255 loss: 1.388461825125558                 accuracy: 0.8378571271896362
generator epoch 256 loss: 1.3889056169782366                 accuracy: 0.8349999785423279
generator epoch 257 loss: 1.3852190176827568                 accuracy: 0.8342856764793396
generator epoch 258 loss: 1.3830992248535157                 accuracy: 0.822857141494751
generator epoch 259 loss: 1.3822675571986607                 accuracy: 0.8414285778999329
generator epoch 260 loss: 1.3857818917410714                 accuracy: 0.8414285778999329
generator epoch 261 loss: 1.3758757699148996                 accuracy: 0.8592857122421265
generator epoch 262 loss: 1.3790069893973214                 accuracy: 0.8299999833106995
generator epoch 263 loss: 1.375058656529018                 accuracy: 0.8285714387893677
generator epoch 264 loss: 1.3760032549176897                 accuracy: 0.8185714483261108
generator epoch 265 loss: 1.3747944667271206                 accuracy: 0.8414285778999329
generator epoch 266 loss: 1.3768339233398437                 accuracy: 0.8299999833106995
generator epoch 267 loss: 1.3719688589913503                 accuracy: 0.8421428203582764
generator epoch 268 loss: 1.3716261962890626                 accuracy: 0.8271428346633911
generator epoch 269 loss: 1.3704828953334263                 accuracy: 0.8399999737739563
generator epoch 270 loss: 1.3693960902622768                 accuracy: 0.8178571462631226
generator epoch 271 loss: 1.3687225708007813                 accuracy: 0.8585714101791382
generator epoch 272 loss: 1.3639282749720982                 accuracy: 0.8478571176528931
generator epoch 273 loss: 1.3699346967424666                 accuracy: 0.837142825126648
generator epoch 274 loss: 1.3680603498186383                 accuracy: 0.8364285826683044
generator epoch 275 loss: 1.3697707972935267                 accuracy: 0.8635714054107666
generator epoch 276 loss: 1.3671979718889509                 accuracy: 0.8321428298950195
generator epoch 277 loss: 1.3625560825892857                 accuracy: 0.822857141494751
generator epoch 278 loss: 1.3591096226283481                 accuracy: 0.8349999785423279
generator epoch 279 loss: 1.3621310041155135                 accuracy: 0.8407142758369446
generator epoch 280 loss: 1.3588556893484933                 accuracy: 0.852142870426178
generator epoch 281 loss: 1.360304967389788                 accuracy: 0.8449999690055847
generator epoch 282 loss: 1.3545369280133928                 accuracy: 0.8507142663002014
generator epoch 283 loss: 1.3557355756487166                 accuracy: 0.8342856764793396
generator epoch 284 loss: 1.355742865862165                 accuracy: 0.8292856812477112
generator epoch 285 loss: 1.3520317749023438                 accuracy: 0.8392857313156128
generator epoch 286 loss: 1.3482473205566405                 accuracy: 0.854285717010498
generator epoch 287 loss: 1.3495017560686384                 accuracy: 0.8557142615318298
generator epoch 288 loss: 1.3549160627092633                 accuracy: 0.8449999690055847
generator epoch 289 loss: 1.35624924054827                 accuracy: 0.8349999785423279
generator epoch 290 loss: 1.3545076093401227                 accuracy: 0.8535714149475098
generator epoch 291 loss: 1.35351416015625                 accuracy: 0.8428571224212646
generator epoch 292 loss: 1.3546247305733816                 accuracy: 0.8692857027053833
generator epoch 293 loss: 1.35072282976423                 accuracy: 0.854285717010498
generator epoch 294 loss: 1.3431375714983258                 accuracy: 0.8499999642372131
generator epoch 295 loss: 1.3431190386090959                 accuracy: 0.8585714101791382
generator epoch 296 loss: 1.3458612618582588                 accuracy: 0.8578571081161499
generator epoch 297 loss: 1.343195751953125                 accuracy: 0.8571428656578064
generator epoch 298 loss: 1.339802188546317                 accuracy: 0.8357142806053162
generator epoch 299 loss: 1.3436096287318637                 accuracy: 0.8499999642372131
generator epoch 300 loss: 1.3396733363560267                 accuracy: 0.8492857217788696
generator epoch 301 loss: 1.3379143676757812                 accuracy: 0.8564285635948181
generator epoch 302 loss: 1.3375845336914063                 accuracy: 0.8671428561210632
generator epoch 303 loss: 1.3458220345633372                 accuracy: 0.8385714292526245
generator epoch 304 loss: 1.3451999049595424                 accuracy: 0.8707142472267151
generator epoch 305 loss: 1.3426896144321987                 accuracy: 0.8528571128845215
generator epoch 306 loss: 1.3336662850516183                 accuracy: 0.8328571319580078
generator epoch 307 loss: 1.3294011771065848                 accuracy: 0.8700000047683716
generator epoch 308 loss: 1.3334678815569196                 accuracy: 0.8364285826683044
generator epoch 309 loss: 1.340399809047154                 accuracy: 0.8621428608894348
generator epoch 310 loss: 1.329515544782366                 accuracy: 0.8621428608894348
generator epoch 311 loss: 1.3329285391671317                 accuracy: 0.8757143020629883
generator epoch 312 loss: 1.3329264264787946                 accuracy: 0.8449999690055847
generator epoch 313 loss: 1.322723441859654                 accuracy: 0.8728571534156799
generator epoch 314 loss: 1.3251174787248885                 accuracy: 0.8550000190734863
generator epoch 315 loss: 1.3234437491280693                 accuracy: 0.8364285826683044
generator epoch 316 loss: 1.3264753923688617                 accuracy: 0.8564285635948181
generator epoch 317 loss: 1.3283653398786273                 accuracy: 0.8571428656578064
generator epoch 318 loss: 1.3230833888462612                 accuracy: 0.8564285635948181
generator epoch 319 loss: 1.3199789167131697                 accuracy: 0.8499999642372131
generator epoch 320 loss: 1.3233680106026786                 accuracy: 0.8650000095367432
generator epoch 321 loss: 1.322805180140904                 accuracy: 0.8557142615318298
generator epoch 322 loss: 1.3251836635044643                 accuracy: 0.8642857074737549
generator epoch 323 loss: 1.31998046875                 accuracy: 0.8564285635948181
generator epoch 324 loss: 1.3206124441964286                 accuracy: 0.8771428465843201
generator epoch 325 loss: 1.3552163879394532                 accuracy: 0.8100000023841858
generator epoch 326 loss: 1.401170845249721                 accuracy: 0.8428571224212646
generator epoch 327 loss: 1.3405988141741072                 accuracy: 0.8607142567634583
generator epoch 328 loss: 1.3286539289202008                 accuracy: 0.8321428298950195
generator epoch 329 loss: 1.3231091273716518                 accuracy: 0.8714285492897034
generator epoch 330 loss: 1.3276906101771764                 accuracy: 0.8271428346633911
generator epoch 331 loss: 1.3194739292689732                 accuracy: 0.8407142758369446
generator epoch 332 loss: 1.314164390345982                 accuracy: 0.8700000047683716
generator epoch 333 loss: 1.3210441249302456                 accuracy: 0.8635714054107666
generator epoch 334 loss: 1.3118229073660714                 accuracy: 0.8728571534156799
generator epoch 335 loss: 1.3082438773018974                 accuracy: 0.8707142472267151
generator epoch 336 loss: 1.3022028355189732                 accuracy: 0.8885714411735535
generator epoch 337 loss: 1.3053119550432477                 accuracy: 0.8421428203582764
generator epoch 338 loss: 1.3056556710379463                 accuracy: 0.8485714197158813
generator epoch 339 loss: 1.311482275390625                 accuracy: 0.8642857074737549
generator epoch 340 loss: 1.3075267211914063                 accuracy: 0.8535714149475098
generator epoch 341 loss: 1.314757004220145                 accuracy: 0.8528571128845215
generator epoch 342 loss: 1.310798686000279                 accuracy: 0.8492857217788696
generator epoch 343 loss: 1.3054965201241628                 accuracy: 0.8514285683631897
generator epoch 344 loss: 1.3023722891671317                 accuracy: 0.8700000047683716
generator epoch 345 loss: 1.3094659868512835                 accuracy: 0.8657142519950867
generator epoch 346 loss: 1.306634902518136                 accuracy: 0.8799999952316284
generator epoch 347 loss: 1.3040150678362166                 accuracy: 0.8857142925262451
generator epoch 348 loss: 1.3019356157575335                 accuracy: 0.8478571176528931
generator epoch 349 loss: 1.2980683959960937                 accuracy: 0.8799999952316284
generator epoch 350 loss: 1.3067852486746652                 accuracy: 0.8635714054107666
generator epoch 351 loss: 1.309668767438616                 accuracy: 0.8714285492897034
generator epoch 352 loss: 1.2994560564313615                 accuracy: 0.8564285635948181
generator epoch 353 loss: 1.2969540387834821                 accuracy: 0.8485714197158813
generator epoch 354 loss: 1.2981205775669642                 accuracy: 0.8799999952316284
generator epoch 355 loss: 1.2974229553222656                 accuracy: 0.8657142519950867
generator epoch 356 loss: 1.2973807137625557                 accuracy: 0.8550000190734863
generator epoch 357 loss: 1.2924587672642298                 accuracy: 0.8807142972946167
generator epoch 358 loss: 1.2925353977748326                 accuracy: 0.8785713911056519
generator epoch 359 loss: 1.2970950648716517                 accuracy: 0.8471428751945496
generator epoch 360 loss: 1.2982280421665737                 accuracy: 0.8378571271896362
generator epoch 361 loss: 1.2998320478166854                 accuracy: 0.8742856979370117
generator epoch 362 loss: 1.2916364432198661                 accuracy: 0.868571400642395
generator epoch 363 loss: 1.2953347717285155                 accuracy: 0.8621428608894348
generator epoch 364 loss: 1.2904470511300223                 accuracy: 0.8792856931686401
generator epoch 365 loss: 1.2988008457728795                 accuracy: 0.8671428561210632
generator epoch 366 loss: 1.2957530325753348                 accuracy: 0.8671428561210632
generator epoch 367 loss: 1.2931136936732701                 accuracy: 0.8485714197158813
generator epoch 368 loss: 1.2918912397112166                 accuracy: 0.8757143020629883
generator epoch 369 loss: 1.28965519757952                 accuracy: 0.8621428608894348
generator epoch 370 loss: 1.2902121355329241                 accuracy: 0.8671428561210632
generator epoch 371 loss: 1.2805851091657365                 accuracy: 0.8828571438789368
generator epoch 372 loss: 1.2827866891043527                 accuracy: 0.8899999856948853
generator epoch 373 loss: 1.2838694161551338                 accuracy: 0.875
generator epoch 374 loss: 1.289309245954241                 accuracy: 0.8671428561210632
generator epoch 375 loss: 1.2883547642299107                 accuracy: 0.8650000095367432
generator epoch 376 loss: 1.283192222377232                 accuracy: 0.8692857027053833
generator epoch 377 loss: 1.2836427969796318                 accuracy: 0.8799999952316284
generator epoch 378 loss: 1.2856176470075336                 accuracy: 0.8657142519950867
generator epoch 379 loss: 1.28809568132673                 accuracy: 0.8514285683631897
generator epoch 380 loss: 1.2856283211844308                 accuracy: 0.8714285492897034
generator epoch 381 loss: 1.2756123613630022                 accuracy: 0.8728571534156799
generator epoch 382 loss: 1.2845572588239398                 accuracy: 0.8785713911056519
generator epoch 383 loss: 1.2843711216517857                 accuracy: 0.8807142972946167
generator epoch 384 loss: 1.2819524039132255                 accuracy: 0.8471428751945496
generator epoch 385 loss: 1.2761993277413504                 accuracy: 0.8778571486473083
generator epoch 386 loss: 1.2787827741350446                 accuracy: 0.8785713911056519
generator epoch 387 loss: 1.2845238516671318                 accuracy: 0.8849999904632568
generator epoch 388 loss: 1.284081672014509                 accuracy: 0.8657142519950867
generator epoch 389 loss: 1.283213614327567                 accuracy: 0.8821428418159485
generator epoch 390 loss: 1.278070098876953                 accuracy: 0.8592857122421265
generator epoch 391 loss: 1.2801689906529017                 accuracy: 0.8807142972946167
generator epoch 392 loss: 1.2811003261021205                 accuracy: 0.8821428418159485
generator epoch 393 loss: 1.2812066214425224                 accuracy: 0.8678571581840515
generator epoch 394 loss: 1.2756795950753348                 accuracy: 0.868571400642395
generator epoch 395 loss: 1.2731002049037388                 accuracy: 0.8650000095367432
generator epoch 396 loss: 1.2738882847377233                 accuracy: 0.8600000143051147
generator epoch 397 loss: 1.275897549002511                 accuracy: 0.8742856979370117
generator epoch 398 loss: 1.2705050266810827                 accuracy: 0.8857142925262451
generator epoch 399 loss: 1.272560311453683                 accuracy: 0.883571445941925
generator epoch 400 loss: 1.2766148507254464                 accuracy: 0.8735713958740234
generator epoch 401 loss: 1.2725453264508928                 accuracy: 0.8700000047683716
generator epoch 402 loss: 1.2758304460797991                 accuracy: 0.8821428418159485
generator epoch 403 loss: 1.2731718200683593                 accuracy: 0.8792856931686401
generator epoch 404 loss: 1.2694147260393416                 accuracy: 0.8764285445213318
generator epoch 405 loss: 1.2696345781598772                 accuracy: 0.8771428465843201
generator epoch 406 loss: 1.263343949672154                 accuracy: 0.8935714364051819
generator epoch 407 loss: 1.2744957885742187                 accuracy: 0.8742856979370117
generator epoch 408 loss: 1.269804976109096                 accuracy: 0.8657142519950867
generator epoch 409 loss: 1.2743578107561384                 accuracy: 0.8728571534156799
generator epoch 410 loss: 1.2699146676199777                 accuracy: 0.8557142615318298
generator epoch 411 loss: 1.2624496590750558                 accuracy: 0.8764285445213318
generator epoch 412 loss: 1.2676412362234932                 accuracy: 0.8849999904632568
generator epoch 413 loss: 1.2610757690429688                 accuracy: 0.8871428370475769
generator epoch 414 loss: 1.2660641366141183                 accuracy: 0.9021428227424622
generator epoch 415 loss: 1.271752485874721                 accuracy: 0.8778571486473083
generator epoch 416 loss: 1.2616256504603796                 accuracy: 0.8828571438789368
generator epoch 417 loss: 1.2664064828055246                 accuracy: 0.8807142972946167
generator epoch 418 loss: 1.2594275390625                 accuracy: 0.889285683631897
generator epoch 419 loss: 1.2575940673828125                 accuracy: 0.8778571486473083
generator epoch 420 loss: 1.262102548653739                 accuracy: 0.8742856979370117
generator epoch 421 loss: 1.264181636265346                 accuracy: 0.8785713911056519
generator epoch 422 loss: 1.2621091247558593                 accuracy: 0.9128571152687073
generator epoch 423 loss: 1.263201309640067                 accuracy: 0.8899999856948853
generator epoch 424 loss: 1.2649699541364396                 accuracy: 0.897857129573822
generator epoch 425 loss: 1.2622156659807477                 accuracy: 0.8507142663002014
generator epoch 426 loss: 1.26158406023298                 accuracy: 0.8857142925262451
generator epoch 427 loss: 1.2526713797433036                 accuracy: 0.8942856788635254
generator epoch 428 loss: 1.259328525216239                 accuracy: 0.8907142877578735
generator epoch 429 loss: 1.2627392839704241                 accuracy: 0.868571400642395
generator epoch 430 loss: 1.2606024405343192                 accuracy: 0.8700000047683716
generator epoch 431 loss: 1.2561539306640626                 accuracy: 0.8692857027053833
generator epoch 432 loss: 1.2610467442103794                 accuracy: 0.8821428418159485
generator epoch 433 loss: 1.2640012983049664                 accuracy: 0.8807142972946167
generator epoch 434 loss: 1.250296138218471                 accuracy: 0.8899999856948853
generator epoch 435 loss: 1.2571173706054688                 accuracy: 0.8607142567634583
generator epoch 436 loss: 1.2548397173200334                 accuracy: 0.9021428227424622
generator epoch 437 loss: 1.2512292733328683                 accuracy: 0.8628571629524231
generator epoch 438 loss: 1.2585179565429687                 accuracy: 0.9028571248054504
generator epoch 439 loss: 1.259942164829799                 accuracy: 0.9021428227424622
generator epoch 440 loss: 1.2595758571079798                 accuracy: 0.8921428322792053
generator epoch 441 loss: 1.2545210423060826                 accuracy: 0.8857142925262451
generator epoch 442 loss: 1.2582906049455915                 accuracy: 0.8935714364051819
generator epoch 443 loss: 1.250168820626395                 accuracy: 0.9007142782211304
generator epoch 444 loss: 1.249762233189174                 accuracy: 0.8885714411735535
generator epoch 445 loss: 1.2538662379673549                 accuracy: 0.8999999761581421
generator epoch 446 loss: 1.248594682094029                 accuracy: 0.8857142925262451
generator epoch 447 loss: 1.2534817522321429                 accuracy: 0.895714282989502
generator epoch 448 loss: 1.2541667846679687                 accuracy: 0.8885714411735535
generator epoch 449 loss: 1.2666633187430245                 accuracy: 0.8807142972946167
generator epoch 450 loss: 1.2538976283482144                 accuracy: 0.8985714316368103
generator epoch 451 loss: 1.2458293509347098                 accuracy: 0.8628571629524231
generator epoch 452 loss: 1.2489660496303014                 accuracy: 0.8635714054107666
generator epoch 453 loss: 1.2383397426060267                 accuracy: 0.8899999856948853
generator epoch 454 loss: 1.2460582641601563                 accuracy: 0.8799999952316284
generator epoch 455 loss: 1.249794677734375                 accuracy: 0.8914285898208618
generator epoch 456 loss: 1.2488655430385045                 accuracy: 0.8871428370475769
generator epoch 457 loss: 1.2458570434570313                 accuracy: 0.8692857027053833
generator epoch 458 loss: 1.2506262625558036                 accuracy: 0.8878571391105652
generator epoch 459 loss: 1.249735422188895                 accuracy: 0.8842856884002686
generator epoch 460 loss: 1.2408646841866628                 accuracy: 0.8771428465843201
generator epoch 461 loss: 1.240745512172154                 accuracy: 0.9014285802841187
generator epoch 462 loss: 1.2468230250767298                 accuracy: 0.8949999809265137
generator epoch 463 loss: 1.2442686462402344                 accuracy: 0.8942856788635254
generator epoch 464 loss: 1.2504502859933035                 accuracy: 0.8949999809265137
generator epoch 465 loss: 1.2461813537597657                 accuracy: 0.8921428322792053
generator epoch 466 loss: 1.2420187587193081                 accuracy: 0.8921428322792053
generator epoch 467 loss: 1.2396869550432477                 accuracy: 0.8678571581840515
generator epoch 468 loss: 1.2444924421037946                 accuracy: 0.897857129573822
generator epoch 469 loss: 1.2393919041224888                 accuracy: 0.8678571581840515
generator epoch 470 loss: 1.2387569989885603                 accuracy: 0.8828571438789368
generator epoch 471 loss: 1.2392032305036271                 accuracy: 0.8921428322792053
generator epoch 472 loss: 1.2399719752720424                 accuracy: 0.8849999904632568
generator epoch 473 loss: 1.2333288408551897                 accuracy: 0.8785713911056519
generator epoch 474 loss: 1.2400064174107144                 accuracy: 0.8935714364051819
generator epoch 475 loss: 1.2382041966029576                 accuracy: 0.904285728931427
generator epoch 476 loss: 1.236699237060547                 accuracy: 0.904285728931427
generator epoch 477 loss: 1.2394514064243862                 accuracy: 0.9049999713897705
generator epoch 478 loss: 1.2356491350446428                 accuracy: 0.883571445941925
generator epoch 479 loss: 1.236661665562221                 accuracy: 0.8949999809265137
generator epoch 480 loss: 1.236607768031529                 accuracy: 0.9035714268684387
generator epoch 481 loss: 1.2369649605887276                 accuracy: 0.8992857336997986
generator epoch 482 loss: 1.2376134643554688                 accuracy: 0.8871428370475769
generator epoch 483 loss: 1.235060928780692                 accuracy: 0.9049999713897705
generator epoch 484 loss: 1.2339745928083148                 accuracy: 0.8642857074737549
generator epoch 485 loss: 1.2377352791922434                 accuracy: 0.9014285802841187
generator epoch 486 loss: 1.2384954842703684                 accuracy: 0.8857142925262451
generator epoch 487 loss: 1.2396247523716517                 accuracy: 0.8692857027053833
generator epoch 488 loss: 1.2325955426897321                 accuracy: 0.8971428275108337
generator epoch 489 loss: 1.237338507952009                 accuracy: 0.8899999856948853
generator epoch 490 loss: 1.24634350062779                 accuracy: 0.8899999856948853
generator epoch 491 loss: 1.2404849731445313                 accuracy: 0.9014285802841187
generator epoch 492 loss: 1.2334316310337612                 accuracy: 0.8707142472267151
generator epoch 493 loss: 1.2364841605050223                 accuracy: 0.925000011920929
generator epoch 494 loss: 1.2351471618652343                 accuracy: 0.8807142972946167
generator epoch 495 loss: 1.2307570390973772                 accuracy: 0.8885714411735535
generator epoch 496 loss: 1.2291513017926898                 accuracy: 0.868571400642395
generator epoch 497 loss: 1.2323260175432478                 accuracy: 0.8878571391105652
generator epoch 498 loss: 1.228439964076451                 accuracy: 0.9214285612106323
generator epoch 499 loss: 1.2359314889090403                 accuracy: 0.8864285349845886
batch 0 train loss: [5.8750668]
batch 1 train loss: [3.2735224]
batch 2 train loss: [2.8079011]
batch 3 train loss: [2.837383]
batch 4 train loss: [2.537587]
batch 5 train loss: [2.4727]
batch 6 train loss: [2.3104115]
batch 7 train loss: [2.204039]
batch 8 train loss: [2.184842]
batch 9 train loss: [2.0469773]
batch 10 train loss: [2.2329783]
batch 11 train loss: [2.1455104]
batch 12 train loss: [2.1760325]
batch 13 train loss: [2.0001926]
batch 14 train loss: [2.1079102]
batch 15 train loss: [1.8451179]
batch 16 train loss: [2.0262535]
batch 17 train loss: [2.0037007]
batch 18 train loss: [2.064671]
batch 19 train loss: [1.9564692]
batch 20 train loss: [1.9175067]
batch 21 train loss: [1.7850276]
batch 22 train loss: [1.851774]
batch 23 train loss: [1.9211705]
batch 24 train loss: [1.8699828]
batch 25 train loss: [1.8653761]
batch 26 train loss: [1.8324373]
batch 27 train loss: [1.8828173]
batch 28 train loss: [1.8145212]
batch 29 train loss: [1.8000118]
batch 30 train loss: [1.8256551]
batch 31 train loss: [1.7804881]
batch 32 train loss: [1.7538722]
batch 33 train loss: [1.7082627]
batch 34 train loss: [1.8186938]
batch 35 train loss: [1.675573]
batch 36 train loss: [1.7202594]
batch 37 train loss: [1.7869285]
batch 38 train loss: [1.742693]
batch 39 train loss: [1.9049178]
batch 40 train loss: [1.8109703]
batch 41 train loss: [1.717812]
batch 42 train loss: [1.6956159]
batch 43 train loss: [1.7423389]
batch 44 train loss: [1.8586313]
batch 45 train loss: [1.7171865]
batch 46 train loss: [1.6268115]
batch 47 train loss: [1.6545211]
batch 48 train loss: [1.6414813]
batch 49 train loss: [1.640582]
batch 50 train loss: [1.7767802]
batch 51 train loss: [1.8342338]
batch 52 train loss: [1.6347555]
batch 53 train loss: [1.7397106]
batch 54 train loss: [1.7101686]
batch 55 train loss: [1.6566427]
batch 56 train loss: [1.7291322]
batch 57 train loss: [1.5299518]
batch 58 train loss: [1.5717943]
batch 59 train loss: [1.7263013]
batch 60 train loss: [1.5643045]
batch 61 train loss: [1.5842853]
batch 62 train loss: [1.5994565]
batch 63 train loss: [1.5254358]
batch 64 train loss: [1.5051959]
batch 65 train loss: [1.6045356]
batch 66 train loss: [1.6547112]
batch 67 train loss: [1.6560084]
batch 68 train loss: [1.5303266]
batch 69 train loss: [1.6800183]
batch 70 train loss: [1.5478075]
batch 71 train loss: [1.5349511]
batch 72 train loss: [1.6485457]
batch 73 train loss: [1.5823497]
batch 74 train loss: [1.7571924]
batch 75 train loss: [1.6726747]
batch 76 train loss: [1.6705604]
batch 77 train loss: [1.5690378]
batch 78 train loss: [1.6314379]
batch 79 train loss: [1.5603544]
batch 80 train loss: [1.6022707]
batch 81 train loss: [1.6651794]
batch 82 train loss: [1.6014397]
batch 83 train loss: [1.759134]
batch 84 train loss: [1.4926959]
batch 85 train loss: [1.6479872]
batch 86 train loss: [1.6405848]
batch 87 train loss: [1.5555718]
batch 88 train loss: [1.612387]
batch 89 train loss: [1.5322317]
batch 90 train loss: [1.7312145]
batch 91 train loss: [1.6785134]
batch 92 train loss: [1.7254934]
batch 93 train loss: [1.6144083]
batch 94 train loss: [1.4871186]
batch 95 train loss: [1.5908072]
batch 96 train loss: [1.5675379]
batch 97 train loss: [1.5469711]
batch 98 train loss: [1.4940124]
batch 99 train loss: [1.6680063]
epoch 0 mean train loss: [1.8367535]
Epoch 0/400=>  train_loss: [1.8367535], iou: nan, cd: 5.125008384370162, test_mse: [1.6310337]
CORRECT PROGRAMS: 9314
batch 0 train loss: [1.3956946]
batch 1 train loss: [1.4648778]
batch 2 train loss: [1.5008824]
batch 3 train loss: [1.5159363]
batch 4 train loss: [1.6217846]
batch 5 train loss: [1.5207255]
batch 6 train loss: [1.3939296]
batch 7 train loss: [1.3007586]
batch 8 train loss: [1.5241027]
batch 9 train loss: [1.5111502]
batch 10 train loss: [1.4450232]
batch 11 train loss: [1.5076696]
batch 12 train loss: [1.4555548]
batch 13 train loss: [1.5042565]
batch 14 train loss: [1.4012265]
batch 15 train loss: [1.4969585]
batch 16 train loss: [1.5053608]
batch 17 train loss: [1.480465]
batch 18 train loss: [1.5459977]
batch 19 train loss: [1.5600908]
batch 20 train loss: [1.6344368]
batch 21 train loss: [1.4804628]
batch 22 train loss: [1.4938391]
batch 23 train loss: [1.4110826]
batch 24 train loss: [1.512912]
batch 25 train loss: [1.4426106]
batch 26 train loss: [1.4940404]
batch 27 train loss: [1.4228432]
batch 28 train loss: [1.4063193]
batch 29 train loss: [1.5499128]
batch 30 train loss: [1.5614655]
batch 31 train loss: [1.5450984]
batch 32 train loss: [1.471772]
batch 33 train loss: [1.5040382]
batch 34 train loss: [1.4946262]
batch 35 train loss: [1.5226961]
batch 36 train loss: [1.4957958]
batch 37 train loss: [1.4578125]
batch 38 train loss: [1.4599249]
batch 39 train loss: [1.4805014]
batch 40 train loss: [1.437736]
batch 41 train loss: [1.5158907]
batch 42 train loss: [1.4515014]
batch 43 train loss: [1.4788232]
batch 44 train loss: [1.3809153]
batch 45 train loss: [1.3327693]
batch 46 train loss: [1.5524924]
batch 47 train loss: [1.5700432]
batch 48 train loss: [1.5882386]
batch 49 train loss: [1.4535838]
batch 50 train loss: [1.5709544]
batch 51 train loss: [1.3969208]
batch 52 train loss: [1.4388669]
batch 53 train loss: [1.4097947]
batch 54 train loss: [1.4074919]
batch 55 train loss: [1.5673957]
batch 56 train loss: [1.383085]
batch 57 train loss: [1.5829066]
batch 58 train loss: [1.382581]
batch 59 train loss: [1.4457419]
batch 60 train loss: [1.4746705]
batch 61 train loss: [1.5466872]
batch 62 train loss: [1.316438]
batch 63 train loss: [1.5135493]
batch 64 train loss: [1.3860451]
batch 65 train loss: [1.4588464]
batch 66 train loss: [1.4672416]
batch 67 train loss: [1.5301203]
batch 68 train loss: [1.5508035]
batch 69 train loss: [1.5039226]
batch 70 train loss: [1.5735556]
batch 71 train loss: [1.5423604]
batch 72 train loss: [1.4792168]
batch 73 train loss: [1.4681491]
batch 74 train loss: [1.3645784]
batch 75 train loss: [1.6202443]
batch 76 train loss: [1.4153482]
batch 77 train loss: [1.4547331]
batch 78 train loss: [1.4137889]
batch 79 train loss: [1.4813083]
batch 80 train loss: [1.405607]
batch 81 train loss: [1.4679016]
batch 82 train loss: [1.563933]
batch 83 train loss: [1.3690768]
batch 84 train loss: [1.4363799]
batch 85 train loss: [1.4160272]
batch 86 train loss: [1.3850131]
batch 87 train loss: [1.5997645]
batch 88 train loss: [1.3897959]
batch 89 train loss: [1.4199207]
batch 90 train loss: [1.4589283]
batch 91 train loss: [1.506427]
batch 92 train loss: [1.5251402]
batch 93 train loss: [1.6622835]
batch 94 train loss: [1.4382241]
batch 95 train loss: [1.4721081]
batch 96 train loss: [1.4742488]
batch 97 train loss: [1.4242097]
batch 98 train loss: [1.4852242]
batch 99 train loss: [1.5286729]
epoch 1 mean train loss: [1.4783287]
Epoch 1/400=>  train_loss: [1.4783287], iou: nan, cd: 4.746448093906515, test_mse: [1.5246199]
CORRECT PROGRAMS: 9314
batch 0 train loss: [1.2625546]
batch 1 train loss: [1.2955805]
batch 2 train loss: [1.3089803]
batch 3 train loss: [1.4565908]
batch 4 train loss: [1.3882143]
batch 5 train loss: [1.2802006]
batch 6 train loss: [1.4227866]
batch 7 train loss: [1.3603023]
batch 8 train loss: [1.3053373]
batch 9 train loss: [1.4393389]
batch 10 train loss: [1.3236483]
batch 11 train loss: [1.4140899]
batch 12 train loss: [1.3318882]
batch 13 train loss: [1.4068698]
batch 14 train loss: [1.4005761]
batch 15 train loss: [1.3682433]
batch 16 train loss: [1.4494462]
batch 17 train loss: [1.3097523]
batch 18 train loss: [1.2794719]
batch 19 train loss: [1.3821013]
batch 20 train loss: [1.3569425]
batch 21 train loss: [1.3761817]
batch 22 train loss: [1.3417333]
batch 23 train loss: [1.3742837]
batch 24 train loss: [1.4007045]
batch 25 train loss: [1.2747248]
batch 26 train loss: [1.35695]
batch 27 train loss: [1.4110649]
batch 28 train loss: [1.3177]
batch 29 train loss: [1.4624256]
batch 30 train loss: [1.3265985]
batch 31 train loss: [1.4776895]
batch 32 train loss: [1.2888511]
batch 33 train loss: [1.3486425]
batch 34 train loss: [1.4276019]
batch 35 train loss: [1.3152072]
batch 36 train loss: [1.2364777]
batch 37 train loss: [1.364204]
batch 38 train loss: [1.4166522]
batch 39 train loss: [1.3421967]
batch 40 train loss: [1.3875172]
batch 41 train loss: [1.3846656]
batch 42 train loss: [1.345628]
batch 43 train loss: [1.4900858]
batch 44 train loss: [1.3946985]
batch 45 train loss: [1.2496637]
batch 46 train loss: [1.4120306]
batch 47 train loss: [1.2869]
batch 48 train loss: [1.3571918]
batch 49 train loss: [1.3660742]
batch 50 train loss: [1.3075564]
batch 51 train loss: [1.3782669]
batch 52 train loss: [1.3750688]
batch 53 train loss: [1.327876]
batch 54 train loss: [1.4819624]
batch 55 train loss: [1.306373]
batch 56 train loss: [1.3842574]
batch 57 train loss: [1.3675781]
batch 58 train loss: [1.3356372]
batch 59 train loss: [1.2478628]
batch 60 train loss: [1.5666363]
batch 61 train loss: [1.4576089]
batch 62 train loss: [1.4159257]
batch 63 train loss: [1.4411117]
batch 64 train loss: [1.3161725]
batch 65 train loss: [1.305244]
batch 66 train loss: [1.4795458]
batch 67 train loss: [1.3642181]
batch 68 train loss: [1.435964]
batch 69 train loss: [1.4292763]
batch 70 train loss: [1.2896433]
batch 71 train loss: [1.3484757]
batch 72 train loss: [1.3833057]
batch 73 train loss: [1.3911726]
batch 74 train loss: [1.3362029]
batch 75 train loss: [1.3308673]
batch 76 train loss: [1.4551762]
batch 77 train loss: [1.3744289]
batch 78 train loss: [1.2995366]
batch 79 train loss: [1.2531859]
batch 80 train loss: [1.334536]
batch 81 train loss: [1.3896167]
batch 82 train loss: [1.340185]
batch 83 train loss: [1.3548566]
batch 84 train loss: [1.4153562]
batch 85 train loss: [1.4193834]
batch 86 train loss: [1.3856233]
batch 87 train loss: [1.4411887]
batch 88 train loss: [1.2152203]
batch 89 train loss: [1.2941273]
batch 90 train loss: [1.4176831]
batch 91 train loss: [1.256224]
batch 92 train loss: [1.2743204]
batch 93 train loss: [1.3220255]
batch 94 train loss: [1.4824157]
batch 95 train loss: [1.2954247]
batch 96 train loss: [1.4686216]
batch 97 train loss: [1.5026885]
batch 98 train loss: [1.3690726]
batch 99 train loss: [1.322937]
epoch 2 mean train loss: [1.3656492]
Epoch 2/400=>  train_loss: [1.3656492], iou: nan, cd: 4.524275824238281, test_mse: [1.4534413]
CORRECT PROGRAMS: 9314
batch 0 train loss: [1.2535992]
batch 1 train loss: [1.3412464]
batch 2 train loss: [1.282424]
batch 3 train loss: [1.3840517]
batch 4 train loss: [1.2953879]
batch 5 train loss: [1.2448609]
batch 6 train loss: [1.1539296]
batch 7 train loss: [1.244583]
batch 8 train loss: [1.2456605]
batch 9 train loss: [1.1476246]
batch 10 train loss: [1.2566874]
batch 11 train loss: [1.2327658]
batch 12 train loss: [1.26555]
batch 13 train loss: [1.2934054]
batch 14 train loss: [1.3819698]
batch 15 train loss: [1.3266406]
batch 16 train loss: [1.4080923]
batch 17 train loss: [1.3281467]
batch 18 train loss: [1.3187437]
batch 19 train loss: [1.3479999]
batch 20 train loss: [1.2334132]
batch 21 train loss: [1.1907486]
batch 22 train loss: [1.312176]
batch 23 train loss: [1.2996277]
batch 24 train loss: [1.3104358]
batch 25 train loss: [1.2258046]
batch 26 train loss: [1.1883143]
batch 27 train loss: [1.369211]
batch 28 train loss: [1.2644258]
batch 29 train loss: [1.2695997]
batch 30 train loss: [1.1533763]
batch 31 train loss: [1.3635228]
batch 32 train loss: [1.2098769]
batch 33 train loss: [1.3044481]
batch 34 train loss: [1.3165661]
batch 35 train loss: [1.3069524]
batch 36 train loss: [1.4165214]
batch 37 train loss: [1.2389053]
batch 38 train loss: [1.1678028]
batch 39 train loss: [1.2687012]
batch 40 train loss: [1.3245268]
batch 41 train loss: [1.2307192]
batch 42 train loss: [1.2891593]
batch 43 train loss: [1.3151844]
batch 44 train loss: [1.3120048]
batch 45 train loss: [1.3346999]
batch 46 train loss: [1.3366648]
batch 47 train loss: [1.2435048]
batch 48 train loss: [1.3307068]
batch 49 train loss: [1.3309867]
batch 50 train loss: [1.2955213]
batch 51 train loss: [1.2135636]
batch 52 train loss: [1.2709262]
batch 53 train loss: [1.2554206]
batch 54 train loss: [1.1808636]
batch 55 train loss: [1.3731692]
batch 56 train loss: [1.3851374]
batch 57 train loss: [1.2673973]
batch 58 train loss: [1.2340692]
batch 59 train loss: [1.3438656]
batch 60 train loss: [1.2421223]
batch 61 train loss: [1.2647866]
batch 62 train loss: [1.1943337]
batch 63 train loss: [1.2205627]
batch 64 train loss: [1.2919302]
batch 65 train loss: [1.3813026]
batch 66 train loss: [1.2755507]
batch 67 train loss: [1.3117085]
batch 68 train loss: [1.3953413]
batch 69 train loss: [1.2223823]
batch 70 train loss: [1.2425162]
batch 71 train loss: [1.200167]
batch 72 train loss: [1.3671247]
batch 73 train loss: [1.2705072]
batch 74 train loss: [1.4376601]
batch 75 train loss: [1.2025591]
batch 76 train loss: [1.372297]
batch 77 train loss: [1.2387155]
batch 78 train loss: [1.226035]
batch 79 train loss: [1.35409]
batch 80 train loss: [1.2475916]
batch 81 train loss: [1.2670468]
batch 82 train loss: [1.2643541]
batch 83 train loss: [1.3396766]
batch 84 train loss: [1.3877476]
batch 85 train loss: [1.2009169]
batch 86 train loss: [1.2959877]
batch 87 train loss: [1.2685298]
batch 88 train loss: [1.363473]
batch 89 train loss: [1.3305132]
batch 90 train loss: [1.2707028]
batch 91 train loss: [1.1746776]
batch 92 train loss: [1.2103847]
batch 93 train loss: [1.3541896]
batch 94 train loss: [1.3676554]
batch 95 train loss: [1.2965195]
batch 96 train loss: [1.2796391]
batch 97 train loss: [1.1645001]
batch 98 train loss: [1.45863]
batch 99 train loss: [1.2622226]
epoch 3 mean train loss: [1.2854854]
Epoch 3/400=>  train_loss: [1.2854854], iou: nan, cd: 4.417630682772566, test_mse: [1.4291414]
CORRECT PROGRAMS: 9314
batch 0 train loss: [1.1106842]
batch 1 train loss: [1.2940843]
batch 2 train loss: [1.191057]
batch 3 train loss: [1.1600888]
batch 4 train loss: [1.1604972]
batch 5 train loss: [1.1691157]
batch 6 train loss: [1.1701052]
batch 7 train loss: [1.1445843]
batch 8 train loss: [1.0500106]
batch 9 train loss: [1.0631949]
batch 10 train loss: [1.3925989]
batch 11 train loss: [1.2260236]
batch 12 train loss: [1.1850572]
batch 13 train loss: [1.3898101]
batch 14 train loss: [1.1697706]
batch 15 train loss: [1.2254556]
batch 16 train loss: [1.0929793]
batch 17 train loss: [1.2270734]
batch 18 train loss: [1.1048683]
batch 19 train loss: [1.2610736]
batch 20 train loss: [1.323048]
batch 21 train loss: [1.186004]
batch 22 train loss: [1.1718392]
batch 23 train loss: [1.1374049]
batch 24 train loss: [1.1510937]
batch 25 train loss: [1.2133961]
batch 26 train loss: [1.4028846]
batch 27 train loss: [1.2614605]
batch 28 train loss: [1.1893733]
batch 29 train loss: [1.2294152]
batch 30 train loss: [1.280219]
batch 31 train loss: [1.1615709]
batch 32 train loss: [1.2240984]
batch 33 train loss: [1.1553693]
batch 34 train loss: [1.1429652]
batch 35 train loss: [1.113578]
batch 36 train loss: [1.1771867]
batch 37 train loss: [1.2282691]
batch 38 train loss: [1.2997347]
batch 39 train loss: [1.2357368]
batch 40 train loss: [1.2541264]
batch 41 train loss: [1.2095077]
batch 42 train loss: [1.1966386]
batch 43 train loss: [1.1834797]
batch 44 train loss: [1.1631256]
batch 45 train loss: [1.2268969]
batch 46 train loss: [1.2907097]
batch 47 train loss: [1.1932337]
batch 48 train loss: [0.984266]
batch 49 train loss: [1.1471118]
batch 50 train loss: [1.2652273]
batch 51 train loss: [1.1277007]
batch 52 train loss: [1.1922978]
batch 53 train loss: [1.3060765]
batch 54 train loss: [1.212254]
batch 55 train loss: [1.247527]
batch 56 train loss: [1.3342755]
batch 57 train loss: [1.1326349]
batch 58 train loss: [1.273222]
batch 59 train loss: [1.1706719]
batch 60 train loss: [1.15707]
batch 61 train loss: [1.1219819]
batch 62 train loss: [1.308935]
batch 63 train loss: [1.1712143]
batch 64 train loss: [1.1657853]
batch 65 train loss: [1.4893897]
batch 66 train loss: [1.1616447]
batch 67 train loss: [1.1805595]
batch 68 train loss: [1.1065899]
batch 69 train loss: [1.2310815]
batch 70 train loss: [1.2699572]
batch 71 train loss: [1.228852]
batch 72 train loss: [1.1921515]
batch 73 train loss: [1.2733636]
batch 74 train loss: [1.094581]
batch 75 train loss: [1.171289]
batch 76 train loss: [1.2020347]
batch 77 train loss: [1.3334757]
batch 78 train loss: [1.2841809]
batch 79 train loss: [1.2494762]
batch 80 train loss: [1.3294137]
batch 81 train loss: [1.2941083]
batch 82 train loss: [1.2877529]
batch 83 train loss: [1.2443961]
batch 84 train loss: [1.2751589]
batch 85 train loss: [1.280987]
batch 86 train loss: [1.2381749]
batch 87 train loss: [1.2043208]
batch 88 train loss: [1.2867097]
batch 89 train loss: [1.3391852]
batch 90 train loss: [1.1092637]
batch 91 train loss: [1.1745099]
batch 92 train loss: [1.1184487]
batch 93 train loss: [1.2841351]
batch 94 train loss: [1.0861201]
batch 95 train loss: [1.2251124]
batch 96 train loss: [1.2187648]
batch 97 train loss: [1.3185622]
batch 98 train loss: [1.338266]
batch 99 train loss: [1.3227526]
epoch 4 mean train loss: [1.215535]
Epoch 4/400=>  train_loss: [1.215535], iou: nan, cd: 4.400381638257773, test_mse: [1.4088894]
CORRECT PROGRAMS: 9314
batch 0 train loss: [1.1866384]
batch 1 train loss: [1.1637444]
batch 2 train loss: [1.2022386]
batch 3 train loss: [1.169583]
batch 4 train loss: [1.0696125]
batch 5 train loss: [1.1328864]
batch 6 train loss: [1.188518]
batch 7 train loss: [1.1773716]
batch 8 train loss: [1.2853682]
batch 9 train loss: [1.0812064]
batch 10 train loss: [1.1818256]
batch 11 train loss: [1.0588038]
batch 12 train loss: [1.0962542]
batch 13 train loss: [1.0033255]
batch 14 train loss: [1.2084023]
batch 15 train loss: [1.1265271]
batch 16 train loss: [1.1838249]
batch 17 train loss: [1.0403662]
batch 18 train loss: [1.107807]
batch 19 train loss: [1.0824041]
batch 20 train loss: [1.07944]
batch 21 train loss: [1.1985911]
batch 22 train loss: [1.0556355]
batch 23 train loss: [1.2401516]
batch 24 train loss: [1.1875442]
batch 25 train loss: [1.1168888]
batch 26 train loss: [1.3064426]
batch 27 train loss: [1.1584195]
batch 28 train loss: [1.0849073]
batch 29 train loss: [1.1870017]
batch 30 train loss: [1.1413739]
batch 31 train loss: [1.1874517]
batch 32 train loss: [1.2655094]
batch 33 train loss: [1.1577679]
batch 34 train loss: [1.0960712]
batch 35 train loss: [1.0745205]
batch 36 train loss: [1.1530776]
batch 37 train loss: [1.2207601]
batch 38 train loss: [1.0787991]
batch 39 train loss: [1.0574102]
batch 40 train loss: [1.1454989]
batch 41 train loss: [1.094798]
batch 42 train loss: [1.0843686]
batch 43 train loss: [1.1373953]
batch 44 train loss: [1.1667387]
batch 45 train loss: [1.14426]
batch 46 train loss: [1.1487856]
batch 47 train loss: [1.153867]
batch 48 train loss: [1.2811632]
batch 49 train loss: [1.0453998]
batch 50 train loss: [1.113065]
batch 51 train loss: [1.2923068]
batch 52 train loss: [1.2286718]
batch 53 train loss: [1.106341]
batch 54 train loss: [1.1945447]
batch 55 train loss: [1.1212215]
batch 56 train loss: [1.2198559]
batch 57 train loss: [1.2161278]
batch 58 train loss: [1.2210423]
batch 59 train loss: [1.0034142]
batch 60 train loss: [1.2121067]
batch 61 train loss: [1.0926214]
batch 62 train loss: [1.1278712]
batch 63 train loss: [1.2335367]
batch 64 train loss: [1.1066121]
batch 65 train loss: [1.0631435]
batch 66 train loss: [1.0557882]
batch 67 train loss: [1.197872]
batch 68 train loss: [1.1596473]
batch 69 train loss: [1.06954]
batch 70 train loss: [1.294446]
batch 71 train loss: [1.0401027]
batch 72 train loss: [1.1453655]
batch 73 train loss: [1.1843003]
batch 74 train loss: [1.0489931]
batch 75 train loss: [1.265578]
batch 76 train loss: [1.2010229]
batch 77 train loss: [1.1920316]
batch 78 train loss: [1.191433]
batch 79 train loss: [1.1449721]
batch 80 train loss: [1.1969986]
batch 81 train loss: [1.1327901]
batch 82 train loss: [1.2058969]
batch 83 train loss: [1.2698745]
batch 84 train loss: [1.1904886]
batch 85 train loss: [1.1246684]
batch 86 train loss: [1.0754111]
batch 87 train loss: [1.2099814]
batch 88 train loss: [1.1931138]
batch 89 train loss: [1.219203]
batch 90 train loss: [1.2227969]
batch 91 train loss: [1.1064119]
batch 92 train loss: [1.2270184]
batch 93 train loss: [1.2208745]
batch 94 train loss: [1.1902357]
batch 95 train loss: [1.1456313]
batch 96 train loss: [1.3143358]
batch 97 train loss: [1.2427876]
batch 98 train loss: [1.1910871]
batch 99 train loss: [1.1794541]
epoch 5 mean train loss: [1.1579937]
Epoch 5/400=>  train_loss: [1.1579937], iou: nan, cd: 4.407188755323099, test_mse: [1.4101025]
CORRECT PROGRAMS: 9314
batch 0 train loss: [1.0178612]
batch 1 train loss: [1.054449]
batch 2 train loss: [1.0813594]
batch 3 train loss: [1.0765641]
batch 4 train loss: [1.124634]
batch 5 train loss: [1.1204903]
batch 6 train loss: [1.0653734]
batch 7 train loss: [1.0125844]
batch 8 train loss: [1.0663998]
batch 9 train loss: [1.1441121]
batch 10 train loss: [1.1160729]
batch 11 train loss: [1.0055469]
batch 12 train loss: [0.92704505]
batch 13 train loss: [1.0922886]
batch 14 train loss: [1.2502251]
batch 15 train loss: [1.0536714]
batch 16 train loss: [1.1231526]
batch 17 train loss: [1.178002]
batch 18 train loss: [1.0279368]
batch 19 train loss: [1.1401057]
batch 20 train loss: [1.1733272]
batch 21 train loss: [1.0988835]
batch 22 train loss: [1.1437835]
batch 23 train loss: [1.1003344]
batch 24 train loss: [1.0720872]
batch 25 train loss: [1.1941721]
batch 26 train loss: [0.9923891]
batch 27 train loss: [1.0918934]
batch 28 train loss: [1.2335758]
batch 29 train loss: [1.0971482]
batch 30 train loss: [1.0666938]
batch 31 train loss: [1.0534647]
batch 32 train loss: [1.1597335]
batch 33 train loss: [1.1351644]
batch 34 train loss: [1.0306872]
batch 35 train loss: [1.0825655]
batch 36 train loss: [1.0447836]
batch 37 train loss: [1.2261347]
batch 38 train loss: [1.1352394]
batch 39 train loss: [1.0827789]
batch 40 train loss: [1.1658643]
batch 41 train loss: [1.0701884]
batch 42 train loss: [1.181313]
batch 43 train loss: [1.0407878]
batch 44 train loss: [1.1119018]
batch 45 train loss: [1.1643494]
batch 46 train loss: [1.1610789]
batch 47 train loss: [1.0495218]
batch 48 train loss: [1.0818161]
batch 49 train loss: [1.049489]
batch 50 train loss: [1.1034998]
batch 51 train loss: [1.1531773]
batch 52 train loss: [0.99382955]
batch 53 train loss: [1.0929532]
batch 54 train loss: [1.1368914]
batch 55 train loss: [1.1716621]
batch 56 train loss: [1.1088892]
batch 57 train loss: [1.1195784]
batch 58 train loss: [1.0920893]
batch 59 train loss: [1.2026652]
batch 60 train loss: [1.0291941]
batch 61 train loss: [1.1161109]
batch 62 train loss: [1.2147058]
batch 63 train loss: [1.0461593]
batch 64 train loss: [1.1250126]
batch 65 train loss: [1.1432022]
batch 66 train loss: [0.97661275]
batch 67 train loss: [1.1264579]
batch 68 train loss: [1.1146154]
batch 69 train loss: [1.1727052]
batch 70 train loss: [0.9866526]
batch 71 train loss: [1.0555023]
batch 72 train loss: [1.1428005]
batch 73 train loss: [1.1619673]
batch 74 train loss: [1.2349887]
batch 75 train loss: [1.039595]
batch 76 train loss: [1.088869]
batch 77 train loss: [1.1768843]
batch 78 train loss: [1.0042858]
batch 79 train loss: [1.1935768]
batch 80 train loss: [1.0678829]
batch 81 train loss: [1.0920019]
batch 82 train loss: [1.0312861]
batch 83 train loss: [1.0522097]
batch 84 train loss: [1.0919015]
batch 85 train loss: [1.063044]
batch 86 train loss: [1.1578016]
batch 87 train loss: [1.0436088]
batch 88 train loss: [1.1575247]
batch 89 train loss: [1.1180404]
batch 90 train loss: [1.1274676]
batch 91 train loss: [1.0809623]
batch 92 train loss: [1.0800849]
batch 93 train loss: [1.1304601]
batch 94 train loss: [1.0563402]
batch 95 train loss: [0.9909666]
batch 96 train loss: [1.1558665]
batch 97 train loss: [1.0942396]
batch 98 train loss: [1.0506146]
batch 99 train loss: [1.2359052]
epoch 6 mean train loss: [1.1017238]
Epoch 6/400=>  train_loss: [1.1017238], iou: nan, cd: 4.076215853380768, test_mse: [1.387409]
CORRECT PROGRAMS: 9314
batch 0 train loss: [1.0140032]
batch 1 train loss: [1.026298]
batch 2 train loss: [1.0213903]
batch 3 train loss: [1.0238918]
batch 4 train loss: [1.1772447]
batch 5 train loss: [1.0173568]
batch 6 train loss: [0.96195537]
batch 7 train loss: [1.0305709]
batch 8 train loss: [1.0613115]
batch 9 train loss: [0.9988659]
batch 10 train loss: [1.0701759]
batch 11 train loss: [0.96390665]
batch 12 train loss: [0.94527215]
batch 13 train loss: [1.0106249]
batch 14 train loss: [1.1481365]
batch 15 train loss: [0.9079875]
batch 16 train loss: [0.9356787]
batch 17 train loss: [0.9593418]
batch 18 train loss: [0.9912749]
batch 19 train loss: [0.93842125]
batch 20 train loss: [1.094948]
batch 21 train loss: [0.9992849]
batch 22 train loss: [0.98261034]
batch 23 train loss: [1.01459]
batch 24 train loss: [1.1104563]
batch 25 train loss: [1.0578698]
batch 26 train loss: [1.0757035]
batch 27 train loss: [1.08553]
batch 28 train loss: [1.0661626]
batch 29 train loss: [1.0391481]
batch 30 train loss: [1.0841464]
batch 31 train loss: [1.0723286]
batch 32 train loss: [1.1135371]
batch 33 train loss: [1.0429845]
batch 34 train loss: [0.9692881]
batch 35 train loss: [1.0161618]
batch 36 train loss: [1.0723622]
batch 37 train loss: [0.92271006]
batch 38 train loss: [0.9548527]
batch 39 train loss: [1.0310792]
batch 40 train loss: [0.98216444]
batch 41 train loss: [1.0615078]
batch 42 train loss: [1.0611835]
batch 43 train loss: [1.0251794]
batch 44 train loss: [1.029768]
batch 45 train loss: [1.0324013]
batch 46 train loss: [1.0405024]
batch 47 train loss: [1.1915393]
batch 48 train loss: [0.9728131]
batch 49 train loss: [1.1417923]
batch 50 train loss: [1.0060568]
batch 51 train loss: [1.0162324]
batch 52 train loss: [1.03704]
batch 53 train loss: [1.0721353]
batch 54 train loss: [0.9955459]
batch 55 train loss: [1.0698608]
batch 56 train loss: [0.996765]
batch 57 train loss: [1.068573]
batch 58 train loss: [1.0367054]
batch 59 train loss: [1.0703195]
batch 60 train loss: [1.1476176]
batch 61 train loss: [1.0676863]
batch 62 train loss: [1.1736217]
batch 63 train loss: [1.0581337]
batch 64 train loss: [0.9786291]
batch 65 train loss: [1.127644]
batch 66 train loss: [1.0016258]
batch 67 train loss: [1.097539]
batch 68 train loss: [1.1298649]
batch 69 train loss: [0.9595065]
batch 70 train loss: [1.0877767]
batch 71 train loss: [1.1526126]
batch 72 train loss: [1.1304477]
batch 73 train loss: [1.1535954]
batch 74 train loss: [1.1327417]
batch 75 train loss: [1.0600203]
batch 76 train loss: [1.1421702]
batch 77 train loss: [1.0418414]
batch 78 train loss: [1.0944531]
batch 79 train loss: [0.95681584]
batch 80 train loss: [1.0158905]
batch 81 train loss: [0.90913355]
batch 82 train loss: [1.0565996]
batch 83 train loss: [1.0752369]
batch 84 train loss: [1.136127]
batch 85 train loss: [1.1155231]
batch 86 train loss: [1.0061414]
batch 87 train loss: [1.0874708]
batch 88 train loss: [1.1942765]
batch 89 train loss: [1.018122]
batch 90 train loss: [1.0427785]
batch 91 train loss: [1.0314859]
batch 92 train loss: [1.1305794]
batch 93 train loss: [1.1694987]
batch 94 train loss: [0.9837101]
batch 95 train loss: [1.1643791]
batch 96 train loss: [1.0100815]
batch 97 train loss: [0.89489526]
batch 98 train loss: [1.1114285]
batch 99 train loss: [1.0858434]
epoch 7 mean train loss: [1.048511]
Epoch 7/400=>  train_loss: [1.048511], iou: nan, cd: 4.109645114349781, test_mse: [1.3853972]
CORRECT PROGRAMS: 9314
batch 0 train loss: [0.9758559]
batch 1 train loss: [1.030588]
batch 2 train loss: [0.90632164]
batch 3 train loss: [0.9879249]
batch 4 train loss: [0.97967845]
batch 5 train loss: [0.9060929]
batch 6 train loss: [1.0026817]
batch 7 train loss: [0.9264613]
batch 8 train loss: [0.89978456]
batch 9 train loss: [0.982705]
batch 10 train loss: [0.8086493]
batch 11 train loss: [0.9999391]
batch 12 train loss: [0.96971285]
batch 13 train loss: [0.8918878]
batch 14 train loss: [0.9711199]
batch 15 train loss: [1.0665778]
batch 16 train loss: [1.1178081]
batch 17 train loss: [0.9342625]
batch 18 train loss: [1.0544771]
batch 19 train loss: [0.8996005]
batch 20 train loss: [1.061435]
batch 21 train loss: [0.9172107]
batch 22 train loss: [1.0171273]
batch 23 train loss: [0.9833546]
batch 24 train loss: [1.0070041]
batch 25 train loss: [0.91198355]
batch 26 train loss: [0.96959794]
batch 27 train loss: [0.96367586]
batch 28 train loss: [0.99454457]
batch 29 train loss: [0.9414599]
batch 30 train loss: [0.9813506]
batch 31 train loss: [1.0659678]
batch 32 train loss: [1.171514]
batch 33 train loss: [1.1398019]
batch 34 train loss: [0.9857373]
batch 35 train loss: [1.0576925]
batch 36 train loss: [0.9839916]
batch 37 train loss: [1.1177682]
batch 38 train loss: [1.0254105]
batch 39 train loss: [0.912574]
batch 40 train loss: [1.1063083]
batch 41 train loss: [0.89647406]
batch 42 train loss: [1.0685166]
batch 43 train loss: [0.97952527]
batch 44 train loss: [1.0233613]
batch 45 train loss: [0.97253823]
batch 46 train loss: [0.96159893]
batch 47 train loss: [1.0371149]
batch 48 train loss: [0.96142787]
batch 49 train loss: [1.0515207]
batch 50 train loss: [0.9119271]
batch 51 train loss: [1.0407336]
batch 52 train loss: [1.0000002]
batch 53 train loss: [1.0741895]
batch 54 train loss: [0.9656258]
batch 55 train loss: [0.9870367]
batch 56 train loss: [0.98340356]
batch 57 train loss: [1.0232481]
batch 58 train loss: [0.97829133]
batch 59 train loss: [0.87461853]
batch 60 train loss: [0.9467187]
batch 61 train loss: [0.9696432]
batch 62 train loss: [0.9578663]
batch 63 train loss: [1.1097946]
batch 64 train loss: [1.0132542]
batch 65 train loss: [1.0235386]
batch 66 train loss: [1.013111]
batch 67 train loss: [1.0283725]
batch 68 train loss: [0.8709738]
batch 69 train loss: [0.9962393]
batch 70 train loss: [1.0856864]
batch 71 train loss: [1.027251]
batch 72 train loss: [1.0338824]
batch 73 train loss: [0.986448]
batch 74 train loss: [0.93926626]
batch 75 train loss: [1.0110835]
batch 76 train loss: [1.115919]
batch 77 train loss: [1.0453792]
batch 78 train loss: [0.95019394]
batch 79 train loss: [0.9731891]
batch 80 train loss: [0.96555525]
batch 81 train loss: [1.0282599]
batch 82 train loss: [0.9230093]
batch 83 train loss: [0.9879282]
batch 84 train loss: [0.97191954]
batch 85 train loss: [1.0884268]
batch 86 train loss: [1.0327934]
batch 87 train loss: [0.9702166]
batch 88 train loss: [0.94517905]
batch 89 train loss: [0.96156514]
batch 90 train loss: [1.043091]
batch 91 train loss: [1.0009556]
batch 92 train loss: [1.0885013]
batch 93 train loss: [1.0959566]
batch 94 train loss: [1.0061331]
batch 95 train loss: [1.0343306]
batch 96 train loss: [1.1202785]
batch 97 train loss: [1.1442717]
batch 98 train loss: [1.032933]
batch 99 train loss: [1.0841253]
epoch 8 mean train loss: [1.0004203]
Epoch 8/400=>  train_loss: [1.0004203], iou: nan, cd: 4.178998688526469, test_mse: [1.3947961]
CORRECT PROGRAMS: 9314
batch 0 train loss: [0.9402483]
batch 1 train loss: [0.9118333]
batch 2 train loss: [0.95742154]
batch 3 train loss: [0.8963401]
batch 4 train loss: [0.9215892]
batch 5 train loss: [0.9811042]
batch 6 train loss: [0.820483]
batch 7 train loss: [0.9305619]
batch 8 train loss: [0.82951206]
batch 9 train loss: [0.9168693]
batch 10 train loss: [0.988356]
batch 11 train loss: [0.9856116]
batch 12 train loss: [0.93544793]
batch 13 train loss: [0.9260877]
batch 14 train loss: [0.9463164]
batch 15 train loss: [0.8350581]
batch 16 train loss: [0.8990741]
batch 17 train loss: [0.9239901]
batch 18 train loss: [0.920321]
batch 19 train loss: [1.0218391]
batch 20 train loss: [0.88523495]
batch 21 train loss: [1.0370636]
batch 22 train loss: [0.80389893]
batch 23 train loss: [0.9240669]
batch 24 train loss: [0.8417108]
batch 25 train loss: [0.9412592]
batch 26 train loss: [0.9176822]
batch 27 train loss: [0.9026221]
batch 28 train loss: [0.85730535]
batch 29 train loss: [0.965526]
batch 30 train loss: [0.89197314]
batch 31 train loss: [0.9634496]
batch 32 train loss: [0.9779979]
batch 33 train loss: [0.96642417]
batch 34 train loss: [0.8923242]
batch 35 train loss: [0.93046165]
batch 36 train loss: [0.919731]
batch 37 train loss: [1.001271]
batch 38 train loss: [0.9191914]
batch 39 train loss: [1.0036424]
batch 40 train loss: [1.0018864]
batch 41 train loss: [0.82072484]
batch 42 train loss: [1.0263119]
batch 43 train loss: [1.0154057]
batch 44 train loss: [0.9358135]
batch 45 train loss: [0.9557854]
batch 46 train loss: [0.974219]
batch 47 train loss: [0.98530275]
batch 48 train loss: [0.8959523]
batch 49 train loss: [1.0721966]
batch 50 train loss: [1.0424012]
batch 51 train loss: [0.8675753]
batch 52 train loss: [1.097333]
batch 53 train loss: [1.0297482]
batch 54 train loss: [1.0150247]
batch 55 train loss: [1.055116]
batch 56 train loss: [0.8504556]
batch 57 train loss: [0.98469925]
batch 58 train loss: [0.89423853]
batch 59 train loss: [0.88328385]
batch 60 train loss: [0.9305215]
batch 61 train loss: [0.92845875]
batch 62 train loss: [0.9960146]
batch 63 train loss: [0.89269614]
batch 64 train loss: [0.97208714]
batch 65 train loss: [0.9589014]
batch 66 train loss: [0.9309934]
batch 67 train loss: [0.9770416]
batch 68 train loss: [0.8937729]
batch 69 train loss: [1.0337723]
batch 70 train loss: [0.94886476]
batch 71 train loss: [0.97456574]
batch 72 train loss: [1.0713828]
batch 73 train loss: [1.0145364]
batch 74 train loss: [1.0322504]
batch 75 train loss: [1.0250365]
batch 76 train loss: [0.9921977]
batch 77 train loss: [1.0634501]
batch 78 train loss: [0.9581683]
batch 79 train loss: [1.0426567]
batch 80 train loss: [0.9338339]
batch 81 train loss: [0.99457633]
batch 82 train loss: [0.9597771]
batch 83 train loss: [0.97843516]
batch 84 train loss: [0.9656272]
batch 85 train loss: [1.042062]
batch 86 train loss: [0.9319894]
batch 87 train loss: [0.93700755]
batch 88 train loss: [0.95364845]
batch 89 train loss: [0.9131764]
batch 90 train loss: [1.0502734]
batch 91 train loss: [0.92030597]
batch 92 train loss: [0.87892294]
batch 93 train loss: [0.8940497]
batch 94 train loss: [0.9739424]
batch 95 train loss: [1.0922798]
batch 96 train loss: [0.9982844]
batch 97 train loss: [0.9799002]
batch 98 train loss: [1.065897]
batch 99 train loss: [1.0441206]
epoch 9 mean train loss: [0.95579845]
WAKE SLEEP ITERATION 1
Inferring cad batch: 0
Inferring cad batch: 1
Inferring cad batch: 2
Inferring cad batch: 3
Inferring cad batch: 4
Inferring cad batch: 5
Inferring cad batch: 6
Inferring cad batch: 7
Inferring cad batch: 8
Inferring cad batch: 9
Inferring cad batch: 10
Inferring cad batch: 11
Inferring cad batch: 12
Inferring cad batch: 13
Inferring cad batch: 14
Inferring cad batch: 15
Inferring cad batch: 16
Inferring cad batch: 17
Inferring cad batch: 18
Inferring cad batch: 19
Inferring cad batch: 20
Inferring cad batch: 21
Inferring cad batch: 22
Inferring cad batch: 23
Inferring cad batch: 24
Inferring cad batch: 25
Inferring cad batch: 26
Inferring cad batch: 27
Inferring cad batch: 28
Inferring cad batch: 29
Inferring cad batch: 30
Inferring cad batch: 31
Inferring cad batch: 32
Inferring cad average chamfer distance: 1.6844365765537344
0.5363018282912344 1.6844365765537344
generator epoch 0 loss: 2.0080143798828125                 accuracy: 0.7607142925262451
generator epoch 1 loss: 1.7586238037109374                 accuracy: 0.7614285349845886
generator epoch 2 loss: 1.644276918247768                 accuracy: 0.8071428537368774
generator epoch 3 loss: 1.5735661830357144                 accuracy: 0.8035714030265808
generator epoch 4 loss: 1.5195345825195312                 accuracy: 0.7892857193946838
generator epoch 5 loss: 1.4797781441824778                 accuracy: 0.800000011920929
generator epoch 6 loss: 1.4455076546805246                 accuracy: 0.824999988079071
generator epoch 7 loss: 1.4197146902901785                 accuracy: 0.7799999713897705
generator epoch 8 loss: 1.39482810320173                 accuracy: 0.8235714435577393
generator epoch 9 loss: 1.37319211164202                 accuracy: 0.8221428394317627
generator epoch 10 loss: 1.3521918683733258                 accuracy: 0.8149999976158142
generator epoch 11 loss: 1.3369813276018414                 accuracy: 0.8428571224212646
generator epoch 12 loss: 1.33023498273577                 accuracy: 0.8207142949104309
generator epoch 13 loss: 1.307487158203125                 accuracy: 0.8064285516738892
generator epoch 14 loss: 1.2952067853655134                 accuracy: 0.8257142901420593
generator epoch 15 loss: 1.292190936279297                 accuracy: 0.8378571271896362
generator epoch 16 loss: 1.2763127624511719                 accuracy: 0.8278571367263794
generator epoch 17 loss: 1.2677899788992746                 accuracy: 0.8535714149475098
generator epoch 18 loss: 1.2566955636160715                 accuracy: 0.8535714149475098
generator epoch 19 loss: 1.2449264055524554                 accuracy: 0.8564285635948181
generator epoch 20 loss: 1.2370674979073661                 accuracy: 0.8442857265472412
generator epoch 21 loss: 1.229906907435826                 accuracy: 0.824999988079071
generator epoch 22 loss: 1.2330461582728796                 accuracy: 0.8392857313156128
generator epoch 23 loss: 1.2176692452566964                 accuracy: 0.845714271068573
generator epoch 24 loss: 1.2090349687848772                 accuracy: 0.8550000190734863
generator epoch 25 loss: 1.2128605006626674                 accuracy: 0.8535714149475098
generator epoch 26 loss: 1.2052831255231584                 accuracy: 0.8550000190734863
generator epoch 27 loss: 1.1931340026855468                 accuracy: 0.8464285731315613
generator epoch 28 loss: 1.1903311357770647                 accuracy: 0.8485714197158813
generator epoch 29 loss: 1.1836507969447545                 accuracy: 0.8357142806053162
generator epoch 30 loss: 1.176287962123326                 accuracy: 0.8707142472267151
generator epoch 31 loss: 1.1746401602608818                 accuracy: 0.8378571271896362
generator epoch 32 loss: 1.170380335344587                 accuracy: 0.8442857265472412
generator epoch 33 loss: 1.1651309674944197                 accuracy: 0.8628571629524231
generator epoch 34 loss: 1.1647811279296876                 accuracy: 0.8592857122421265
generator epoch 35 loss: 1.16129857875279                 accuracy: 0.824999988079071
generator epoch 36 loss: 1.1568963108607702                 accuracy: 0.8600000143051147
generator epoch 37 loss: 1.1490093252999443                 accuracy: 0.8657142519950867
generator epoch 38 loss: 1.1472797119140625                 accuracy: 0.8550000190734863
generator epoch 39 loss: 1.1441082205636162                 accuracy: 0.8999999761581421
generator epoch 40 loss: 1.1410060198102678                 accuracy: 0.8621428608894348
generator epoch 41 loss: 1.1368840070452009                 accuracy: 0.8499999642372131
generator epoch 42 loss: 1.1309078709193638                 accuracy: 0.8671428561210632
generator epoch 43 loss: 1.1332932259695871                 accuracy: 0.8778571486473083
generator epoch 44 loss: 1.127850892857143                 accuracy: 0.8707142472267151
generator epoch 45 loss: 1.1297364615304128                 accuracy: 0.8678571581840515
generator epoch 46 loss: 1.120573957170759                 accuracy: 0.8635714054107666
generator epoch 47 loss: 1.1217520211356027                 accuracy: 0.8600000143051147
generator epoch 48 loss: 1.1178609941755022                 accuracy: 0.8864285349845886
generator epoch 49 loss: 1.1123363891601563                 accuracy: 0.8378571271896362
generator epoch 50 loss: 1.1139700265066965                 accuracy: 0.8799999952316284
generator epoch 51 loss: 1.110302250453404                 accuracy: 0.8550000190734863
generator epoch 52 loss: 1.1083171316964286                 accuracy: 0.8564285635948181
generator epoch 53 loss: 1.1060964390345982                 accuracy: 0.8592857122421265
generator epoch 54 loss: 1.0971909868512835                 accuracy: 0.8692857027053833
generator epoch 55 loss: 1.1003288382393974                 accuracy: 0.8700000047683716
generator epoch 56 loss: 1.1009943010602679                 accuracy: 0.8714285492897034
generator epoch 57 loss: 1.093939967564174                 accuracy: 0.8642857074737549
generator epoch 58 loss: 1.0932641531808036                 accuracy: 0.8735713958740234
generator epoch 59 loss: 1.0951698617117747                 accuracy: 0.8757143020629883
generator epoch 60 loss: 1.0885294032505581                 accuracy: 0.8464285731315613
generator epoch 61 loss: 1.0896587480817523                 accuracy: 0.8621428608894348
generator epoch 62 loss: 1.0862005955287388                 accuracy: 0.895714282989502
generator epoch 63 loss: 1.0870315333775111                 accuracy: 0.868571400642395
generator epoch 64 loss: 1.081895365687779                 accuracy: 0.8771428465843201
generator epoch 65 loss: 1.0831597630092076                 accuracy: 0.8821428418159485
generator epoch 66 loss: 1.080082821219308                 accuracy: 0.8399999737739563
generator epoch 67 loss: 1.0757750994001116                 accuracy: 0.8914285898208618
generator epoch 68 loss: 1.0809481942313057                 accuracy: 0.8899999856948853
generator epoch 69 loss: 1.078588103376116                 accuracy: 0.8778571486473083
generator epoch 70 loss: 1.074679430280413                 accuracy: 0.9028571248054504
generator epoch 71 loss: 1.067504323904855                 accuracy: 0.8778571486473083
generator epoch 72 loss: 1.0699697596958706                 accuracy: 0.8857142925262451
generator epoch 73 loss: 1.0732485961914062                 accuracy: 0.8650000095367432
generator epoch 74 loss: 1.069827743966239                 accuracy: 0.8492857217788696
generator epoch 75 loss: 1.065754012625558                 accuracy: 0.9014285802841187
generator epoch 76 loss: 1.0658001944405693                 accuracy: 0.8671428561210632
generator epoch 77 loss: 1.062749365234375                 accuracy: 0.8842856884002686
generator epoch 78 loss: 1.0597373578752791                 accuracy: 0.8742856979370117
generator epoch 79 loss: 1.0609266026088169                 accuracy: 0.8785713911056519
generator epoch 80 loss: 1.059743506731306                 accuracy: 0.8678571581840515
generator epoch 81 loss: 1.0551395359584264                 accuracy: 0.8907142877578735
generator epoch 82 loss: 1.0517441859654018                 accuracy: 0.8807142972946167
generator epoch 83 loss: 1.0549591291155134                 accuracy: 0.8857142925262451
generator epoch 84 loss: 1.051616535295759                 accuracy: 0.8857142925262451
generator epoch 85 loss: 1.0539419599260602                 accuracy: 0.8799999952316284
generator epoch 86 loss: 1.0524562220982143                 accuracy: 0.8721428513526917
generator epoch 87 loss: 1.0520480224609374                 accuracy: 0.8914285898208618
generator epoch 88 loss: 1.052843465750558                 accuracy: 0.8942856788635254
generator epoch 89 loss: 1.0482091500418527                 accuracy: 0.8949999809265137
generator epoch 90 loss: 1.0466654070172992                 accuracy: 0.8792856931686401
generator epoch 91 loss: 1.0471435974121093                 accuracy: 0.8757143020629883
generator epoch 92 loss: 1.0455568559919084                 accuracy: 0.9014285802841187
generator epoch 93 loss: 1.0402561235700334                 accuracy: 0.8778571486473083
generator epoch 94 loss: 1.043869548688616                 accuracy: 0.9021428227424622
generator epoch 95 loss: 1.036503555733817                 accuracy: 0.8878571391105652
generator epoch 96 loss: 1.0405902596609933                 accuracy: 0.8921428322792053
generator epoch 97 loss: 1.0411332685198103                 accuracy: 0.8899999856948853
generator epoch 98 loss: 1.0386811994280134                 accuracy: 0.883571445941925
generator epoch 99 loss: 1.0364695504324777                 accuracy: 0.883571445941925
generator epoch 100 loss: 1.0394734697614398                 accuracy: 0.8821428418159485
generator epoch 101 loss: 1.0351564060756138                 accuracy: 0.889285683631897
generator epoch 102 loss: 1.0364333592006139                 accuracy: 0.8999999761581421
generator epoch 103 loss: 1.0326319989885602                 accuracy: 0.9021428227424622
generator epoch 104 loss: 1.0329658368791852                 accuracy: 0.8799999952316284
generator epoch 105 loss: 1.030133114188058                 accuracy: 0.8985714316368103
generator epoch 106 loss: 1.0293872079031807                 accuracy: 0.8964285850524902
generator epoch 107 loss: 1.029255557686942                 accuracy: 0.9035714268684387
generator epoch 108 loss: 1.0295171683175224                 accuracy: 0.8642857074737549
generator epoch 109 loss: 1.0292225786481586                 accuracy: 0.8757143020629883
generator epoch 110 loss: 1.0309814261300223                 accuracy: 0.8907142877578735
generator epoch 111 loss: 1.0272155395507812                 accuracy: 0.8971428275108337
generator epoch 112 loss: 1.0186067225864954                 accuracy: 0.8742856979370117
generator epoch 113 loss: 1.02019724382673                 accuracy: 0.8628571629524231
generator epoch 114 loss: 1.029499143763951                 accuracy: 0.8864285349845886
generator epoch 115 loss: 1.0198730268205916                 accuracy: 0.8871428370475769
generator epoch 116 loss: 1.0232846923828125                 accuracy: 0.8899999856948853
generator epoch 117 loss: 1.0293778730119978                 accuracy: 0.8857142925262451
generator epoch 118 loss: 1.018102685546875                 accuracy: 0.8871428370475769
generator epoch 119 loss: 1.0142460457938058                 accuracy: 0.8935714364051819
generator epoch 120 loss: 1.0227786778041295                 accuracy: 0.9014285802841187
generator epoch 121 loss: 1.0164208417619978                 accuracy: 0.8971428275108337
generator epoch 122 loss: 1.0162273428780693                 accuracy: 0.904285728931427
generator epoch 123 loss: 1.0157038051060268                 accuracy: 0.918571412563324
generator epoch 124 loss: 1.0165064130510604                 accuracy: 0.8849999904632568
generator epoch 125 loss: 1.0124076154436383                 accuracy: 0.8942856788635254
generator epoch 126 loss: 1.014752227783203                 accuracy: 0.9035714268684387
generator epoch 127 loss: 1.0126627162388393                 accuracy: 0.9071428179740906
generator epoch 128 loss: 1.0080761282784598                 accuracy: 0.9028571248054504
generator epoch 129 loss: 1.0109438145228795                 accuracy: 0.8992857336997986
generator epoch 130 loss: 1.006598237827846                 accuracy: 0.9107142686843872
generator epoch 131 loss: 1.0029915230887276                 accuracy: 0.883571445941925
generator epoch 132 loss: 1.0079107718331473                 accuracy: 0.8999999761581421
generator epoch 133 loss: 1.0059927124023438                 accuracy: 0.9021428227424622
generator epoch 134 loss: 1.0035130249023438                 accuracy: 0.9121428728103638
generator epoch 135 loss: 1.0049649213518415                 accuracy: 0.8928571343421936
generator epoch 136 loss: 1.0071081316266741                 accuracy: 0.8857142925262451
generator epoch 137 loss: 1.0055453552246094                 accuracy: 0.895714282989502
generator epoch 138 loss: 1.007209664481027                 accuracy: 0.9157142639160156
generator epoch 139 loss: 1.0062963282993862                 accuracy: 0.9192857146263123
generator epoch 140 loss: 1.0038573503766741                 accuracy: 0.9028571248054504
generator epoch 141 loss: 0.9970822483607701                 accuracy: 0.9078571200370789
generator epoch 142 loss: 1.0005833653041294                 accuracy: 0.9057142734527588
generator epoch 143 loss: 1.0014525460379464                 accuracy: 0.9021428227424622
generator epoch 144 loss: 1.0066459237234933                 accuracy: 0.897857129573822
generator epoch 145 loss: 1.0025822387695313                 accuracy: 0.9149999618530273
generator epoch 146 loss: 1.0021548418317523                 accuracy: 0.9107142686843872
generator epoch 147 loss: 0.9972878714425223                 accuracy: 0.9092857241630554
generator epoch 148 loss: 0.9991883082798549                 accuracy: 0.8964285850524902
generator epoch 149 loss: 0.9980901532854353                 accuracy: 0.8964285850524902
generator epoch 150 loss: 0.9919228934151786                 accuracy: 0.9164285659790039
generator epoch 151 loss: 0.9974020577566964                 accuracy: 0.8764285445213318
generator epoch 152 loss: 0.9969125784737723                 accuracy: 0.918571412563324
generator epoch 153 loss: 1.0017969700404576                 accuracy: 0.895714282989502
generator epoch 154 loss: 0.9972438546316964                 accuracy: 0.8907142877578735
generator epoch 155 loss: 0.9946660609654018                 accuracy: 0.9064285755157471
generator epoch 156 loss: 0.996026766531808                 accuracy: 0.9021428227424622
generator epoch 157 loss: 0.9952854832240513                 accuracy: 0.8885714411735535
generator epoch 158 loss: 0.9872694536481584                 accuracy: 0.9021428227424622
generator epoch 159 loss: 0.9925023943219866                 accuracy: 0.9214285612106323
generator epoch 160 loss: 0.9961584123883929                 accuracy: 0.9057142734527588
generator epoch 161 loss: 0.9924193481445313                 accuracy: 0.8885714411735535
generator epoch 162 loss: 0.9853748151506696                 accuracy: 0.8935714364051819
generator epoch 163 loss: 0.9857409075055804                 accuracy: 0.8871428370475769
generator epoch 164 loss: 0.9892805097307478                 accuracy: 0.8849999904632568
generator epoch 165 loss: 0.9820499843052455                 accuracy: 0.8928571343421936
generator epoch 166 loss: 0.9898401759556361                 accuracy: 0.8871428370475769
generator epoch 167 loss: 0.9843005885532924                 accuracy: 0.8999999761581421
generator epoch 168 loss: 0.989944437953404                 accuracy: 0.8792856931686401
generator epoch 169 loss: 0.9884454973493304                 accuracy: 0.9057142734527588
generator epoch 170 loss: 0.9827455732073103                 accuracy: 0.9221428632736206
generator epoch 171 loss: 0.9857359357561384                 accuracy: 0.897857129573822
generator epoch 172 loss: 0.9856293239048549                 accuracy: 0.8971428275108337
generator epoch 173 loss: 0.981862983921596                 accuracy: 0.897857129573822
generator epoch 174 loss: 0.9830715253557478                 accuracy: 0.9064285755157471
generator epoch 175 loss: 0.9804086887904576                 accuracy: 0.9028571248054504
generator epoch 176 loss: 0.9817928789411272                 accuracy: 0.9228571057319641
generator epoch 177 loss: 0.9771333234514509                 accuracy: 0.9114285707473755
generator epoch 178 loss: 0.9823595912388393                 accuracy: 0.8935714364051819
generator epoch 179 loss: 0.9866646248953683                 accuracy: 0.904285728931427
generator epoch 180 loss: 0.9802855651855469                 accuracy: 0.9264285564422607
generator epoch 181 loss: 0.9798039768763951                 accuracy: 0.9078571200370789
generator epoch 182 loss: 0.9823047581263951                 accuracy: 0.9035714268684387
generator epoch 183 loss: 0.9784072675432478                 accuracy: 0.9142857193946838
generator epoch 184 loss: 0.9808587969098772                 accuracy: 0.8914285898208618
generator epoch 185 loss: 0.9793157479422433                 accuracy: 0.9192857146263123
generator epoch 186 loss: 0.977548859514509                 accuracy: 0.9092857241630554
generator epoch 187 loss: 0.9792250627790179                 accuracy: 0.9057142734527588
generator epoch 188 loss: 0.9758047607421875                 accuracy: 0.9049999713897705
generator epoch 189 loss: 0.9771680018833705                 accuracy: 0.904285728931427
generator epoch 190 loss: 0.9769662257603237                 accuracy: 0.904285728931427
generator epoch 191 loss: 0.9750644635881697                 accuracy: 0.9278571605682373
generator epoch 192 loss: 0.9782796691894531                 accuracy: 0.9192857146263123
generator epoch 193 loss: 0.9771410103934152                 accuracy: 0.8992857336997986
generator epoch 194 loss: 0.9755138959612165                 accuracy: 0.9235714077949524
generator epoch 195 loss: 0.977269917515346                 accuracy: 0.9242857098579407
generator epoch 196 loss: 0.9750774196079799                 accuracy: 0.9107142686843872
generator epoch 197 loss: 0.9730005667550223                 accuracy: 0.8899999856948853
generator epoch 198 loss: 0.9694872410365514                 accuracy: 0.9242857098579407
generator epoch 199 loss: 0.973453400530134                 accuracy: 0.9142857193946838
generator epoch 200 loss: 0.9691247314453125                 accuracy: 0.9171428680419922
generator epoch 201 loss: 0.9667347891671317                 accuracy: 0.9078571200370789
generator epoch 202 loss: 0.9735329014369419                 accuracy: 0.8999999761581421
generator epoch 203 loss: 0.971150679234096                 accuracy: 0.9221428632736206
generator epoch 204 loss: 0.9713988490513393                 accuracy: 0.9121428728103638
generator epoch 205 loss: 0.9705145098005022                 accuracy: 0.8985714316368103
generator epoch 206 loss: 0.9692177978515625                 accuracy: 0.9242857098579407
generator epoch 207 loss: 0.9676713902064732                 accuracy: 0.9121428728103638
generator epoch 208 loss: 0.9690131356375558                 accuracy: 0.9200000166893005
generator epoch 209 loss: 0.9668307713099888                 accuracy: 0.918571412563324
generator epoch 210 loss: 0.9701340959821428                 accuracy: 0.920714259147644
generator epoch 211 loss: 0.9621657566615514                 accuracy: 0.9128571152687073
generator epoch 212 loss: 0.9672541913713728                 accuracy: 0.9014285802841187
generator epoch 213 loss: 0.9641536830357142                 accuracy: 0.9142857193946838
generator epoch 214 loss: 0.9682667977469308                 accuracy: 0.9064285755157471
generator epoch 215 loss: 0.9667313284737723                 accuracy: 0.9085714221000671
generator epoch 216 loss: 0.9726931640625                 accuracy: 0.8942856788635254
generator epoch 217 loss: 0.9693543535505023                 accuracy: 0.9171428680419922
generator epoch 218 loss: 0.9664558628627232                 accuracy: 0.9135714173316956
generator epoch 219 loss: 0.9715892935616629                 accuracy: 0.9164285659790039
generator epoch 220 loss: 0.9691964556012835                 accuracy: 0.9099999666213989
generator epoch 221 loss: 0.9636112139020647                 accuracy: 0.9107142686843872
generator epoch 222 loss: 0.9660063214983259                 accuracy: 0.927142858505249
generator epoch 223 loss: 0.9675196759905134                 accuracy: 0.9385713934898376
generator epoch 224 loss: 0.9622969735281808                 accuracy: 0.918571412563324
generator epoch 225 loss: 0.9629474452427456                 accuracy: 0.9228571057319641
generator epoch 226 loss: 0.9610931161063058                 accuracy: 0.9214285612106323
generator epoch 227 loss: 0.9610111537388393                 accuracy: 0.9278571605682373
generator epoch 228 loss: 0.9638742963518415                 accuracy: 0.9107142686843872
generator epoch 229 loss: 0.9590522853306361                 accuracy: 0.925000011920929
generator epoch 230 loss: 0.9580046561104911                 accuracy: 0.9200000166893005
generator epoch 231 loss: 0.9585273847307477                 accuracy: 0.9278571605682373
generator epoch 232 loss: 0.9566063677106584                 accuracy: 0.9099999666213989
generator epoch 233 loss: 0.9653069100516183                 accuracy: 0.9099999666213989
generator epoch 234 loss: 0.9606613630022321                 accuracy: 0.9121428728103638
generator epoch 235 loss: 0.9556005048479352                 accuracy: 0.9228571057319641
generator epoch 236 loss: 0.950991836983817                 accuracy: 0.9399999976158142
generator epoch 237 loss: 0.9595710885184152                 accuracy: 0.9014285802841187
generator epoch 238 loss: 0.9583298078264509                 accuracy: 0.9200000166893005
generator epoch 239 loss: 0.9522079511369977                 accuracy: 0.904285728931427
generator epoch 240 loss: 0.9579837724958147                 accuracy: 0.904285728931427
generator epoch 241 loss: 0.957562890625                 accuracy: 0.9235714077949524
generator epoch 242 loss: 0.9564164350237165                 accuracy: 0.9085714221000671
generator epoch 243 loss: 0.9546008754185268                 accuracy: 0.9092857241630554
generator epoch 244 loss: 0.9557876220703125                 accuracy: 0.9107142686843872
generator epoch 245 loss: 0.9583015956333706                 accuracy: 0.9221428632736206
generator epoch 246 loss: 0.9530234017508371                 accuracy: 0.9049999713897705
generator epoch 247 loss: 0.9577053981236049                 accuracy: 0.9285714030265808
generator epoch 248 loss: 0.950045183454241                 accuracy: 0.9257142543792725
generator epoch 249 loss: 0.9542321803501674                 accuracy: 0.925000011920929
generator epoch 250 loss: 0.953922354561942                 accuracy: 0.9335713982582092
generator epoch 251 loss: 0.9540908176967076                 accuracy: 0.9321428537368774
generator epoch 252 loss: 0.9566092450823103                 accuracy: 0.9192857146263123
generator epoch 253 loss: 0.9575378784179688                 accuracy: 0.9099999666213989
generator epoch 254 loss: 0.9504063746861049                 accuracy: 0.9314285516738892
generator epoch 255 loss: 0.9513625662667411                 accuracy: 0.925000011920929
generator epoch 256 loss: 0.9575678397042411                 accuracy: 0.9035714268684387
generator epoch 257 loss: 0.9527213248116629                 accuracy: 0.9192857146263123
generator epoch 258 loss: 0.9549498291015625                 accuracy: 0.9242857098579407
generator epoch 259 loss: 0.9512130519321986                 accuracy: 0.9007142782211304
generator epoch 260 loss: 0.9543308157784598                 accuracy: 0.9107142686843872
generator epoch 261 loss: 0.948853547014509                 accuracy: 0.9078571200370789
generator epoch 262 loss: 0.9511754176548549                 accuracy: 0.9228571057319641
generator epoch 263 loss: 0.9515693202427455                 accuracy: 0.9392856955528259
generator epoch 264 loss: 0.9459279087611607                 accuracy: 0.9314285516738892
generator epoch 265 loss: 0.9523503836495536                 accuracy: 0.9071428179740906
generator epoch 266 loss: 0.9471925432477678                 accuracy: 0.9071428179740906
generator epoch 267 loss: 0.9499104509626116                 accuracy: 0.918571412563324
generator epoch 268 loss: 0.9510357709612165                 accuracy: 0.9357143044471741
generator epoch 269 loss: 0.9516753932407924                 accuracy: 0.9107142686843872
generator epoch 270 loss: 0.9500479317801339                 accuracy: 0.9385713934898376
generator epoch 271 loss: 0.9518710632324219                 accuracy: 0.9242857098579407
generator epoch 272 loss: 0.9496431073869978                 accuracy: 0.9314285516738892
generator epoch 273 loss: 0.9451917271205357                 accuracy: 0.9321428537368774
generator epoch 274 loss: 0.9425540910993303                 accuracy: 0.9178571105003357
generator epoch 275 loss: 0.9500045671735491                 accuracy: 0.9264285564422607
generator epoch 276 loss: 0.9476463431222099                 accuracy: 0.918571412563324
generator epoch 277 loss: 0.9473920724051339                 accuracy: 0.9228571057319641
generator epoch 278 loss: 0.9509937770298549                 accuracy: 0.9200000166893005
generator epoch 279 loss: 0.9486932582310268                 accuracy: 0.9099999666213989
generator epoch 280 loss: 0.9408839015415736                 accuracy: 0.925000011920929
generator epoch 281 loss: 0.943176163155692                 accuracy: 0.9121428728103638
generator epoch 282 loss: 0.9451912876674107                 accuracy: 0.9114285707473755
generator epoch 283 loss: 0.9481141462053572                 accuracy: 0.9071428179740906
generator epoch 284 loss: 0.9441541094098772                 accuracy: 0.9342857003211975
generator epoch 285 loss: 0.9470214991978236                 accuracy: 0.920714259147644
generator epoch 286 loss: 0.9475677638462612                 accuracy: 0.9178571105003357
generator epoch 287 loss: 0.94502314453125                 accuracy: 0.9292857050895691
generator epoch 288 loss: 0.9483989510672433                 accuracy: 0.9157142639160156
generator epoch 289 loss: 0.9376762756347656                 accuracy: 0.9078571200370789
generator epoch 290 loss: 0.9435198617117746                 accuracy: 0.9307142496109009
generator epoch 291 loss: 0.9530038809640067                 accuracy: 0.9235714077949524
generator epoch 292 loss: 0.946928413609096                 accuracy: 0.9350000023841858
generator epoch 293 loss: 0.9393152640206474                 accuracy: 0.9257142543792725
generator epoch 294 loss: 0.9434366411481585                 accuracy: 0.925000011920929
generator epoch 295 loss: 0.9393758754185267                 accuracy: 0.9385713934898376
generator epoch 296 loss: 0.9395564078194755                 accuracy: 0.9428571462631226
generator epoch 297 loss: 0.9471219674246651                 accuracy: 0.925000011920929
generator epoch 298 loss: 0.9380313685825893                 accuracy: 0.9442856907844543
generator epoch 299 loss: 0.9454193420410156                 accuracy: 0.9192857146263123
generator epoch 300 loss: 0.9418002702985491                 accuracy: 0.9171428680419922
generator epoch 301 loss: 0.9468085414341518                 accuracy: 0.9192857146263123
generator epoch 302 loss: 0.9361958234514509                 accuracy: 0.9221428632736206
generator epoch 303 loss: 0.9409749276297433                 accuracy: 0.9335713982582092
generator epoch 304 loss: 0.9434803737095424                 accuracy: 0.9171428680419922
generator epoch 305 loss: 0.9413390598842076                 accuracy: 0.9335713982582092
generator epoch 306 loss: 0.9379446585518973                 accuracy: 0.9278571605682373
generator epoch 307 loss: 0.9435123997279576                 accuracy: 0.9178571105003357
generator epoch 308 loss: 0.9403410714285714                 accuracy: 0.9307142496109009
generator epoch 309 loss: 0.937656214250837                 accuracy: 0.9114285707473755
generator epoch 310 loss: 0.9359155465262277                 accuracy: 0.9307142496109009
generator epoch 311 loss: 0.9373644818987166                 accuracy: 0.9235714077949524
generator epoch 312 loss: 0.9436524553571428                 accuracy: 0.9178571105003357
generator epoch 313 loss: 0.9428247270856585                 accuracy: 0.9257142543792725
generator epoch 314 loss: 0.9376329424176897                 accuracy: 0.9321428537368774
generator epoch 315 loss: 0.9416104901994977                 accuracy: 0.9214285612106323
generator epoch 316 loss: 0.9399774788992745                 accuracy: 0.9192857146263123
generator epoch 317 loss: 0.9454551121303013                 accuracy: 0.9264285564422607
generator epoch 318 loss: 0.9398457153320312                 accuracy: 0.9092857241630554
generator epoch 319 loss: 0.9356672476632254                 accuracy: 0.9192857146263123
generator epoch 320 loss: 0.9382259756905692                 accuracy: 0.9350000023841858
generator epoch 321 loss: 0.9434621433803013                 accuracy: 0.9192857146263123
generator epoch 322 loss: 0.9406937813895089                 accuracy: 0.9342857003211975
generator epoch 323 loss: 0.941050363595145                 accuracy: 0.9107142686843872
generator epoch 324 loss: 0.9359267961774553                 accuracy: 0.9214285612106323
generator epoch 325 loss: 0.9415232177734375                 accuracy: 0.9135714173316956
generator epoch 326 loss: 0.9459563921247209                 accuracy: 0.9264285564422607
generator epoch 327 loss: 0.93897021484375                 accuracy: 0.9328571557998657
generator epoch 328 loss: 0.9359405674525669                 accuracy: 0.9214285612106323
generator epoch 329 loss: 0.93404206804548                 accuracy: 0.9242857098579407
generator epoch 330 loss: 0.9322413818359375                 accuracy: 0.9107142686843872
generator epoch 331 loss: 0.9337551164899554                 accuracy: 0.9114285707473755
generator epoch 332 loss: 0.9353145438058036                 accuracy: 0.9242857098579407
generator epoch 333 loss: 0.9376200483049665                 accuracy: 0.9285714030265808
generator epoch 334 loss: 0.933235808454241                 accuracy: 0.9364285469055176
generator epoch 335 loss: 0.9304259007045201                 accuracy: 0.9171428680419922
generator epoch 336 loss: 0.939403173828125                 accuracy: 0.9371428489685059
generator epoch 337 loss: 0.9334791704450335                 accuracy: 0.9178571105003357
generator epoch 338 loss: 0.933149862234933                 accuracy: 0.9342857003211975
generator epoch 339 loss: 0.9307766566685268                 accuracy: 0.9135714173316956
generator epoch 340 loss: 0.9290022356305804                 accuracy: 0.9328571557998657
generator epoch 341 loss: 0.9397988734654018                 accuracy: 0.9285714030265808
generator epoch 342 loss: 0.9278359043666294                 accuracy: 0.9257142543792725
generator epoch 343 loss: 0.9315735464913505                 accuracy: 0.9235714077949524
generator epoch 344 loss: 0.93880068359375                 accuracy: 0.918571412563324
generator epoch 345 loss: 0.9328953063964843                 accuracy: 0.9350000023841858
generator epoch 346 loss: 0.9256307137625558                 accuracy: 0.925000011920929
generator epoch 347 loss: 0.9331491725376674                 accuracy: 0.927142858505249
generator epoch 348 loss: 0.9351140511648995                 accuracy: 0.9285714030265808
generator epoch 349 loss: 0.936455704171317                 accuracy: 0.9064285755157471
generator epoch 350 loss: 0.9368983136858259                 accuracy: 0.9378571510314941
generator epoch 351 loss: 0.9347157697405134                 accuracy: 0.9314285516738892
generator epoch 352 loss: 0.9347750584193638                 accuracy: 0.9300000071525574
generator epoch 353 loss: 0.9298849809919085                 accuracy: 0.9149999618530273
generator epoch 354 loss: 0.9298362932477678                 accuracy: 0.9300000071525574
generator epoch 355 loss: 0.9267203587123326                 accuracy: 0.9171428680419922
generator epoch 356 loss: 0.9290961233956473                 accuracy: 0.9335713982582092
generator epoch 357 loss: 0.9308838256835937                 accuracy: 0.9385713934898376
generator epoch 358 loss: 0.9319194083077567                 accuracy: 0.9300000071525574
generator epoch 359 loss: 0.9345771048409598                 accuracy: 0.920714259147644
generator epoch 360 loss: 0.926223681640625                 accuracy: 0.9292857050895691
generator epoch 361 loss: 0.9303427481515067                 accuracy: 0.9321428537368774
generator epoch 362 loss: 0.9323560067313058                 accuracy: 0.9214285612106323
generator epoch 363 loss: 0.9345847664969308                 accuracy: 0.9307142496109009
generator epoch 364 loss: 0.9287294067382813                 accuracy: 0.9107142686843872
generator epoch 365 loss: 0.9254928972516742                 accuracy: 0.9157142639160156
generator epoch 366 loss: 0.9281614501953125                 accuracy: 0.9385713934898376
generator epoch 367 loss: 0.9273257245744978                 accuracy: 0.9228571057319641
generator epoch 368 loss: 0.9365876395089285                 accuracy: 0.9264285564422607
generator epoch 369 loss: 0.9332799377441406                 accuracy: 0.9278571605682373
generator epoch 370 loss: 0.9327207336425781                 accuracy: 0.9164285659790039
generator epoch 371 loss: 0.9305891828264509                 accuracy: 0.9085714221000671
generator epoch 372 loss: 0.9332729509626116                 accuracy: 0.9200000166893005
generator epoch 373 loss: 0.9308050598144532                 accuracy: 0.9121428728103638
generator epoch 374 loss: 0.9289039411272322                 accuracy: 0.9350000023841858
generator epoch 375 loss: 0.9277948189871652                 accuracy: 0.9278571605682373
generator epoch 376 loss: 0.9277676086425781                 accuracy: 0.9300000071525574
generator epoch 377 loss: 0.9279733032226563                 accuracy: 0.9107142686843872
generator epoch 378 loss: 0.9221671412876674                 accuracy: 0.925000011920929
generator epoch 379 loss: 0.9315064357212611                 accuracy: 0.9371428489685059
generator epoch 380 loss: 0.9272258483886718                 accuracy: 0.9307142496109009
generator epoch 381 loss: 0.9268785461425781                 accuracy: 0.9392856955528259
generator epoch 382 loss: 0.9260334708077567                 accuracy: 0.9492856860160828
generator epoch 383 loss: 0.9253671037946428                 accuracy: 0.9399999976158142
generator epoch 384 loss: 0.9189363368443081                 accuracy: 0.9321428537368774
generator epoch 385 loss: 0.9285470764160156                 accuracy: 0.9307142496109009
generator epoch 386 loss: 0.9252198922293526                 accuracy: 0.9171428680419922
generator epoch 387 loss: 0.9231428013392857                 accuracy: 0.9142857193946838
generator epoch 388 loss: 0.9265620771135603                 accuracy: 0.9392856955528259
generator epoch 389 loss: 0.9238064906529018                 accuracy: 0.9321428537368774
generator epoch 390 loss: 0.9241486458914621                 accuracy: 0.9314285516738892
generator epoch 391 loss: 0.9291206743512835                 accuracy: 0.9407142996788025
generator epoch 392 loss: 0.921149955531529                 accuracy: 0.9407142996788025
generator epoch 393 loss: 0.9196935355050223                 accuracy: 0.941428542137146
generator epoch 394 loss: 0.9229626229422433                 accuracy: 0.9228571057319641
generator epoch 395 loss: 0.9217905439104352                 accuracy: 0.9392856955528259
generator epoch 396 loss: 0.9216331874302456                 accuracy: 0.9128571152687073
generator epoch 397 loss: 0.9272857631138393                 accuracy: 0.9035714268684387
generator epoch 398 loss: 0.9293001342773437                 accuracy: 0.9421428442001343
generator epoch 399 loss: 0.9233356331961495                 accuracy: 0.9235714077949524
generator epoch 400 loss: 0.9242405709402902                 accuracy: 0.9321428537368774
generator epoch 401 loss: 0.9228102913992745                 accuracy: 0.9178571105003357
generator epoch 402 loss: 0.9238764770507812                 accuracy: 0.9221428632736206
generator epoch 403 loss: 0.9248246477399553                 accuracy: 0.9171428680419922
generator epoch 404 loss: 0.9240147966657366                 accuracy: 0.941428542137146
generator epoch 405 loss: 0.9205409109933036                 accuracy: 0.918571412563324
generator epoch 406 loss: 0.9228440769740514                 accuracy: 0.9178571105003357
generator epoch 407 loss: 0.9262351614815848                 accuracy: 0.9328571557998657
generator epoch 408 loss: 0.9204786481584821                 accuracy: 0.918571412563324
generator epoch 409 loss: 0.9197188799176897                 accuracy: 0.9442856907844543
generator epoch 410 loss: 0.9178421700613839                 accuracy: 0.9292857050895691
generator epoch 411 loss: 0.9189046090262277                 accuracy: 0.9164285659790039
generator epoch 412 loss: 0.9215203002929687                 accuracy: 0.9300000071525574
generator epoch 413 loss: 0.9243643668038505                 accuracy: 0.9392856955528259
generator epoch 414 loss: 0.9221697300502232                 accuracy: 0.9421428442001343
generator epoch 415 loss: 0.9218073695591518                 accuracy: 0.9335713982582092
generator epoch 416 loss: 0.9195531755719866                 accuracy: 0.9121428728103638
generator epoch 417 loss: 0.9263350176130022                 accuracy: 0.9242857098579407
generator epoch 418 loss: 0.925983620779855                 accuracy: 0.9442856907844543
generator epoch 419 loss: 0.9253907924107143                 accuracy: 0.9300000071525574
generator epoch 420 loss: 0.9240002764020647                 accuracy: 0.9235714077949524
generator epoch 421 loss: 0.9240642368861607                 accuracy: 0.9392856955528259
generator epoch 422 loss: 0.9230356209891183                 accuracy: 0.9164285659790039
generator epoch 423 loss: 0.9180093113490514                 accuracy: 0.9285714030265808
generator epoch 424 loss: 0.9168739371163505                 accuracy: 0.9321428537368774
generator epoch 425 loss: 0.916650235421317                 accuracy: 0.9407142996788025
generator epoch 426 loss: 0.9220017569405692                 accuracy: 0.9350000023841858
generator epoch 427 loss: 0.9153365164620536                 accuracy: 0.9285714030265808
generator epoch 428 loss: 0.9226089957101005                 accuracy: 0.9307142496109009
generator epoch 429 loss: 0.9202656058175224                 accuracy: 0.9171428680419922
generator epoch 430 loss: 0.9195191816057477                 accuracy: 0.9328571557998657
generator epoch 431 loss: 0.9215957807268416                 accuracy: 0.9392856955528259
generator epoch 432 loss: 0.9205413408551897                 accuracy: 0.9242857098579407
generator epoch 433 loss: 0.920764217703683                 accuracy: 0.9242857098579407
generator epoch 434 loss: 0.9218140816824777                 accuracy: 0.9292857050895691
generator epoch 435 loss: 0.9175030883789063                 accuracy: 0.9385713934898376
generator epoch 436 loss: 0.9171861441476005                 accuracy: 0.9228571057319641
generator epoch 437 loss: 0.917078373500279                 accuracy: 0.9257142543792725
generator epoch 438 loss: 0.91810244140625                 accuracy: 0.9392856955528259
generator epoch 439 loss: 0.9222611476353236                 accuracy: 0.9242857098579407
generator epoch 440 loss: 0.9173275102887835                 accuracy: 0.9357143044471741
generator epoch 441 loss: 0.919116397530692                 accuracy: 0.9242857098579407
generator epoch 442 loss: 0.9173570138113839                 accuracy: 0.9328571557998657
generator epoch 443 loss: 0.9164437072753906                 accuracy: 0.925000011920929
generator epoch 444 loss: 0.9188385951450893                 accuracy: 0.9407142996788025
generator epoch 445 loss: 0.9155564461844308                 accuracy: 0.9392856955528259
generator epoch 446 loss: 0.9191063886369978                 accuracy: 0.9350000023841858
generator epoch 447 loss: 0.9181598510742187                 accuracy: 0.9392856955528259
generator epoch 448 loss: 0.9187418195452008                 accuracy: 0.9407142996788025
generator epoch 449 loss: 0.91881826171875                 accuracy: 0.9292857050895691
generator epoch 450 loss: 0.9158328098842076                 accuracy: 0.9278571605682373
generator epoch 451 loss: 0.9217776384626116                 accuracy: 0.9121428728103638
generator epoch 452 loss: 0.920321826171875                 accuracy: 0.925000011920929
generator epoch 453 loss: 0.9183918884277343                 accuracy: 0.9285714030265808
generator epoch 454 loss: 0.919782319859096                 accuracy: 0.947857141494751
generator epoch 455 loss: 0.9192182965959822                 accuracy: 0.9421428442001343
generator epoch 456 loss: 0.9171758562360491                 accuracy: 0.9342857003211975
generator epoch 457 loss: 0.9159990626743861                 accuracy: 0.9442856907844543
generator epoch 458 loss: 0.9136174298967634                 accuracy: 0.9378571510314941
generator epoch 459 loss: 0.91713220476423                 accuracy: 0.9392856955528259
generator epoch 460 loss: 0.9168833225795201                 accuracy: 0.9278571605682373
generator epoch 461 loss: 0.9120514683314732                 accuracy: 0.9314285516738892
generator epoch 462 loss: 0.9145861615862165                 accuracy: 0.9321428537368774
generator epoch 463 loss: 0.9155929478236607                 accuracy: 0.9285714030265808
generator epoch 464 loss: 0.9085244559151786                 accuracy: 0.9314285516738892
generator epoch 465 loss: 0.9138059910365514                 accuracy: 0.9335713982582092
generator epoch 466 loss: 0.9121308026994978                 accuracy: 0.9221428632736206
generator epoch 467 loss: 0.9167420915876116                 accuracy: 0.9378571510314941
generator epoch 468 loss: 0.9132529663085938                 accuracy: 0.9442856907844543
generator epoch 469 loss: 0.9115237819126674                 accuracy: 0.9178571105003357
generator epoch 470 loss: 0.9155918125697544                 accuracy: 0.9307142496109009
generator epoch 471 loss: 0.9186142569405692                 accuracy: 0.9135714173316956
generator epoch 472 loss: 0.9165420671735491                 accuracy: 0.9357143044471741
generator epoch 473 loss: 0.9178521510532924                 accuracy: 0.9285714030265808
generator epoch 474 loss: 0.9153936131068638                 accuracy: 0.9507142901420593
generator epoch 475 loss: 0.9112442775181362                 accuracy: 0.9242857098579407
generator epoch 476 loss: 0.9157248892647879                 accuracy: 0.9264285564422607
generator epoch 477 loss: 0.9161021597726005                 accuracy: 0.9357143044471741
generator epoch 478 loss: 0.917079323032924                 accuracy: 0.9392856955528259
generator epoch 479 loss: 0.9161228410993304                 accuracy: 0.9442856907844543
generator epoch 480 loss: 0.9162490103585379                 accuracy: 0.9314285516738892
generator epoch 481 loss: 0.918622208077567                 accuracy: 0.9371428489685059
generator epoch 482 loss: 0.9144617893763951                 accuracy: 0.9335713982582092
generator epoch 483 loss: 0.9167060555594309                 accuracy: 0.9357143044471741
generator epoch 484 loss: 0.9160901471819196                 accuracy: 0.9521428346633911
generator epoch 485 loss: 0.9142935224260603                 accuracy: 0.9142857193946838
generator epoch 486 loss: 0.9135658133370536                 accuracy: 0.9442856907844543
generator epoch 487 loss: 0.9173021179199219                 accuracy: 0.9228571057319641
generator epoch 488 loss: 0.9093838762555804                 accuracy: 0.920714259147644
generator epoch 489 loss: 0.9061140904017857                 accuracy: 0.9307142496109009
generator epoch 490 loss: 0.9156164960588727                 accuracy: 0.9314285516738892
generator epoch 491 loss: 0.9304456516810826                 accuracy: 0.9242857098579407
generator epoch 492 loss: 0.9203903119768415                 accuracy: 0.9350000023841858
generator epoch 493 loss: 0.913677814592634                 accuracy: 0.9385713934898376
generator epoch 494 loss: 0.9178529323032925                 accuracy: 0.9364285469055176
generator epoch 495 loss: 0.9121087254115513                 accuracy: 0.9342857003211975
generator epoch 496 loss: 0.9129304617745536                 accuracy: 0.9242857098579407
generator epoch 497 loss: 0.9130412562779018                 accuracy: 0.9371428489685059
generator epoch 498 loss: 0.912032169015067                 accuracy: 0.9392856955528259
generator epoch 499 loss: 0.9111211233956473                 accuracy: 0.9171428680419922
batch 0 train loss: [0.9718426]
batch 1 train loss: [0.9760092]
batch 2 train loss: [1.043662]
batch 3 train loss: [1.0012608]
batch 4 train loss: [1.0270356]
batch 5 train loss: [0.92436874]
batch 6 train loss: [1.0206314]
batch 7 train loss: [0.9718377]
batch 8 train loss: [0.9125527]
batch 9 train loss: [1.0546316]
batch 10 train loss: [1.1156524]
batch 11 train loss: [0.9515138]
batch 12 train loss: [0.99982536]
batch 13 train loss: [0.93704426]
batch 14 train loss: [0.9476825]
batch 15 train loss: [0.9692636]
batch 16 train loss: [0.9832614]
batch 17 train loss: [0.9655024]
batch 18 train loss: [0.91727006]
batch 19 train loss: [1.012998]
batch 20 train loss: [0.9475552]
batch 21 train loss: [0.99194276]
batch 22 train loss: [0.99798644]
batch 23 train loss: [0.9362335]
batch 24 train loss: [0.7957334]
batch 25 train loss: [0.98548794]
batch 26 train loss: [0.963707]
batch 27 train loss: [1.014514]
batch 28 train loss: [0.8957696]
batch 29 train loss: [0.99042416]
batch 30 train loss: [0.9038845]
batch 31 train loss: [0.87211466]
batch 32 train loss: [0.8399605]
batch 33 train loss: [0.8621866]
batch 34 train loss: [0.90371233]
batch 35 train loss: [0.90058184]
batch 36 train loss: [0.9731032]
batch 37 train loss: [0.85555947]
batch 38 train loss: [0.86116105]
batch 39 train loss: [0.8179957]
batch 40 train loss: [0.8795698]
batch 41 train loss: [0.9466664]
batch 42 train loss: [0.91365075]
batch 43 train loss: [0.9740081]
batch 44 train loss: [0.91689926]
batch 45 train loss: [0.8557076]
batch 46 train loss: [0.8481935]
batch 47 train loss: [0.88775516]
batch 48 train loss: [0.88877183]
batch 49 train loss: [0.9026142]
batch 50 train loss: [0.81606615]
batch 51 train loss: [0.99470574]
batch 52 train loss: [0.8823883]
batch 53 train loss: [0.84038585]
batch 54 train loss: [0.9188972]
batch 55 train loss: [0.8348513]
batch 56 train loss: [0.8381956]
batch 57 train loss: [0.9462862]
batch 58 train loss: [0.80046624]
batch 59 train loss: [0.79820806]
batch 60 train loss: [0.8938785]
batch 61 train loss: [0.8956778]
batch 62 train loss: [0.85159427]
batch 63 train loss: [1.0261554]
batch 64 train loss: [0.8141387]
batch 65 train loss: [0.9045468]
batch 66 train loss: [0.7879369]
batch 67 train loss: [0.8818398]
batch 68 train loss: [0.7645245]
batch 69 train loss: [0.87975526]
batch 70 train loss: [0.8431483]
batch 71 train loss: [0.87429106]
batch 72 train loss: [0.8616793]
batch 73 train loss: [0.8123283]
batch 74 train loss: [0.9103507]
batch 75 train loss: [0.92896587]
batch 76 train loss: [0.81094116]
batch 77 train loss: [0.9485355]
batch 78 train loss: [0.8813594]
batch 79 train loss: [0.83357805]
batch 80 train loss: [0.8264075]
batch 81 train loss: [0.7652916]
batch 82 train loss: [0.8277853]
batch 83 train loss: [0.7978246]
batch 84 train loss: [0.94115]
batch 85 train loss: [0.9061591]
batch 86 train loss: [0.8455393]
batch 87 train loss: [0.79127735]
batch 88 train loss: [0.9178531]
batch 89 train loss: [0.94118977]
batch 90 train loss: [0.8405354]
batch 91 train loss: [0.87095463]
batch 92 train loss: [0.8574249]
batch 93 train loss: [0.8089014]
batch 94 train loss: [0.934908]
batch 95 train loss: [0.87618285]
batch 96 train loss: [0.923465]
batch 97 train loss: [0.6932823]
batch 98 train loss: [0.83925545]
batch 99 train loss: [0.967755]
epoch 0 mean train loss: [0.902761]
Epoch 0/400=>  train_loss: [0.902761], iou: nan, cd: 3.4138443238157588, test_mse: [0.8391094]
CORRECT PROGRAMS: 9803
batch 0 train loss: [0.8272336]
batch 1 train loss: [0.65525603]
batch 2 train loss: [0.790023]
batch 3 train loss: [0.7667296]
batch 4 train loss: [0.78538364]
batch 5 train loss: [0.80809987]
batch 6 train loss: [0.7021845]
batch 7 train loss: [0.73021585]
batch 8 train loss: [0.7143629]
batch 9 train loss: [0.7413197]
batch 10 train loss: [0.7248037]
batch 11 train loss: [0.73489755]
batch 12 train loss: [0.73262876]
batch 13 train loss: [0.72699094]
batch 14 train loss: [0.6906722]
batch 15 train loss: [0.7546225]
batch 16 train loss: [0.8542758]
batch 17 train loss: [0.738998]
batch 18 train loss: [0.95552695]
batch 19 train loss: [0.80767936]
batch 20 train loss: [0.7718684]
batch 21 train loss: [0.80030185]
batch 22 train loss: [0.7906763]
batch 23 train loss: [0.85924876]
batch 24 train loss: [0.7818411]
batch 25 train loss: [0.79487926]
batch 26 train loss: [0.75799304]
batch 27 train loss: [0.80747277]
batch 28 train loss: [0.71188605]
batch 29 train loss: [0.75916857]
batch 30 train loss: [0.79777855]
batch 31 train loss: [0.73672885]
batch 32 train loss: [0.81871086]
batch 33 train loss: [0.76292634]
batch 34 train loss: [0.74050534]
batch 35 train loss: [0.81108254]
batch 36 train loss: [0.7572582]
batch 37 train loss: [0.7638348]
batch 38 train loss: [0.81771433]
batch 39 train loss: [0.732016]
batch 40 train loss: [0.7887159]
batch 41 train loss: [0.7234097]
batch 42 train loss: [0.6608374]
batch 43 train loss: [0.8525411]
batch 44 train loss: [0.7257029]
batch 45 train loss: [0.74231744]
batch 46 train loss: [0.69813687]
batch 47 train loss: [0.7814361]
batch 48 train loss: [0.80873865]
batch 49 train loss: [0.7574963]
batch 50 train loss: [0.763033]
batch 51 train loss: [0.7968449]
batch 52 train loss: [0.7907268]
batch 53 train loss: [0.78249586]
batch 54 train loss: [0.6917233]
batch 55 train loss: [0.77119267]
batch 56 train loss: [0.64227915]
batch 57 train loss: [0.67126137]
batch 58 train loss: [0.74390525]
batch 59 train loss: [0.68897575]
batch 60 train loss: [0.8376755]
batch 61 train loss: [0.7332938]
batch 62 train loss: [0.7910275]
batch 63 train loss: [0.7825635]
batch 64 train loss: [0.72059613]
batch 65 train loss: [0.7717629]
batch 66 train loss: [0.79744977]
batch 67 train loss: [0.7869939]
batch 68 train loss: [0.7544192]
batch 69 train loss: [0.7920419]
batch 70 train loss: [0.8604057]
batch 71 train loss: [0.68387944]
batch 72 train loss: [0.6922466]
batch 73 train loss: [0.8458259]
batch 74 train loss: [0.6826822]
batch 75 train loss: [0.78997844]
batch 76 train loss: [0.7074469]
batch 77 train loss: [0.7545217]
batch 78 train loss: [0.7277542]
batch 79 train loss: [0.831166]
batch 80 train loss: [0.7323943]
batch 81 train loss: [0.8638978]
batch 82 train loss: [0.7405101]
batch 83 train loss: [0.7764719]
batch 84 train loss: [0.75446904]
batch 85 train loss: [0.7836382]
batch 86 train loss: [0.7543302]
batch 87 train loss: [0.77487636]
batch 88 train loss: [0.83676606]
batch 89 train loss: [0.6948847]
batch 90 train loss: [0.78578925]
batch 91 train loss: [0.73661554]
batch 92 train loss: [0.7780708]
batch 93 train loss: [0.6789905]
batch 94 train loss: [0.74483037]
batch 95 train loss: [0.724878]
batch 96 train loss: [0.78463686]
batch 97 train loss: [0.76301825]
batch 98 train loss: [0.8120591]
batch 99 train loss: [0.7538287]
epoch 1 mean train loss: [0.7631627]
Epoch 1/400=>  train_loss: [0.7631627], iou: nan, cd: 3.070398651932368, test_mse: [0.7599225]
CORRECT PROGRAMS: 9803
batch 0 train loss: [0.6875788]
batch 1 train loss: [0.6582286]
batch 2 train loss: [0.63374794]
batch 3 train loss: [0.7210203]
batch 4 train loss: [0.6363775]
batch 5 train loss: [0.6855344]
batch 6 train loss: [0.6689604]
batch 7 train loss: [0.66131985]
batch 8 train loss: [0.6532275]
batch 9 train loss: [0.59980553]
batch 10 train loss: [0.7710985]
batch 11 train loss: [0.7129689]
batch 12 train loss: [0.72747207]
batch 13 train loss: [0.7057515]
batch 14 train loss: [0.634117]
batch 15 train loss: [0.81638646]
batch 16 train loss: [0.6166374]
batch 17 train loss: [0.6503515]
batch 18 train loss: [0.69755685]
batch 19 train loss: [0.6386515]
batch 20 train loss: [0.67326623]
batch 21 train loss: [0.6944272]
batch 22 train loss: [0.58402103]
batch 23 train loss: [0.6597049]
batch 24 train loss: [0.7000318]
batch 25 train loss: [0.71591264]
batch 26 train loss: [0.83718145]
batch 27 train loss: [0.67931694]
batch 28 train loss: [0.7632195]
batch 29 train loss: [0.7081524]
batch 30 train loss: [0.5695926]
batch 31 train loss: [0.5407394]
batch 32 train loss: [0.6725713]
batch 33 train loss: [0.7000854]
batch 34 train loss: [0.69524014]
batch 35 train loss: [0.70714265]
batch 36 train loss: [0.641056]
batch 37 train loss: [0.694255]
batch 38 train loss: [0.6479939]
batch 39 train loss: [0.6905224]
batch 40 train loss: [0.65708715]
batch 41 train loss: [0.76696694]
batch 42 train loss: [0.6487138]
batch 43 train loss: [0.7210473]
batch 44 train loss: [0.7234236]
batch 45 train loss: [0.74389225]
batch 46 train loss: [0.64565265]
batch 47 train loss: [0.67445606]
batch 48 train loss: [0.733539]
batch 49 train loss: [0.66797227]
batch 50 train loss: [0.71956563]
batch 51 train loss: [0.7033384]
batch 52 train loss: [0.7318787]
batch 53 train loss: [0.6767196]
batch 54 train loss: [0.6336152]
batch 55 train loss: [0.55977523]
batch 56 train loss: [0.6829659]
batch 57 train loss: [0.64570254]
batch 58 train loss: [0.7105418]
batch 59 train loss: [0.7540794]
batch 60 train loss: [0.6983273]
batch 61 train loss: [0.7313805]
batch 62 train loss: [0.65444297]
batch 63 train loss: [0.633879]
batch 64 train loss: [0.710216]
batch 65 train loss: [0.65662044]
batch 66 train loss: [0.77800167]
batch 67 train loss: [0.6845652]
batch 68 train loss: [0.65552866]
batch 69 train loss: [0.7060887]
batch 70 train loss: [0.66246796]
batch 71 train loss: [0.7088438]
batch 72 train loss: [0.71527475]
batch 73 train loss: [0.6815604]
batch 74 train loss: [0.6692268]
batch 75 train loss: [0.68464607]
batch 76 train loss: [0.69321036]
batch 77 train loss: [0.74228555]
batch 78 train loss: [0.6513853]
batch 79 train loss: [0.75566804]
batch 80 train loss: [0.6736299]
batch 81 train loss: [0.70605534]
batch 82 train loss: [0.6338501]
batch 83 train loss: [0.6737949]
batch 84 train loss: [0.6606252]
batch 85 train loss: [0.72786576]
batch 86 train loss: [0.7428744]
batch 87 train loss: [0.71662754]
batch 88 train loss: [0.67114073]
batch 89 train loss: [0.67065066]
batch 90 train loss: [0.7571523]
batch 91 train loss: [0.66199577]
batch 92 train loss: [0.7800447]
batch 93 train loss: [0.6402065]
batch 94 train loss: [0.7136192]
batch 95 train loss: [0.7479884]
batch 96 train loss: [0.6269574]
batch 97 train loss: [0.8481586]
batch 98 train loss: [0.679864]
batch 99 train loss: [0.74856013]
epoch 2 mean train loss: [0.6890744]
Epoch 2/400=>  train_loss: [0.6890744], iou: nan, cd: 3.090914144719497, test_mse: [0.7478799]
CORRECT PROGRAMS: 9803
batch 0 train loss: [0.62459075]
batch 1 train loss: [0.55342263]
batch 2 train loss: [0.56795067]
batch 3 train loss: [0.59779626]
batch 4 train loss: [0.5835859]
batch 5 train loss: [0.6321262]
batch 6 train loss: [0.6578248]
batch 7 train loss: [0.6337635]
batch 8 train loss: [0.74016875]
batch 9 train loss: [0.7517203]
batch 10 train loss: [0.7410638]
batch 11 train loss: [0.6895902]
batch 12 train loss: [0.5992727]
batch 13 train loss: [0.6488005]
batch 14 train loss: [0.58365834]
batch 15 train loss: [0.61626464]
batch 16 train loss: [0.6995278]
batch 17 train loss: [0.7113448]
batch 18 train loss: [0.58533025]
batch 19 train loss: [0.56837237]
batch 20 train loss: [0.5217078]
batch 21 train loss: [0.6167081]
batch 22 train loss: [0.5494696]
batch 23 train loss: [0.6804908]
batch 24 train loss: [0.60291845]
batch 25 train loss: [0.5318966]
batch 26 train loss: [0.6664874]
batch 27 train loss: [0.6753129]
batch 28 train loss: [0.6874928]
batch 29 train loss: [0.4957795]
batch 30 train loss: [0.58644557]
batch 31 train loss: [0.63647187]
batch 32 train loss: [0.6633841]
batch 33 train loss: [0.61765647]
batch 34 train loss: [0.6392092]
batch 35 train loss: [0.5772975]
batch 36 train loss: [0.6627962]
batch 37 train loss: [0.55411494]
batch 38 train loss: [0.58585477]
batch 39 train loss: [0.56982684]
batch 40 train loss: [0.67737716]
batch 41 train loss: [0.6438091]
batch 42 train loss: [0.66592246]
batch 43 train loss: [0.596229]
batch 44 train loss: [0.7050509]
batch 45 train loss: [0.55925465]
batch 46 train loss: [0.57269347]
batch 47 train loss: [0.6442875]
batch 48 train loss: [0.6085229]
batch 49 train loss: [0.6525802]
batch 50 train loss: [0.6992726]
batch 51 train loss: [0.5548008]
batch 52 train loss: [0.5922389]
batch 53 train loss: [0.70429397]
batch 54 train loss: [0.6432009]
batch 55 train loss: [0.5986694]
batch 56 train loss: [0.6884078]
batch 57 train loss: [0.6335597]
batch 58 train loss: [0.5968237]
batch 59 train loss: [0.67133576]
batch 60 train loss: [0.6463101]
batch 61 train loss: [0.5799357]
batch 62 train loss: [0.5676335]
batch 63 train loss: [0.74995536]
batch 64 train loss: [0.6289844]
batch 65 train loss: [0.57704425]
batch 66 train loss: [0.6805622]
batch 67 train loss: [0.6703907]
batch 68 train loss: [0.67075354]
batch 69 train loss: [0.6517243]
batch 70 train loss: [0.65333575]
batch 71 train loss: [0.6704697]
batch 72 train loss: [0.6936791]
batch 73 train loss: [0.6420116]
batch 74 train loss: [0.65488756]
batch 75 train loss: [0.63391036]
batch 76 train loss: [0.63448083]
batch 77 train loss: [0.58338106]
batch 78 train loss: [0.67185223]
batch 79 train loss: [0.5704237]
batch 80 train loss: [0.66511935]
batch 81 train loss: [0.69356686]
batch 82 train loss: [0.57861507]
batch 83 train loss: [0.6089264]
batch 84 train loss: [0.70095366]
batch 85 train loss: [0.5887492]
batch 86 train loss: [0.6987507]
batch 87 train loss: [0.61305124]
batch 88 train loss: [0.636298]
batch 89 train loss: [0.625821]
batch 90 train loss: [0.642593]
batch 91 train loss: [0.6319791]
batch 92 train loss: [0.58212507]
batch 93 train loss: [0.7240395]
batch 94 train loss: [0.6573548]
batch 95 train loss: [0.68492204]
batch 96 train loss: [0.7027344]
batch 97 train loss: [0.7401243]
batch 98 train loss: [0.67467314]
batch 99 train loss: [0.58342445]
epoch 3 mean train loss: [0.6348137]
Epoch 3/400=>  train_loss: [0.6348137], iou: nan, cd: 2.910587151024371, test_mse: [0.7201402]
CORRECT PROGRAMS: 9803
batch 0 train loss: [0.66298956]
batch 1 train loss: [0.6058606]
batch 2 train loss: [0.53021413]
batch 3 train loss: [0.6031983]
batch 4 train loss: [0.62244856]
batch 5 train loss: [0.59030175]
batch 6 train loss: [0.53057855]
batch 7 train loss: [0.5702503]
batch 8 train loss: [0.47235668]
batch 9 train loss: [0.5577953]
batch 10 train loss: [0.51453435]
batch 11 train loss: [0.6278039]
batch 12 train loss: [0.56835836]
batch 13 train loss: [0.5345863]
batch 14 train loss: [0.61240464]
batch 15 train loss: [0.6145229]
batch 16 train loss: [0.5176488]
batch 17 train loss: [0.61998147]
batch 18 train loss: [0.5559084]
batch 19 train loss: [0.6202049]
batch 20 train loss: [0.5504567]
batch 21 train loss: [0.5354367]
batch 22 train loss: [0.689718]
batch 23 train loss: [0.5432452]
batch 24 train loss: [0.5160677]
batch 25 train loss: [0.6192807]
batch 26 train loss: [0.59320766]
batch 27 train loss: [0.56092924]
batch 28 train loss: [0.637964]
batch 29 train loss: [0.5629381]
batch 30 train loss: [0.5857634]
batch 31 train loss: [0.59748536]
batch 32 train loss: [0.56416863]
batch 33 train loss: [0.6357]
batch 34 train loss: [0.53272176]
batch 35 train loss: [0.5628874]
batch 36 train loss: [0.6165413]
batch 37 train loss: [0.60045475]
batch 38 train loss: [0.69244426]
batch 39 train loss: [0.56748146]
batch 40 train loss: [0.5571968]
batch 41 train loss: [0.5735721]
batch 42 train loss: [0.6477276]
batch 43 train loss: [0.52797085]
batch 44 train loss: [0.52791196]
batch 45 train loss: [0.6178846]
batch 46 train loss: [0.52132726]
batch 47 train loss: [0.60376]
batch 48 train loss: [0.64008933]
batch 49 train loss: [0.5768736]
batch 50 train loss: [0.5700049]
batch 51 train loss: [0.6091112]
batch 52 train loss: [0.5765555]
batch 53 train loss: [0.59250873]
batch 54 train loss: [0.61783427]
batch 55 train loss: [0.4412457]
batch 56 train loss: [0.5990697]
batch 57 train loss: [0.56908536]
batch 58 train loss: [0.590514]
batch 59 train loss: [0.60044134]
batch 60 train loss: [0.62844306]
batch 61 train loss: [0.6311262]
batch 62 train loss: [0.61487836]
batch 63 train loss: [0.5585651]
batch 64 train loss: [0.64755744]
batch 65 train loss: [0.5965416]
batch 66 train loss: [0.585798]
batch 67 train loss: [0.5814599]
batch 68 train loss: [0.47475845]
batch 69 train loss: [0.54401]
batch 70 train loss: [0.5827579]
batch 71 train loss: [0.7528775]
batch 72 train loss: [0.6075288]
batch 73 train loss: [0.6167515]
batch 74 train loss: [0.5469003]
batch 75 train loss: [0.5776742]
batch 76 train loss: [0.6171378]
batch 77 train loss: [0.6409273]
batch 78 train loss: [0.67128396]
batch 79 train loss: [0.5632371]
batch 80 train loss: [0.5579176]
batch 81 train loss: [0.7100492]
batch 82 train loss: [0.56147826]
batch 83 train loss: [0.59239674]
batch 84 train loss: [0.5422692]
batch 85 train loss: [0.61853886]
batch 86 train loss: [0.64037454]
batch 87 train loss: [0.63627374]
batch 88 train loss: [0.64382935]
batch 89 train loss: [0.54541355]
batch 90 train loss: [0.60902894]
batch 91 train loss: [0.6293017]
batch 92 train loss: [0.53602415]
batch 93 train loss: [0.62363786]
batch 94 train loss: [0.6191125]
batch 95 train loss: [0.6489729]
batch 96 train loss: [0.62888557]
batch 97 train loss: [0.6244836]
batch 98 train loss: [0.60924476]
batch 99 train loss: [0.5933251]
epoch 4 mean train loss: [0.590683]
Epoch 4/400=>  train_loss: [0.590683], iou: nan, cd: 2.7993536033846818, test_mse: [0.69918936]
CORRECT PROGRAMS: 9803
batch 0 train loss: [0.53435326]
batch 1 train loss: [0.55377406]
batch 2 train loss: [0.570392]
batch 3 train loss: [0.5419636]
batch 4 train loss: [0.568839]
batch 5 train loss: [0.431513]
batch 6 train loss: [0.5492112]
batch 7 train loss: [0.54270035]
batch 8 train loss: [0.5671941]
batch 9 train loss: [0.5304843]
batch 10 train loss: [0.49005452]
batch 11 train loss: [0.5204665]
batch 12 train loss: [0.68063533]
batch 13 train loss: [0.62762374]
batch 14 train loss: [0.56626415]
batch 15 train loss: [0.6634543]
batch 16 train loss: [0.5836352]
batch 17 train loss: [0.5416]
batch 18 train loss: [0.5482571]
batch 19 train loss: [0.5423385]
batch 20 train loss: [0.5564191]
batch 21 train loss: [0.49386838]
batch 22 train loss: [0.5091907]
batch 23 train loss: [0.56040615]
batch 24 train loss: [0.6015912]
batch 25 train loss: [0.5357253]
batch 26 train loss: [0.54183507]
batch 27 train loss: [0.4368457]
batch 28 train loss: [0.6032082]
batch 29 train loss: [0.5035896]
batch 30 train loss: [0.53924084]
batch 31 train loss: [0.49612677]
batch 32 train loss: [0.5349346]
batch 33 train loss: [0.58186406]
batch 34 train loss: [0.5780229]
batch 35 train loss: [0.5704912]
batch 36 train loss: [0.5332778]
batch 37 train loss: [0.62782824]
batch 38 train loss: [0.5377928]
batch 39 train loss: [0.5826808]
batch 40 train loss: [0.5514221]
batch 41 train loss: [0.53353006]
batch 42 train loss: [0.5471198]
batch 43 train loss: [0.49444452]
batch 44 train loss: [0.50266004]
batch 45 train loss: [0.56929123]
batch 46 train loss: [0.5638685]
batch 47 train loss: [0.4813543]
batch 48 train loss: [0.5481195]
batch 49 train loss: [0.5129471]
batch 50 train loss: [0.5535107]
batch 51 train loss: [0.5799978]
batch 52 train loss: [0.54683954]
batch 53 train loss: [0.650653]
batch 54 train loss: [0.50360596]
batch 55 train loss: [0.5519869]
batch 56 train loss: [0.53829783]
batch 57 train loss: [0.4768532]
batch 58 train loss: [0.5853406]
batch 59 train loss: [0.48861727]
batch 60 train loss: [0.56431776]
batch 61 train loss: [0.61052054]
batch 62 train loss: [0.5725784]
batch 63 train loss: [0.4788612]
batch 64 train loss: [0.5598637]
batch 65 train loss: [0.5986355]
batch 66 train loss: [0.5418117]
batch 67 train loss: [0.4834171]
batch 68 train loss: [0.5676079]
batch 69 train loss: [0.6349028]
batch 70 train loss: [0.61804134]
batch 71 train loss: [0.526665]
batch 72 train loss: [0.6381754]
batch 73 train loss: [0.5236534]
batch 74 train loss: [0.4185091]
batch 75 train loss: [0.63879436]
batch 76 train loss: [0.45602787]
batch 77 train loss: [0.557447]
batch 78 train loss: [0.58627886]
batch 79 train loss: [0.5462825]
batch 80 train loss: [0.5992091]
batch 81 train loss: [0.5427848]
batch 82 train loss: [0.49992397]
batch 83 train loss: [0.5061111]
batch 84 train loss: [0.56119657]
batch 85 train loss: [0.50448316]
batch 86 train loss: [0.569469]
batch 87 train loss: [0.53950095]
batch 88 train loss: [0.603719]
batch 89 train loss: [0.6728055]
batch 90 train loss: [0.6771468]
batch 91 train loss: [0.5978577]
batch 92 train loss: [0.5985036]
batch 93 train loss: [0.5542595]
batch 94 train loss: [0.5503458]
batch 95 train loss: [0.55574167]
batch 96 train loss: [0.5371746]
batch 97 train loss: [0.5155878]
batch 98 train loss: [0.5067701]
batch 99 train loss: [0.73038656]
epoch 5 mean train loss: [0.5540552]
Epoch 5/400=>  train_loss: [0.5540552], iou: nan, cd: 2.9299706751386516, test_mse: [0.7182003]
CORRECT PROGRAMS: 9803
batch 0 train loss: [0.49526182]
batch 1 train loss: [0.5026451]
batch 2 train loss: [0.47228867]
batch 3 train loss: [0.4763043]
batch 4 train loss: [0.53367054]
batch 5 train loss: [0.551853]
batch 6 train loss: [0.46461058]
batch 7 train loss: [0.45150092]
batch 8 train loss: [0.5277511]
batch 9 train loss: [0.52380604]
batch 10 train loss: [0.4330178]
batch 11 train loss: [0.54357386]
batch 12 train loss: [0.501746]
batch 13 train loss: [0.5097857]
batch 14 train loss: [0.4943708]
batch 15 train loss: [0.44348133]
batch 16 train loss: [0.539118]
batch 17 train loss: [0.54506236]
batch 18 train loss: [0.49802604]
batch 19 train loss: [0.5278536]
batch 20 train loss: [0.4882577]
batch 21 train loss: [0.4989428]
batch 22 train loss: [0.43331796]
batch 23 train loss: [0.54795235]
batch 24 train loss: [0.5531936]
batch 25 train loss: [0.54933953]
batch 26 train loss: [0.5870395]
batch 27 train loss: [0.5348748]
batch 28 train loss: [0.51267815]
batch 29 train loss: [0.56191635]
batch 30 train loss: [0.4849611]
batch 31 train loss: [0.59788877]
batch 32 train loss: [0.4626863]
batch 33 train loss: [0.523531]
batch 34 train loss: [0.48064697]
batch 35 train loss: [0.45957732]
batch 36 train loss: [0.50034326]
batch 37 train loss: [0.5251786]
batch 38 train loss: [0.47512728]
batch 39 train loss: [0.55790883]
batch 40 train loss: [0.5144745]
batch 41 train loss: [0.5098975]
batch 42 train loss: [0.45494214]
batch 43 train loss: [0.58632004]
batch 44 train loss: [0.5935295]
batch 45 train loss: [0.62500346]
batch 46 train loss: [0.5906243]
batch 47 train loss: [0.47843426]
batch 48 train loss: [0.48766175]
batch 49 train loss: [0.46896198]
batch 50 train loss: [0.543522]
batch 51 train loss: [0.5336637]
batch 52 train loss: [0.5651983]
batch 53 train loss: [0.5710239]
batch 54 train loss: [0.5186173]
batch 55 train loss: [0.5591077]
batch 56 train loss: [0.49316612]
batch 57 train loss: [0.45129922]
batch 58 train loss: [0.52995664]
batch 59 train loss: [0.5369011]
batch 60 train loss: [0.58617866]
batch 61 train loss: [0.45833808]
batch 62 train loss: [0.50128764]
batch 63 train loss: [0.58175737]
batch 64 train loss: [0.5737966]
batch 65 train loss: [0.49662226]
batch 66 train loss: [0.43267107]
batch 67 train loss: [0.59640443]
batch 68 train loss: [0.5750214]
batch 69 train loss: [0.547952]
batch 70 train loss: [0.50908387]
batch 71 train loss: [0.6047733]
batch 72 train loss: [0.38472092]
batch 73 train loss: [0.5950735]
batch 74 train loss: [0.60048264]
batch 75 train loss: [0.5514869]
batch 76 train loss: [0.5104954]
batch 77 train loss: [0.5235679]
batch 78 train loss: [0.51992583]
batch 79 train loss: [0.53540635]
batch 80 train loss: [0.49450654]
batch 81 train loss: [0.50914764]
batch 82 train loss: [0.4982155]
batch 83 train loss: [0.51022494]
batch 84 train loss: [0.5346098]
batch 85 train loss: [0.5927987]
batch 86 train loss: [0.54344696]
batch 87 train loss: [0.46550518]
batch 88 train loss: [0.4976596]
batch 89 train loss: [0.52000326]
batch 90 train loss: [0.47385898]
batch 91 train loss: [0.5821276]
batch 92 train loss: [0.52987194]
batch 93 train loss: [0.5288372]
batch 94 train loss: [0.58050096]
batch 95 train loss: [0.5305095]
batch 96 train loss: [0.53873897]
batch 97 train loss: [0.61294603]
batch 98 train loss: [0.5638489]
batch 99 train loss: [0.57824314]
epoch 6 mean train loss: [0.5235404]
Epoch 6/400=>  train_loss: [0.5235404], iou: nan, cd: 2.872790940786259, test_mse: [0.70750034]
CORRECT PROGRAMS: 9803
batch 0 train loss: [0.46922958]
batch 1 train loss: [0.4350835]
batch 2 train loss: [0.47757524]
batch 3 train loss: [0.5308115]
batch 4 train loss: [0.38662973]
batch 5 train loss: [0.47998652]
batch 6 train loss: [0.4848196]
batch 7 train loss: [0.5140128]
batch 8 train loss: [0.4838289]
batch 9 train loss: [0.52412504]
batch 10 train loss: [0.4791284]
batch 11 train loss: [0.5179331]
batch 12 train loss: [0.41917518]
batch 13 train loss: [0.42973906]
batch 14 train loss: [0.50797415]
batch 15 train loss: [0.5536517]
batch 16 train loss: [0.41535503]
batch 17 train loss: [0.47818762]
batch 18 train loss: [0.4533762]
batch 19 train loss: [0.47637966]
batch 20 train loss: [0.44245785]
batch 21 train loss: [0.5172219]
batch 22 train loss: [0.44305602]
batch 23 train loss: [0.4794147]
batch 24 train loss: [0.48499146]
batch 25 train loss: [0.4906105]
batch 26 train loss: [0.4787911]
batch 27 train loss: [0.45536113]
batch 28 train loss: [0.5326326]
batch 29 train loss: [0.52503276]
batch 30 train loss: [0.50342304]
batch 31 train loss: [0.5182116]
batch 32 train loss: [0.4424438]
batch 33 train loss: [0.5341614]
batch 34 train loss: [0.4952156]
batch 35 train loss: [0.48213857]
batch 36 train loss: [0.4992851]
batch 37 train loss: [0.50888723]
batch 38 train loss: [0.44881123]
batch 39 train loss: [0.50316215]
batch 40 train loss: [0.43193057]
batch 41 train loss: [0.51487696]
batch 42 train loss: [0.42824158]
batch 43 train loss: [0.46591815]
batch 44 train loss: [0.5275266]
batch 45 train loss: [0.4321568]
batch 46 train loss: [0.54137266]
batch 47 train loss: [0.5120176]
batch 48 train loss: [0.48601422]
batch 49 train loss: [0.45365778]
batch 50 train loss: [0.56508416]
batch 51 train loss: [0.49071464]
batch 52 train loss: [0.50851715]
batch 53 train loss: [0.47551233]
batch 54 train loss: [0.48390785]
batch 55 train loss: [0.41640776]
batch 56 train loss: [0.44309992]
batch 57 train loss: [0.42705593]
batch 58 train loss: [0.45876876]
batch 59 train loss: [0.46263322]
batch 60 train loss: [0.5761503]
batch 61 train loss: [0.48875767]
batch 62 train loss: [0.45950234]
batch 63 train loss: [0.56495345]
batch 64 train loss: [0.51009333]
batch 65 train loss: [0.41933057]
batch 66 train loss: [0.4852455]
batch 67 train loss: [0.52907515]
batch 68 train loss: [0.52677315]
batch 69 train loss: [0.5688886]
batch 70 train loss: [0.5208778]
batch 71 train loss: [0.43736753]
batch 72 train loss: [0.5201387]
batch 73 train loss: [0.4808767]
batch 74 train loss: [0.46328473]
batch 75 train loss: [0.51571333]
batch 76 train loss: [0.47083867]
batch 77 train loss: [0.5594506]
batch 78 train loss: [0.54394495]
batch 79 train loss: [0.5920374]
batch 80 train loss: [0.42309424]
batch 81 train loss: [0.48910505]
batch 82 train loss: [0.45208934]
batch 83 train loss: [0.51742023]
batch 84 train loss: [0.536286]
batch 85 train loss: [0.42901912]
batch 86 train loss: [0.46642736]
batch 87 train loss: [0.48628524]
batch 88 train loss: [0.5124917]
batch 89 train loss: [0.48608127]
batch 90 train loss: [0.5350071]
batch 91 train loss: [0.4912061]
batch 92 train loss: [0.5520418]
batch 93 train loss: [0.5312171]
batch 94 train loss: [0.49225816]
batch 95 train loss: [0.52521086]
batch 96 train loss: [0.53585666]
batch 97 train loss: [0.45651078]
batch 98 train loss: [0.5551123]
batch 99 train loss: [0.51352495]
epoch 7 mean train loss: [0.4904728]
Epoch 7/400=>  train_loss: [0.4904728], iou: nan, cd: 2.842845506836417, test_mse: [0.71743613]
CORRECT PROGRAMS: 9803
batch 0 train loss: [0.46191776]
batch 1 train loss: [0.38677648]
batch 2 train loss: [0.4390394]
batch 3 train loss: [0.45680407]
batch 4 train loss: [0.5125248]
batch 5 train loss: [0.43146235]
batch 6 train loss: [0.46818152]
batch 7 train loss: [0.5152807]
batch 8 train loss: [0.42157567]
batch 9 train loss: [0.43805027]
batch 10 train loss: [0.48718196]
batch 11 train loss: [0.4073632]
batch 12 train loss: [0.46132502]
batch 13 train loss: [0.4773416]
batch 14 train loss: [0.4069055]
batch 15 train loss: [0.44154054]
batch 16 train loss: [0.46112287]
batch 17 train loss: [0.48064357]
batch 18 train loss: [0.47678855]
batch 19 train loss: [0.46541303]
batch 20 train loss: [0.46887818]
batch 21 train loss: [0.45304742]
batch 22 train loss: [0.49172544]
batch 23 train loss: [0.42717096]
batch 24 train loss: [0.4883312]
batch 25 train loss: [0.42352563]
batch 26 train loss: [0.5215485]
batch 27 train loss: [0.45482355]
batch 28 train loss: [0.4654594]
batch 29 train loss: [0.4816428]
batch 30 train loss: [0.4990643]
batch 31 train loss: [0.41743287]
batch 32 train loss: [0.50389904]
batch 33 train loss: [0.4811245]
batch 34 train loss: [0.5103853]
batch 35 train loss: [0.4572468]
batch 36 train loss: [0.50332713]
batch 37 train loss: [0.4667763]
batch 38 train loss: [0.45086557]
batch 39 train loss: [0.42059594]
batch 40 train loss: [0.4934032]
batch 41 train loss: [0.43504393]
batch 42 train loss: [0.49560627]
batch 43 train loss: [0.46515805]
batch 44 train loss: [0.53757745]
batch 45 train loss: [0.43192175]
batch 46 train loss: [0.46606883]
batch 47 train loss: [0.49026275]
batch 48 train loss: [0.48288244]
batch 49 train loss: [0.49924362]
batch 50 train loss: [0.48258507]
batch 51 train loss: [0.46536198]
batch 52 train loss: [0.48580194]
batch 53 train loss: [0.4945932]
batch 54 train loss: [0.5051039]
batch 55 train loss: [0.37603423]
batch 56 train loss: [0.46473134]
batch 57 train loss: [0.53237695]
batch 58 train loss: [0.51806724]
batch 59 train loss: [0.4745508]
batch 60 train loss: [0.47774792]
batch 61 train loss: [0.46810082]
batch 62 train loss: [0.4591943]
batch 63 train loss: [0.41520664]
batch 64 train loss: [0.43047228]
batch 65 train loss: [0.55496156]
batch 66 train loss: [0.46095237]
batch 67 train loss: [0.50781786]
batch 68 train loss: [0.48347032]
batch 69 train loss: [0.4658715]
batch 70 train loss: [0.4524961]
batch 71 train loss: [0.58734983]
batch 72 train loss: [0.49200034]
batch 73 train loss: [0.43411028]
batch 74 train loss: [0.4705027]
batch 75 train loss: [0.49151978]
batch 76 train loss: [0.42628]
batch 77 train loss: [0.4929579]
batch 78 train loss: [0.5006457]
batch 79 train loss: [0.43069285]
batch 80 train loss: [0.50754]
batch 81 train loss: [0.4380978]
batch 82 train loss: [0.4180548]
batch 83 train loss: [0.44802868]
batch 84 train loss: [0.50762254]
batch 85 train loss: [0.4630766]
batch 86 train loss: [0.4750375]
batch 87 train loss: [0.4381484]
batch 88 train loss: [0.46082014]
batch 89 train loss: [0.49189407]
batch 90 train loss: [0.5459087]
batch 91 train loss: [0.42952204]
batch 92 train loss: [0.5224381]
batch 93 train loss: [0.5302793]
batch 94 train loss: [0.50492734]
batch 95 train loss: [0.52408767]
batch 96 train loss: [0.47212842]
batch 97 train loss: [0.47243458]
batch 98 train loss: [0.55574596]
batch 99 train loss: [0.54699826]
epoch 8 mean train loss: [0.4733562]
WAKE SLEEP ITERATION 2
Inferring cad batch: 0
Inferring cad batch: 1
Inferring cad batch: 2
Inferring cad batch: 3
Inferring cad batch: 4
Inferring cad batch: 5
Inferring cad batch: 6
Inferring cad batch: 7
Inferring cad batch: 8
Inferring cad batch: 9
Inferring cad batch: 10
Inferring cad batch: 11
Inferring cad batch: 12
Inferring cad batch: 13
Inferring cad batch: 14
Inferring cad batch: 15
Inferring cad batch: 16
Inferring cad batch: 17
Inferring cad batch: 18
Inferring cad batch: 19
Inferring cad batch: 20
Inferring cad batch: 21
Inferring cad batch: 22
Inferring cad batch: 23
Inferring cad batch: 24
Inferring cad batch: 25
Inferring cad batch: 26
Inferring cad batch: 27
Inferring cad batch: 28
Inferring cad batch: 29
Inferring cad batch: 30
Inferring cad batch: 31
Inferring cad batch: 32
Inferring cad average chamfer distance: 1.5307209843639695
0.5668779954262596 1.5307209843639695
generator epoch 0 loss: 1.4502236136300224                 accuracy: 0.8321428298950195
generator epoch 1 loss: 1.295742369733538                 accuracy: 0.8407142758369446
generator epoch 2 loss: 1.2417690412248883                 accuracy: 0.8707142472267151
generator epoch 3 loss: 1.2013551749093192                 accuracy: 0.8557142615318298
generator epoch 4 loss: 1.1633359497070312                 accuracy: 0.8585714101791382
generator epoch 5 loss: 1.148204558454241                 accuracy: 0.8714285492897034
generator epoch 6 loss: 1.1272143659319196                 accuracy: 0.8735713958740234
generator epoch 7 loss: 1.11225546875                 accuracy: 0.8814285397529602
generator epoch 8 loss: 1.0987063040597098                 accuracy: 0.8614285588264465
generator epoch 9 loss: 1.0856227975027901                 accuracy: 0.8828571438789368
generator epoch 10 loss: 1.076898748779297                 accuracy: 0.8728571534156799
generator epoch 11 loss: 1.0658086242675782                 accuracy: 0.8792856931686401
generator epoch 12 loss: 1.0543146458217076                 accuracy: 0.8700000047683716
generator epoch 13 loss: 1.0508679042271205                 accuracy: 0.8771428465843201
generator epoch 14 loss: 1.0421576729910715                 accuracy: 0.8621428608894348
generator epoch 15 loss: 1.034415865652902                 accuracy: 0.8785713911056519
generator epoch 16 loss: 1.0312986676897322                 accuracy: 0.8807142972946167
generator epoch 17 loss: 1.02539646257673                 accuracy: 0.8964285850524902
generator epoch 18 loss: 1.0273626656668526                 accuracy: 0.9021428227424622
generator epoch 19 loss: 1.0186315577915737                 accuracy: 0.904285728931427
generator epoch 20 loss: 1.0203503941127232                 accuracy: 0.889285683631897
generator epoch 21 loss: 1.0045328508649554                 accuracy: 0.8949999809265137
generator epoch 22 loss: 1.0077965532575335                 accuracy: 0.8971428275108337
generator epoch 23 loss: 1.0018790937151227                 accuracy: 0.8771428465843201
generator epoch 24 loss: 0.9946017987932477                 accuracy: 0.8785713911056519
generator epoch 25 loss: 0.9945252493722099                 accuracy: 0.8757143020629883
generator epoch 26 loss: 0.997842640032087                 accuracy: 0.8764285445213318
generator epoch 27 loss: 0.9898410086495536                 accuracy: 0.8757143020629883
generator epoch 28 loss: 0.9902427830287388                 accuracy: 0.897857129573822
generator epoch 29 loss: 0.9788384268624442                 accuracy: 0.9007142782211304
generator epoch 30 loss: 0.9813425284249442                 accuracy: 0.8971428275108337
generator epoch 31 loss: 0.9780268563406808                 accuracy: 0.889285683631897
generator epoch 32 loss: 0.9810552655901228                 accuracy: 0.8921428322792053
generator epoch 33 loss: 0.9736746285574777                 accuracy: 0.8828571438789368
generator epoch 34 loss: 0.973064786202567                 accuracy: 0.8899999856948853
generator epoch 35 loss: 0.9688367100306919                 accuracy: 0.9021428227424622
generator epoch 36 loss: 0.9680081560407366                 accuracy: 0.8921428322792053
generator epoch 37 loss: 0.9636775756835938                 accuracy: 0.889285683631897
generator epoch 38 loss: 0.961149649483817                 accuracy: 0.9092857241630554
generator epoch 39 loss: 0.9588920445033482                 accuracy: 0.8907142877578735
generator epoch 40 loss: 0.9581370239257813                 accuracy: 0.8992857336997986
generator epoch 41 loss: 0.9642705383300781                 accuracy: 0.9028571248054504
generator epoch 42 loss: 0.9591975655691964                 accuracy: 0.897857129573822
generator epoch 43 loss: 0.9607905081612723                 accuracy: 0.8857142925262451
generator epoch 44 loss: 0.9528585396902902                 accuracy: 0.8828571438789368
generator epoch 45 loss: 0.9514149475097656                 accuracy: 0.8971428275108337
generator epoch 46 loss: 0.9485528259277344                 accuracy: 0.875
generator epoch 47 loss: 0.9482593104771205                 accuracy: 0.8949999809265137
generator epoch 48 loss: 0.9490872889927455                 accuracy: 0.9092857241630554
generator epoch 49 loss: 0.9483240304129464                 accuracy: 0.8949999809265137
generator epoch 50 loss: 0.9439938180106027                 accuracy: 0.8921428322792053
generator epoch 51 loss: 0.9423926696777344                 accuracy: 0.9014285802841187
generator epoch 52 loss: 0.9394837855747767                 accuracy: 0.9149999618530273
generator epoch 53 loss: 0.9396086094447544                 accuracy: 0.8907142877578735
generator epoch 54 loss: 0.9425179922921317                 accuracy: 0.8971428275108337
generator epoch 55 loss: 0.9378604282924107                 accuracy: 0.8964285850524902
generator epoch 56 loss: 0.9360861363002232                 accuracy: 0.8921428322792053
generator epoch 57 loss: 0.9334082763671875                 accuracy: 0.9028571248054504
generator epoch 58 loss: 0.9377337724958147                 accuracy: 0.9128571152687073
generator epoch 59 loss: 0.9272634451729911                 accuracy: 0.9014285802841187
generator epoch 60 loss: 0.9344176548549107                 accuracy: 0.9064285755157471
generator epoch 61 loss: 0.9333472952706473                 accuracy: 0.8828571438789368
generator epoch 62 loss: 0.9246585963657924                 accuracy: 0.9035714268684387
generator epoch 63 loss: 0.9292559465680803                 accuracy: 0.9107142686843872
generator epoch 64 loss: 0.9260934422084264                 accuracy: 0.9035714268684387
generator epoch 65 loss: 0.9246661437988282                 accuracy: 0.9135714173316956
generator epoch 66 loss: 0.9275025512695313                 accuracy: 0.9157142639160156
generator epoch 67 loss: 0.9252705174037389                 accuracy: 0.9135714173316956
generator epoch 68 loss: 0.924928156389509                 accuracy: 0.8921428322792053
generator epoch 69 loss: 0.9169095772879464                 accuracy: 0.8971428275108337
generator epoch 70 loss: 0.9241311802455358                 accuracy: 0.897857129573822
generator epoch 71 loss: 0.9228787649972098                 accuracy: 0.9021428227424622
generator epoch 72 loss: 0.9151972760881697                 accuracy: 0.9028571248054504
generator epoch 73 loss: 0.9130780936104911                 accuracy: 0.9028571248054504
generator epoch 74 loss: 0.9132745387486049                 accuracy: 0.9035714268684387
generator epoch 75 loss: 0.9184908002580915                 accuracy: 0.8992857336997986
generator epoch 76 loss: 0.9125457580566406                 accuracy: 0.9064285755157471
generator epoch 77 loss: 0.9157117571149553                 accuracy: 0.9164285659790039
generator epoch 78 loss: 0.9175406685965402                 accuracy: 0.9057142734527588
generator epoch 79 loss: 0.9129335152762277                 accuracy: 0.918571412563324
generator epoch 80 loss: 0.9086889883858817                 accuracy: 0.9099999666213989
generator epoch 81 loss: 0.9110188127790179                 accuracy: 0.9035714268684387
generator epoch 82 loss: 0.9134201991489955                 accuracy: 0.9114285707473755
generator epoch 83 loss: 0.9152218139648437                 accuracy: 0.9049999713897705
generator epoch 84 loss: 0.9120792279924665                 accuracy: 0.8964285850524902
generator epoch 85 loss: 0.908494615827288                 accuracy: 0.9071428179740906
generator epoch 86 loss: 0.9079661420549665                 accuracy: 0.9071428179740906
generator epoch 87 loss: 0.9070716291155134                 accuracy: 0.9114285707473755
generator epoch 88 loss: 0.903677592250279                 accuracy: 0.8899999856948853
generator epoch 89 loss: 0.9047447474888393                 accuracy: 0.9157142639160156
generator epoch 90 loss: 0.9046419154575893                 accuracy: 0.9121428728103638
generator epoch 91 loss: 0.905674777657645                 accuracy: 0.9221428632736206
generator epoch 92 loss: 0.9013228262765067                 accuracy: 0.9285714030265808
generator epoch 93 loss: 0.9023389875139509                 accuracy: 0.9157142639160156
generator epoch 94 loss: 0.8953488691057477                 accuracy: 0.9164285659790039
generator epoch 95 loss: 0.9008709926060268                 accuracy: 0.9178571105003357
generator epoch 96 loss: 0.8997236868722098                 accuracy: 0.9064285755157471
generator epoch 97 loss: 0.9033614423479353                 accuracy: 0.9171428680419922
generator epoch 98 loss: 0.900290567452567                 accuracy: 0.9099999666213989
generator epoch 99 loss: 0.8969114955357143                 accuracy: 0.9149999618530273
generator epoch 100 loss: 0.8937880789620536                 accuracy: 0.918571412563324
generator epoch 101 loss: 0.8971432268415178                 accuracy: 0.9142857193946838
generator epoch 102 loss: 0.8957416530064174                 accuracy: 0.8914285898208618
generator epoch 103 loss: 0.90138115234375                 accuracy: 0.9071428179740906
generator epoch 104 loss: 0.898059769984654                 accuracy: 0.9128571152687073
generator epoch 105 loss: 0.8949452244349888                 accuracy: 0.9057142734527588
generator epoch 106 loss: 0.8912899448939732                 accuracy: 0.9164285659790039
generator epoch 107 loss: 0.8919929966517857                 accuracy: 0.9021428227424622
generator epoch 108 loss: 0.8925863699776786                 accuracy: 0.9121428728103638
generator epoch 109 loss: 0.894347065952846                 accuracy: 0.8949999809265137
generator epoch 110 loss: 0.8930106052943638                 accuracy: 0.9078571200370789
generator epoch 111 loss: 0.895656107875279                 accuracy: 0.9064285755157471
generator epoch 112 loss: 0.8947867797851563                 accuracy: 0.9135714173316956
generator epoch 113 loss: 0.8917230634416853                 accuracy: 0.9028571248054504
generator epoch 114 loss: 0.8896749302455357                 accuracy: 0.9178571105003357
generator epoch 115 loss: 0.8924833984375                 accuracy: 0.9149999618530273
generator epoch 116 loss: 0.8892196236746652                 accuracy: 0.9164285659790039
generator epoch 117 loss: 0.8947968444824219                 accuracy: 0.925000011920929
generator epoch 118 loss: 0.8912675258091518                 accuracy: 0.9157142639160156
generator epoch 119 loss: 0.8903973964146206                 accuracy: 0.8942856788635254
generator epoch 120 loss: 0.8876786150251116                 accuracy: 0.9200000166893005
generator epoch 121 loss: 0.8858360360281808                 accuracy: 0.9121428728103638
generator epoch 122 loss: 0.8928510846819196                 accuracy: 0.904285728931427
generator epoch 123 loss: 0.8859080392020089                 accuracy: 0.9142857193946838
generator epoch 124 loss: 0.8844636849539621                 accuracy: 0.9264285564422607
generator epoch 125 loss: 0.8832087454659598                 accuracy: 0.9300000071525574
generator epoch 126 loss: 0.8867631147112165                 accuracy: 0.9121428728103638
generator epoch 127 loss: 0.8858849993024553                 accuracy: 0.9264285564422607
generator epoch 128 loss: 0.8813043936593192                 accuracy: 0.9228571057319641
generator epoch 129 loss: 0.8814715087890626                 accuracy: 0.9035714268684387
generator epoch 130 loss: 0.8881519810267857                 accuracy: 0.9114285707473755
generator epoch 131 loss: 0.8873357561383929                 accuracy: 0.9107142686843872
generator epoch 132 loss: 0.8806093183244977                 accuracy: 0.9228571057319641
generator epoch 133 loss: 0.8852171657017299                 accuracy: 0.9035714268684387
generator epoch 134 loss: 0.885980122593471                 accuracy: 0.9057142734527588
generator epoch 135 loss: 0.8843161516462054                 accuracy: 0.9235714077949524
generator epoch 136 loss: 0.8812183907645089                 accuracy: 0.9200000166893005
generator epoch 137 loss: 0.8758132742745536                 accuracy: 0.9135714173316956
generator epoch 138 loss: 0.8793929670061383                 accuracy: 0.9285714030265808
generator epoch 139 loss: 0.8769973536900112                 accuracy: 0.9235714077949524
generator epoch 140 loss: 0.8782165736607143                 accuracy: 0.9200000166893005
generator epoch 141 loss: 0.8780704153878348                 accuracy: 0.9128571152687073
generator epoch 142 loss: 0.8743987104143415                 accuracy: 0.9128571152687073
generator epoch 143 loss: 0.8771870457240514                 accuracy: 0.8992857336997986
generator epoch 144 loss: 0.8819820922851562                 accuracy: 0.9228571057319641
generator epoch 145 loss: 0.8767932294573103                 accuracy: 0.918571412563324
generator epoch 146 loss: 0.8709164350237165                 accuracy: 0.8971428275108337
generator epoch 147 loss: 0.8860948826381139                 accuracy: 0.9399999976158142
generator epoch 148 loss: 0.8792567138671875                 accuracy: 0.9321428537368774
generator epoch 149 loss: 0.8750633954729352                 accuracy: 0.9221428632736206
generator epoch 150 loss: 0.8789837376185826                 accuracy: 0.9307142496109009
generator epoch 151 loss: 0.8750707885742187                 accuracy: 0.9214285612106323
generator epoch 152 loss: 0.8743278590611049                 accuracy: 0.9321428537368774
generator epoch 153 loss: 0.8743689862932478                 accuracy: 0.9114285707473755
generator epoch 154 loss: 0.8750263785226005                 accuracy: 0.9135714173316956
generator epoch 155 loss: 0.8747473066057477                 accuracy: 0.9292857050895691
generator epoch 156 loss: 0.8765445138113839                 accuracy: 0.918571412563324
generator epoch 157 loss: 0.8720600088936942                 accuracy: 0.9350000023841858
generator epoch 158 loss: 0.8786417585100447                 accuracy: 0.9285714030265808
generator epoch 159 loss: 0.8756173078264509                 accuracy: 0.925000011920929
generator epoch 160 loss: 0.872722860281808                 accuracy: 0.9278571605682373
generator epoch 161 loss: 0.8740007638113839                 accuracy: 0.920714259147644
generator epoch 162 loss: 0.8720005981445312                 accuracy: 0.9371428489685059
generator epoch 163 loss: 0.8657159415108817                 accuracy: 0.9285714030265808
generator epoch 164 loss: 0.8728251133510044                 accuracy: 0.9221428632736206
generator epoch 165 loss: 0.8686095755440848                 accuracy: 0.9321428537368774
generator epoch 166 loss: 0.8708294825962611                 accuracy: 0.9099999666213989
generator epoch 167 loss: 0.8650944798060826                 accuracy: 0.9228571057319641
generator epoch 168 loss: 0.8681666312081473                 accuracy: 0.9164285659790039
generator epoch 169 loss: 0.8695161525181362                 accuracy: 0.9099999666213989
generator epoch 170 loss: 0.868403125                 accuracy: 0.8907142877578735
generator epoch 171 loss: 0.8664635716029576                 accuracy: 0.9307142496109009
generator epoch 172 loss: 0.8666457554408482                 accuracy: 0.9242857098579407
generator epoch 173 loss: 0.873015207345145                 accuracy: 0.920714259147644
generator epoch 174 loss: 0.8629788417271206                 accuracy: 0.9350000023841858
generator epoch 175 loss: 0.8681911638532366                 accuracy: 0.9121428728103638
generator epoch 176 loss: 0.8683922415597098                 accuracy: 0.9192857146263123
generator epoch 177 loss: 0.8692018973214286                 accuracy: 0.9314285516738892
generator epoch 178 loss: 0.8672114135742187                 accuracy: 0.9407142996788025
generator epoch 179 loss: 0.8684822562081473                 accuracy: 0.904285728931427
generator epoch 180 loss: 0.8631825823102679                 accuracy: 0.9164285659790039
generator epoch 181 loss: 0.8662999712262834                 accuracy: 0.9157142639160156
generator epoch 182 loss: 0.8656971313476562                 accuracy: 0.9378571510314941
generator epoch 183 loss: 0.8701923810686384                 accuracy: 0.9192857146263123
generator epoch 184 loss: 0.8645856541224889                 accuracy: 0.9078571200370789
generator epoch 185 loss: 0.8709251935686384                 accuracy: 0.9357143044471741
generator epoch 186 loss: 0.8667479056222098                 accuracy: 0.9292857050895691
generator epoch 187 loss: 0.8622683698381697                 accuracy: 0.927142858505249
generator epoch 188 loss: 0.8627485586983817                 accuracy: 0.9307142496109009
generator epoch 189 loss: 0.8629395778111049                 accuracy: 0.9149999618530273
generator epoch 190 loss: 0.8597367684500558                 accuracy: 0.925000011920929
generator epoch 191 loss: 0.8645090427943638                 accuracy: 0.9164285659790039
generator epoch 192 loss: 0.8636908586774553                 accuracy: 0.9314285516738892
generator epoch 193 loss: 0.8631390284946987                 accuracy: 0.9292857050895691
generator epoch 194 loss: 0.8568804338727679                 accuracy: 0.9328571557998657
generator epoch 195 loss: 0.8616919416155134                 accuracy: 0.9335713982582092
generator epoch 196 loss: 0.859837992640904                 accuracy: 0.9099999666213989
generator epoch 197 loss: 0.8644517551967076                 accuracy: 0.9342857003211975
generator epoch 198 loss: 0.8645344430106027                 accuracy: 0.927142858505249
generator epoch 199 loss: 0.8717842825753348                 accuracy: 0.9350000023841858
generator epoch 200 loss: 0.8571955313546317                 accuracy: 0.925000011920929
generator epoch 201 loss: 0.8570335780552455                 accuracy: 0.9107142686843872
generator epoch 202 loss: 0.861493443952288                 accuracy: 0.9378571510314941
generator epoch 203 loss: 0.8633618068150112                 accuracy: 0.9157142639160156
generator epoch 204 loss: 0.8575138148716518                 accuracy: 0.9328571557998657
generator epoch 205 loss: 0.8540872584751674                 accuracy: 0.9264285564422607
generator epoch 206 loss: 0.8600246486118862                 accuracy: 0.9378571510314941
generator epoch 207 loss: 0.8547945452008928                 accuracy: 0.9228571057319641
generator epoch 208 loss: 0.8557408586774553                 accuracy: 0.9214285612106323
generator epoch 209 loss: 0.852251123046875                 accuracy: 0.9342857003211975
generator epoch 210 loss: 0.8572998011997768                 accuracy: 0.920714259147644
generator epoch 211 loss: 0.8533543422154017                 accuracy: 0.9300000071525574
generator epoch 212 loss: 0.8575089939662388                 accuracy: 0.9285714030265808
generator epoch 213 loss: 0.8594349827357701                 accuracy: 0.9278571605682373
generator epoch 214 loss: 0.8545183000837053                 accuracy: 0.9278571605682373
generator epoch 215 loss: 0.8533117457798549                 accuracy: 0.9028571248054504
generator epoch 216 loss: 0.8598275373186384                 accuracy: 0.9278571605682373
generator epoch 217 loss: 0.8541939592633928                 accuracy: 0.9171428680419922
generator epoch 218 loss: 0.8576380972726004                 accuracy: 0.9328571557998657
generator epoch 219 loss: 0.8564030020577567                 accuracy: 0.9149999618530273
generator epoch 220 loss: 0.8575353254045759                 accuracy: 0.9242857098579407
generator epoch 221 loss: 0.8586145699637276                 accuracy: 0.9121428728103638
generator epoch 222 loss: 0.8528972359793526                 accuracy: 0.9364285469055176
generator epoch 223 loss: 0.8515735866001675                 accuracy: 0.9407142996788025
generator epoch 224 loss: 0.8551534842354911                 accuracy: 0.9192857146263123
generator epoch 225 loss: 0.8600012451171875                 accuracy: 0.9292857050895691
generator epoch 226 loss: 0.8540257873535156                 accuracy: 0.9292857050895691
generator epoch 227 loss: 0.8502178161621093                 accuracy: 0.9364285469055176
generator epoch 228 loss: 0.8554385559082032                 accuracy: 0.9328571557998657
generator epoch 229 loss: 0.853497887311663                 accuracy: 0.9314285516738892
generator epoch 230 loss: 0.8521977059500558                 accuracy: 0.9364285469055176
generator epoch 231 loss: 0.8486685259137835                 accuracy: 0.9371428489685059
generator epoch 232 loss: 0.8503449340820313                 accuracy: 0.9350000023841858
generator epoch 233 loss: 0.8463525739397322                 accuracy: 0.9292857050895691
generator epoch 234 loss: 0.8487127685546875                 accuracy: 0.9335713982582092
generator epoch 235 loss: 0.8533924307686942                 accuracy: 0.941428542137146
generator epoch 236 loss: 0.8529707850864955                 accuracy: 0.9164285659790039
generator epoch 237 loss: 0.849306751360212                 accuracy: 0.9292857050895691
generator epoch 238 loss: 0.8497554173060826                 accuracy: 0.9300000071525574
generator epoch 239 loss: 0.8515906032017299                 accuracy: 0.9385713934898376
generator epoch 240 loss: 0.849887016078404                 accuracy: 0.9392856955528259
generator epoch 241 loss: 0.851838143484933                 accuracy: 0.9321428537368774
generator epoch 242 loss: 0.8548128243582589                 accuracy: 0.9378571510314941
generator epoch 243 loss: 0.8571430986676898                 accuracy: 0.9314285516738892
generator epoch 244 loss: 0.85206642804827                 accuracy: 0.9107142686843872
generator epoch 245 loss: 0.8484542035784041                 accuracy: 0.9135714173316956
generator epoch 246 loss: 0.8502746852329799                 accuracy: 0.9214285612106323
generator epoch 247 loss: 0.8487209978376116                 accuracy: 0.9257142543792725
generator epoch 248 loss: 0.8445830636160714                 accuracy: 0.9457142949104309
generator epoch 249 loss: 0.849082950265067                 accuracy: 0.927142858505249
generator epoch 250 loss: 0.8454267900739397                 accuracy: 0.9099999666213989
generator epoch 251 loss: 0.8501639430454799                 accuracy: 0.9200000166893005
generator epoch 252 loss: 0.8551296020507813                 accuracy: 0.9335713982582092
generator epoch 253 loss: 0.8483758693150112                 accuracy: 0.9449999928474426
generator epoch 254 loss: 0.8476760846819197                 accuracy: 0.925000011920929
generator epoch 255 loss: 0.8476763636997768                 accuracy: 0.9364285469055176
generator epoch 256 loss: 0.8494093375069754                 accuracy: 0.9385713934898376
generator epoch 257 loss: 0.8467265572684152                 accuracy: 0.9300000071525574
generator epoch 258 loss: 0.8448455845424108                 accuracy: 0.9228571057319641
generator epoch 259 loss: 0.8442309980119977                 accuracy: 0.9314285516738892
generator epoch 260 loss: 0.8474078639439174                 accuracy: 0.925000011920929
generator epoch 261 loss: 0.849287992640904                 accuracy: 0.918571412563324
generator epoch 262 loss: 0.8458406032017299                 accuracy: 0.9142857193946838
generator epoch 263 loss: 0.8440180943080358                 accuracy: 0.9314285516738892
generator epoch 264 loss: 0.8418419128417969                 accuracy: 0.9242857098579407
generator epoch 265 loss: 0.8399111764090402                 accuracy: 0.9278571605682373
generator epoch 266 loss: 0.847303209577288                 accuracy: 0.9292857050895691
generator epoch 267 loss: 0.840066024344308                 accuracy: 0.927142858505249
generator epoch 268 loss: 0.8433749720982143                 accuracy: 0.9307142496109009
generator epoch 269 loss: 0.8458270263671875                 accuracy: 0.9307142496109009
generator epoch 270 loss: 0.8443288312639509                 accuracy: 0.9214285612106323
generator epoch 271 loss: 0.8454268990652902                 accuracy: 0.920714259147644
generator epoch 272 loss: 0.8429134050641741                 accuracy: 0.9392856955528259
generator epoch 273 loss: 0.8410680803571429                 accuracy: 0.918571412563324
generator epoch 274 loss: 0.8396390546526228                 accuracy: 0.9342857003211975
generator epoch 275 loss: 0.8436519252232143                 accuracy: 0.9335713982582092
generator epoch 276 loss: 0.8371274117606027                 accuracy: 0.9342857003211975
generator epoch 277 loss: 0.8442601841517857                 accuracy: 0.9350000023841858
generator epoch 278 loss: 0.8470928545270647                 accuracy: 0.9407142996788025
generator epoch 279 loss: 0.84089089617048                 accuracy: 0.918571412563324
generator epoch 280 loss: 0.8446560939243861                 accuracy: 0.9164285659790039
generator epoch 281 loss: 0.8409771353585379                 accuracy: 0.920714259147644
generator epoch 282 loss: 0.8421322256905692                 accuracy: 0.9307142496109009
generator epoch 283 loss: 0.8482087690080915                 accuracy: 0.927142858505249
generator epoch 284 loss: 0.8399316310337611                 accuracy: 0.9342857003211975
generator epoch 285 loss: 0.8537195853097098                 accuracy: 0.9092857241630554
generator epoch 286 loss: 0.8455274954659598                 accuracy: 0.9178571105003357
generator epoch 287 loss: 0.8408470990862165                 accuracy: 0.9257142543792725
generator epoch 288 loss: 0.8408129717145647                 accuracy: 0.9214285612106323
generator epoch 289 loss: 0.8419937962123326                 accuracy: 0.9378571510314941
generator epoch 290 loss: 0.8364384652273995                 accuracy: 0.9385713934898376
generator epoch 291 loss: 0.8477524448939732                 accuracy: 0.9378571510314941
generator epoch 292 loss: 0.8392528555733817                 accuracy: 0.9278571605682373
generator epoch 293 loss: 0.8448525896344866                 accuracy: 0.9307142496109009
generator epoch 294 loss: 0.8438367213657925                 accuracy: 0.9357143044471741
generator epoch 295 loss: 0.8451283839634487                 accuracy: 0.9292857050895691
generator epoch 296 loss: 0.8440592895507812                 accuracy: 0.9471428394317627
generator epoch 297 loss: 0.8386745404924665                 accuracy: 0.9364285469055176
generator epoch 298 loss: 0.8382196655273437                 accuracy: 0.941428542137146
generator epoch 299 loss: 0.8386761003766741                 accuracy: 0.9449999928474426
generator epoch 300 loss: 0.8369906284877232                 accuracy: 0.9399999976158142
generator epoch 301 loss: 0.8369023175920759                 accuracy: 0.9178571105003357
generator epoch 302 loss: 0.8373797746930803                 accuracy: 0.9328571557998657
generator epoch 303 loss: 0.8377992693219866                 accuracy: 0.9471428394317627
generator epoch 304 loss: 0.8409013331821986                 accuracy: 0.9307142496109009
generator epoch 305 loss: 0.8373240426199777                 accuracy: 0.9457142949104309
generator epoch 306 loss: 0.8398113019670759                 accuracy: 0.9378571510314941
generator epoch 307 loss: 0.8323626037597657                 accuracy: 0.9328571557998657
generator epoch 308 loss: 0.8404846496582031                 accuracy: 0.9307142496109009
generator epoch 309 loss: 0.8347153433663504                 accuracy: 0.9264285564422607
generator epoch 310 loss: 0.8391640485491071                 accuracy: 0.925000011920929
generator epoch 311 loss: 0.8421816205705915                 accuracy: 0.925000011920929
generator epoch 312 loss: 0.8368013715471541                 accuracy: 0.9328571557998657
generator epoch 313 loss: 0.8379092494419643                 accuracy: 0.9314285516738892
generator epoch 314 loss: 0.8373535505022321                 accuracy: 0.9485714435577393
generator epoch 315 loss: 0.8330142325265067                 accuracy: 0.9328571557998657
generator epoch 316 loss: 0.8378225490025112                 accuracy: 0.9307142496109009
generator epoch 317 loss: 0.8372869541713169                 accuracy: 0.9235714077949524
generator epoch 318 loss: 0.8367587829589844                 accuracy: 0.9371428489685059
generator epoch 319 loss: 0.839159326171875                 accuracy: 0.9257142543792725
generator epoch 320 loss: 0.834159192766462                 accuracy: 0.9307142496109009
generator epoch 321 loss: 0.8412440333775112                 accuracy: 0.9085714221000671
generator epoch 322 loss: 0.8326043561662947                 accuracy: 0.9321428537368774
generator epoch 323 loss: 0.8333881574358258                 accuracy: 0.927142858505249
generator epoch 324 loss: 0.8354642953055246                 accuracy: 0.9514285326004028
generator epoch 325 loss: 0.8335451651436941                 accuracy: 0.9292857050895691
generator epoch 326 loss: 0.8347007542201451                 accuracy: 0.941428542137146
generator epoch 327 loss: 0.8378044538225446                 accuracy: 0.9221428632736206
generator epoch 328 loss: 0.8332995169503348                 accuracy: 0.9364285469055176
generator epoch 329 loss: 0.8349650285993303                 accuracy: 0.9357143044471741
generator epoch 330 loss: 0.8369994951520647                 accuracy: 0.9321428537368774
generator epoch 331 loss: 0.8366314130510603                 accuracy: 0.9307142496109009
generator epoch 332 loss: 0.831134579031808                 accuracy: 0.9307142496109009
generator epoch 333 loss: 0.8328507053920201                 accuracy: 0.9399999976158142
generator epoch 334 loss: 0.8327768075125558                 accuracy: 0.9407142996788025
generator epoch 335 loss: 0.8319707223074777                 accuracy: 0.9335713982582092
generator epoch 336 loss: 0.8257273877825055                 accuracy: 0.9421428442001343
generator epoch 337 loss: 0.8326907505580358                 accuracy: 0.9328571557998657
generator epoch 338 loss: 0.8349689130510602                 accuracy: 0.9421428442001343
generator epoch 339 loss: 0.8317003479003906                 accuracy: 0.947857141494751
generator epoch 340 loss: 0.8367250959123884                 accuracy: 0.9278571605682373
generator epoch 341 loss: 0.8367420314243862                 accuracy: 0.9385713934898376
generator epoch 342 loss: 0.836029434640067                 accuracy: 0.9242857098579407
generator epoch 343 loss: 0.8326314069475447                 accuracy: 0.9399999976158142
generator epoch 344 loss: 0.8384405543736049                 accuracy: 0.9300000071525574
generator epoch 345 loss: 0.8351361049107143                 accuracy: 0.9257142543792725
generator epoch 346 loss: 0.8345908490862165                 accuracy: 0.9357143044471741
generator epoch 347 loss: 0.826479048374721                 accuracy: 0.9357143044471741
generator epoch 348 loss: 0.8337409005301339                 accuracy: 0.9314285516738892
generator epoch 349 loss: 0.831701664515904                 accuracy: 0.9314285516738892
generator epoch 350 loss: 0.8301003086635045                 accuracy: 0.9357143044471741
generator epoch 351 loss: 0.8325603585379464                 accuracy: 0.9471428394317627
generator epoch 352 loss: 0.8294271135602679                 accuracy: 0.9428571462631226
generator epoch 353 loss: 0.8306812796456473                 accuracy: 0.9342857003211975
generator epoch 354 loss: 0.8344726553780693                 accuracy: 0.9235714077949524
generator epoch 355 loss: 0.826252366420201                 accuracy: 0.9364285469055176
generator epoch 356 loss: 0.8325271423339844                 accuracy: 0.9242857098579407
generator epoch 357 loss: 0.8308643345424107                 accuracy: 0.9392856955528259
generator epoch 358 loss: 0.826219526890346                 accuracy: 0.9314285516738892
generator epoch 359 loss: 0.8290818106515067                 accuracy: 0.9442856907844543
generator epoch 360 loss: 0.8318986982073102                 accuracy: 0.9399999976158142
generator epoch 361 loss: 0.8262514578683036                 accuracy: 0.9457142949104309
generator epoch 362 loss: 0.828356587437221                 accuracy: 0.941428542137146
generator epoch 363 loss: 0.8278769749232701                 accuracy: 0.9278571605682373
generator epoch 364 loss: 0.827399263218471                 accuracy: 0.9492856860160828
generator epoch 365 loss: 0.8268886012486049                 accuracy: 0.9421428442001343
generator epoch 366 loss: 0.8308851170131138                 accuracy: 0.9321428537368774
generator epoch 367 loss: 0.8330706263950893                 accuracy: 0.9242857098579407
generator epoch 368 loss: 0.825606583077567                 accuracy: 0.9399999976158142
generator epoch 369 loss: 0.8298908560616629                 accuracy: 0.941428542137146
generator epoch 370 loss: 0.8294891191755023                 accuracy: 0.9178571105003357
generator epoch 371 loss: 0.8290179050990514                 accuracy: 0.9357143044471741
generator epoch 372 loss: 0.827740434047154                 accuracy: 0.9278571605682373
generator epoch 373 loss: 0.8271873421805246                 accuracy: 0.925000011920929
generator epoch 374 loss: 0.8238760663713728                 accuracy: 0.949999988079071
generator epoch 375 loss: 0.8281580470493861                 accuracy: 0.9371428489685059
generator epoch 376 loss: 0.8324038827078684                 accuracy: 0.9378571510314941
generator epoch 377 loss: 0.8309462873186384                 accuracy: 0.9285714030265808
generator epoch 378 loss: 0.8283483075823103                 accuracy: 0.9321428537368774
generator epoch 379 loss: 0.8291964773995536                 accuracy: 0.9321428537368774
generator epoch 380 loss: 0.8273564243861607                 accuracy: 0.9321428537368774
generator epoch 381 loss: 0.8307911961146763                 accuracy: 0.9378571510314941
generator epoch 382 loss: 0.8260173086983817                 accuracy: 0.927142858505249
generator epoch 383 loss: 0.8280991271972656                 accuracy: 0.9449999928474426
generator epoch 384 loss: 0.8239668875558036                 accuracy: 0.9428571462631226
generator epoch 385 loss: 0.832006529889788                 accuracy: 0.9335713982582092
generator epoch 386 loss: 0.8264144374302456                 accuracy: 0.9492856860160828
generator epoch 387 loss: 0.8288379847935268                 accuracy: 0.9421428442001343
generator epoch 388 loss: 0.8349901663643973                 accuracy: 0.941428542137146
generator epoch 389 loss: 0.8273194859095983                 accuracy: 0.9421428442001343
generator epoch 390 loss: 0.8226938973563058                 accuracy: 0.9435713887214661
generator epoch 391 loss: 0.8273360447474888                 accuracy: 0.9528571367263794
generator epoch 392 loss: 0.8295001028878348                 accuracy: 0.9378571510314941
generator epoch 393 loss: 0.8274564095633371                 accuracy: 0.9385713934898376
generator epoch 394 loss: 0.8219908848353794                 accuracy: 0.9471428394317627
generator epoch 395 loss: 0.8258768842424665                 accuracy: 0.9314285516738892
generator epoch 396 loss: 0.8253889029366629                 accuracy: 0.9399999976158142
generator epoch 397 loss: 0.8260648655482701                 accuracy: 0.9364285469055176
generator epoch 398 loss: 0.8245408900669643                 accuracy: 0.9449999928474426
generator epoch 399 loss: 0.8277823050362724                 accuracy: 0.9371428489685059
generator epoch 400 loss: 0.8234461408342634                 accuracy: 0.9457142949104309
generator epoch 401 loss: 0.8194851196289062                 accuracy: 0.9464285373687744
generator epoch 402 loss: 0.8222920933314732                 accuracy: 0.9357143044471741
generator epoch 403 loss: 0.8301491847446987                 accuracy: 0.9371428489685059
generator epoch 404 loss: 0.8286223641531808                 accuracy: 0.9278571605682373
generator epoch 405 loss: 0.8267883937290736                 accuracy: 0.9342857003211975
generator epoch 406 loss: 0.8270403669084821                 accuracy: 0.9378571510314941
generator epoch 407 loss: 0.8332291407993861                 accuracy: 0.9221428632736206
generator epoch 408 loss: 0.8204430855887277                 accuracy: 0.9335713982582092
generator epoch 409 loss: 0.8230482875279018                 accuracy: 0.9278571605682373
generator epoch 410 loss: 0.821272208077567                 accuracy: 0.9385713934898376
generator epoch 411 loss: 0.8198493739536831                 accuracy: 0.9335713982582092
generator epoch 412 loss: 0.8270886213030134                 accuracy: 0.9314285516738892
generator epoch 413 loss: 0.8259435433523995                 accuracy: 0.941428542137146
generator epoch 414 loss: 0.8193995309012276                 accuracy: 0.9435713887214661
generator epoch 415 loss: 0.8237735682896206                 accuracy: 0.9392856955528259
generator epoch 416 loss: 0.8209970432826451                 accuracy: 0.9421428442001343
generator epoch 417 loss: 0.8262213091169085                 accuracy: 0.9357143044471741
generator epoch 418 loss: 0.8205363063267299                 accuracy: 0.9350000023841858
generator epoch 419 loss: 0.8247108982631138                 accuracy: 0.9364285469055176
generator epoch 420 loss: 0.8275319353376116                 accuracy: 0.9535714387893677
generator epoch 421 loss: 0.8217290631975447                 accuracy: 0.9385713934898376
generator epoch 422 loss: 0.8235370091029576                 accuracy: 0.9471428394317627
generator epoch 423 loss: 0.823134232875279                 accuracy: 0.9407142996788025
generator epoch 424 loss: 0.8245853018624442                 accuracy: 0.9171428680419922
generator epoch 425 loss: 0.8225373273577009                 accuracy: 0.9428571462631226
generator epoch 426 loss: 0.8229685738699777                 accuracy: 0.9399999976158142
generator epoch 427 loss: 0.8202313816615513                 accuracy: 0.9328571557998657
generator epoch 428 loss: 0.8183440726143973                 accuracy: 0.9449999928474426
generator epoch 429 loss: 0.8224323939732143                 accuracy: 0.9328571557998657
generator epoch 430 loss: 0.8205348720005581                 accuracy: 0.9178571105003357
generator epoch 431 loss: 0.8260441685267857                 accuracy: 0.9335713982582092
generator epoch 432 loss: 0.8273659606933593                 accuracy: 0.9164285659790039
generator epoch 433 loss: 0.8185448573521206                 accuracy: 0.9435713887214661
generator epoch 434 loss: 0.8216571725027901                 accuracy: 0.9314285516738892
generator epoch 435 loss: 0.8219586390904018                 accuracy: 0.949999988079071
generator epoch 436 loss: 0.8266251892089844                 accuracy: 0.9428571462631226
generator epoch 437 loss: 0.8199973510742188                 accuracy: 0.9442856907844543
generator epoch 438 loss: 0.8226172633579799                 accuracy: 0.9599999785423279
generator epoch 439 loss: 0.8223949689592633                 accuracy: 0.947857141494751
generator epoch 440 loss: 0.8208366768973214                 accuracy: 0.9507142901420593
generator epoch 441 loss: 0.822033220563616                 accuracy: 0.9328571557998657
generator epoch 442 loss: 0.8286350507463728                 accuracy: 0.9457142949104309
generator epoch 443 loss: 0.8233008675711495                 accuracy: 0.9442856907844543
generator epoch 444 loss: 0.8215607587541852                 accuracy: 0.9571428298950195
generator epoch 445 loss: 0.8263798950195312                 accuracy: 0.9321428537368774
generator epoch 446 loss: 0.8184044128417969                 accuracy: 0.9371428489685059
generator epoch 447 loss: 0.8215576372419084                 accuracy: 0.9407142996788025
generator epoch 448 loss: 0.8206110857282366                 accuracy: 0.9407142996788025
generator epoch 449 loss: 0.8217279427664621                 accuracy: 0.9399999976158142
generator epoch 450 loss: 0.8209537928989955                 accuracy: 0.9485714435577393
generator epoch 451 loss: 0.819354887172154                 accuracy: 0.9328571557998657
generator epoch 452 loss: 0.8226420061383929                 accuracy: 0.9378571510314941
generator epoch 453 loss: 0.8205289358956473                 accuracy: 0.9542856812477112
generator epoch 454 loss: 0.8178958513532366                 accuracy: 0.9328571557998657
generator epoch 455 loss: 0.8290274361746652                 accuracy: 0.9449999928474426
generator epoch 456 loss: 0.8203578848702567                 accuracy: 0.9300000071525574
generator epoch 457 loss: 0.827607874407087                 accuracy: 0.9449999928474426
generator epoch 458 loss: 0.8153312848772322                 accuracy: 0.9399999976158142
generator epoch 459 loss: 0.8174341857910157                 accuracy: 0.9492856860160828
generator epoch 460 loss: 0.8203385890415736                 accuracy: 0.9464285373687744
generator epoch 461 loss: 0.8182335170200893                 accuracy: 0.9557142853736877
generator epoch 462 loss: 0.8222100455147879                 accuracy: 0.9399999976158142
generator epoch 463 loss: 0.8204772086007255                 accuracy: 0.9335713982582092
generator epoch 464 loss: 0.8232610918317522                 accuracy: 0.9392856955528259
generator epoch 465 loss: 0.8197658534458705                 accuracy: 0.9399999976158142
generator epoch 466 loss: 0.8202211643763951                 accuracy: 0.9435713887214661
generator epoch 467 loss: 0.8212468584333147                 accuracy: 0.9385713934898376
generator epoch 468 loss: 0.8225269121442522                 accuracy: 0.9449999928474426
generator epoch 469 loss: 0.8195221296037947                 accuracy: 0.9350000023841858
generator epoch 470 loss: 0.8188595676967075                 accuracy: 0.9485714435577393
generator epoch 471 loss: 0.8139375383649553                 accuracy: 0.9364285469055176
generator epoch 472 loss: 0.8173551426478795                 accuracy: 0.9535714387893677
generator epoch 473 loss: 0.8177745396205357                 accuracy: 0.9364285469055176
generator epoch 474 loss: 0.8135621364048549                 accuracy: 0.9328571557998657
generator epoch 475 loss: 0.8209375854492188                 accuracy: 0.9350000023841858
generator epoch 476 loss: 0.822469722202846                 accuracy: 0.9300000071525574
generator epoch 477 loss: 0.8345180472237723                 accuracy: 0.9428571462631226
generator epoch 478 loss: 0.8190501133510044                 accuracy: 0.9328571557998657
generator epoch 479 loss: 0.814242631312779                 accuracy: 0.9335713982582092
generator epoch 480 loss: 0.8235905491420201                 accuracy: 0.9428571462631226
generator epoch 481 loss: 0.824302214704241                 accuracy: 0.9507142901420593
generator epoch 482 loss: 0.8166107491629464                 accuracy: 0.9457142949104309
generator epoch 483 loss: 0.8185261195591518                 accuracy: 0.9399999976158142
generator epoch 484 loss: 0.8198221749441964                 accuracy: 0.9442856907844543
generator epoch 485 loss: 0.8164709533691407                 accuracy: 0.9335713982582092
generator epoch 486 loss: 0.820078205217634                 accuracy: 0.9385713934898376
generator epoch 487 loss: 0.8171840009416853                 accuracy: 0.9435713887214661
generator epoch 488 loss: 0.8137350830078125                 accuracy: 0.9435713887214661
generator epoch 489 loss: 0.8167053327287946                 accuracy: 0.9399999976158142
generator epoch 490 loss: 0.815033016531808                 accuracy: 0.9392856955528259
generator epoch 491 loss: 0.815358842250279                 accuracy: 0.9399999976158142
generator epoch 492 loss: 0.8148231855119977                 accuracy: 0.9442856907844543
generator epoch 493 loss: 0.8127361703055246                 accuracy: 0.9292857050895691
generator epoch 494 loss: 0.8180413077218192                 accuracy: 0.949999988079071
generator epoch 495 loss: 0.8144512590680804                 accuracy: 0.9221428632736206
generator epoch 496 loss: 0.8143755004882812                 accuracy: 0.949999988079071
generator epoch 497 loss: 0.8188189618791852                 accuracy: 0.9507142901420593
generator epoch 498 loss: 0.815917081124442                 accuracy: 0.9385713934898376
generator epoch 499 loss: 0.8152364013671874                 accuracy: 0.9350000023841858
batch 0 train loss: [0.84894556]
batch 1 train loss: [0.69842714]
batch 2 train loss: [0.8099171]
batch 3 train loss: [0.74701]
batch 4 train loss: [0.7065793]
batch 5 train loss: [0.75566775]
batch 6 train loss: [0.82167107]
batch 7 train loss: [0.6325998]
batch 8 train loss: [0.74488336]
batch 9 train loss: [0.72322565]
batch 10 train loss: [0.7171088]
batch 11 train loss: [0.74492466]
batch 12 train loss: [0.7534591]
batch 13 train loss: [0.70808154]
batch 14 train loss: [0.64120597]
batch 15 train loss: [0.697298]
batch 16 train loss: [0.71488184]
batch 17 train loss: [0.7945532]
batch 18 train loss: [0.7360617]
batch 19 train loss: [0.67418253]
batch 20 train loss: [0.6873933]
batch 21 train loss: [0.6026127]
batch 22 train loss: [0.676329]
batch 23 train loss: [0.6649143]
batch 24 train loss: [0.738799]
batch 25 train loss: [0.6073616]
batch 26 train loss: [0.7608717]
batch 27 train loss: [0.7724726]
batch 28 train loss: [0.65432847]
batch 29 train loss: [0.7153462]
batch 30 train loss: [0.7994773]
batch 31 train loss: [0.6533799]
batch 32 train loss: [0.6840827]
batch 33 train loss: [0.74803466]
batch 34 train loss: [0.72303873]
batch 35 train loss: [0.7477204]
batch 36 train loss: [0.74266255]
batch 37 train loss: [0.65735507]
batch 38 train loss: [0.6832216]
batch 39 train loss: [0.7323154]
batch 40 train loss: [0.589071]
batch 41 train loss: [0.639135]
batch 42 train loss: [0.73439914]
batch 43 train loss: [0.63456583]
batch 44 train loss: [0.60121405]
batch 45 train loss: [0.66006434]
batch 46 train loss: [0.67725044]
batch 47 train loss: [0.55394506]
batch 48 train loss: [0.48775274]
batch 49 train loss: [0.62059224]
batch 50 train loss: [0.73874706]
batch 51 train loss: [0.7220208]
batch 52 train loss: [0.6371338]
batch 53 train loss: [0.6994145]
batch 54 train loss: [0.6975526]
batch 55 train loss: [0.6658053]
batch 56 train loss: [0.59751964]
batch 57 train loss: [0.6464836]
batch 58 train loss: [0.64071476]
batch 59 train loss: [0.6371872]
batch 60 train loss: [0.5814098]
batch 61 train loss: [0.75234234]
batch 62 train loss: [0.6181537]
batch 63 train loss: [0.60010225]
batch 64 train loss: [0.651674]
batch 65 train loss: [0.6270077]
batch 66 train loss: [0.6227621]
batch 67 train loss: [0.54351664]
batch 68 train loss: [0.67441094]
batch 69 train loss: [0.58003795]
batch 70 train loss: [0.71631044]
batch 71 train loss: [0.76542526]
batch 72 train loss: [0.6125328]
batch 73 train loss: [0.63376737]
batch 74 train loss: [0.6719548]
batch 75 train loss: [0.68517524]
batch 76 train loss: [0.5669983]
batch 77 train loss: [0.6857054]
batch 78 train loss: [0.68285334]
batch 79 train loss: [0.6740212]
batch 80 train loss: [0.6051444]
batch 81 train loss: [0.68831]
batch 82 train loss: [0.58332074]
batch 83 train loss: [0.6377429]
batch 84 train loss: [0.54291296]
batch 85 train loss: [0.6783435]
batch 86 train loss: [0.65410966]
batch 87 train loss: [0.6363598]
batch 88 train loss: [0.6008823]
batch 89 train loss: [0.58497494]
batch 90 train loss: [0.60161245]
batch 91 train loss: [0.66661245]
batch 92 train loss: [0.77931964]
batch 93 train loss: [0.5889608]
batch 94 train loss: [0.58790207]
batch 95 train loss: [0.6742327]
batch 96 train loss: [0.6449158]
batch 97 train loss: [0.6137084]
batch 98 train loss: [0.6596762]
batch 99 train loss: [0.6336477]
epoch 0 mean train loss: [0.67211807]
Epoch 0/400=>  train_loss: [0.67211807], iou: nan, cd: 2.8860221287823804, test_mse: [0.60556626]
CORRECT PROGRAMS: 9833
batch 0 train loss: [0.6311368]
batch 1 train loss: [0.53024685]
batch 2 train loss: [0.6219509]
batch 3 train loss: [0.54259384]
batch 4 train loss: [0.5821236]
batch 5 train loss: [0.59778416]
batch 6 train loss: [0.5408351]
batch 7 train loss: [0.5295949]
batch 8 train loss: [0.5941174]
batch 9 train loss: [0.5997814]
batch 10 train loss: [0.52065635]
batch 11 train loss: [0.61452097]
batch 12 train loss: [0.6060693]
batch 13 train loss: [0.49364728]
batch 14 train loss: [0.57535833]
batch 15 train loss: [0.51312816]
batch 16 train loss: [0.547107]
batch 17 train loss: [0.57421446]
batch 18 train loss: [0.5214242]
batch 19 train loss: [0.5028813]
batch 20 train loss: [0.41716143]
batch 21 train loss: [0.56370234]
batch 22 train loss: [0.6076893]
batch 23 train loss: [0.5238428]
batch 24 train loss: [0.48085144]
batch 25 train loss: [0.569956]
batch 26 train loss: [0.580502]
batch 27 train loss: [0.535398]
batch 28 train loss: [0.5258737]
batch 29 train loss: [0.5181897]
batch 30 train loss: [0.5518122]
batch 31 train loss: [0.49140805]
batch 32 train loss: [0.5725671]
batch 33 train loss: [0.5121697]
batch 34 train loss: [0.5067727]
batch 35 train loss: [0.54773325]
batch 36 train loss: [0.6151407]
batch 37 train loss: [0.5190913]
batch 38 train loss: [0.569513]
batch 39 train loss: [0.59535974]
batch 40 train loss: [0.54754305]
batch 41 train loss: [0.46042526]
batch 42 train loss: [0.50296104]
batch 43 train loss: [0.5196373]
batch 44 train loss: [0.48347887]
batch 45 train loss: [0.58359545]
batch 46 train loss: [0.6662128]
batch 47 train loss: [0.58219]
batch 48 train loss: [0.5745394]
batch 49 train loss: [0.5571928]
batch 50 train loss: [0.59114975]
batch 51 train loss: [0.63984615]
batch 52 train loss: [0.5552747]
batch 53 train loss: [0.60654664]
batch 54 train loss: [0.5706754]
batch 55 train loss: [0.5566957]
batch 56 train loss: [0.5101891]
batch 57 train loss: [0.48667267]
batch 58 train loss: [0.51268345]
batch 59 train loss: [0.56566495]
batch 60 train loss: [0.55860144]
batch 61 train loss: [0.5628247]
batch 62 train loss: [0.52318734]
batch 63 train loss: [0.45630282]
batch 64 train loss: [0.60079604]
batch 65 train loss: [0.60524416]
batch 66 train loss: [0.56143427]
batch 67 train loss: [0.5503998]
batch 68 train loss: [0.61719894]
batch 69 train loss: [0.58906066]
batch 70 train loss: [0.54918945]
batch 71 train loss: [0.59227633]
batch 72 train loss: [0.52060276]
batch 73 train loss: [0.6546786]
batch 74 train loss: [0.5912182]
batch 75 train loss: [0.5789684]
batch 76 train loss: [0.606623]
batch 77 train loss: [0.56998175]
batch 78 train loss: [0.5947316]
batch 79 train loss: [0.56229144]
batch 80 train loss: [0.58389044]
batch 81 train loss: [0.5599904]
batch 82 train loss: [0.58336514]
batch 83 train loss: [0.5540747]
batch 84 train loss: [0.49319524]
batch 85 train loss: [0.52385956]
batch 86 train loss: [0.5161089]
batch 87 train loss: [0.67209536]
batch 88 train loss: [0.5313086]
batch 89 train loss: [0.5362915]
batch 90 train loss: [0.5148217]
batch 91 train loss: [0.56282115]
batch 92 train loss: [0.56660885]
batch 93 train loss: [0.46067733]
batch 94 train loss: [0.51288867]
batch 95 train loss: [0.52368706]
batch 96 train loss: [0.5515997]
batch 97 train loss: [0.58488667]
batch 98 train loss: [0.4826042]
batch 99 train loss: [0.6149933]
epoch 1 mean train loss: [0.5549246]
Epoch 1/400=>  train_loss: [0.5549246], iou: nan, cd: 2.7708776928227237, test_mse: [0.5578454]
CORRECT PROGRAMS: 9833
batch 0 train loss: [0.48625398]
batch 1 train loss: [0.47476923]
batch 2 train loss: [0.47695163]
batch 3 train loss: [0.5303082]
batch 4 train loss: [0.4786183]
batch 5 train loss: [0.5539123]
batch 6 train loss: [0.49112207]
batch 7 train loss: [0.47416815]
batch 8 train loss: [0.5090356]
batch 9 train loss: [0.47701815]
batch 10 train loss: [0.4650922]
batch 11 train loss: [0.48949936]
batch 12 train loss: [0.54582304]
batch 13 train loss: [0.42389873]
batch 14 train loss: [0.5429651]
batch 15 train loss: [0.585453]
batch 16 train loss: [0.52398515]
batch 17 train loss: [0.38582242]
batch 18 train loss: [0.4829983]
batch 19 train loss: [0.43599194]
batch 20 train loss: [0.40758803]
batch 21 train loss: [0.5659218]
batch 22 train loss: [0.4782675]
batch 23 train loss: [0.5012913]
batch 24 train loss: [0.47651294]
batch 25 train loss: [0.57330716]
batch 26 train loss: [0.49709263]
batch 27 train loss: [0.57256496]
batch 28 train loss: [0.49520946]
batch 29 train loss: [0.4772654]
batch 30 train loss: [0.5784806]
batch 31 train loss: [0.4518637]
batch 32 train loss: [0.5434561]
batch 33 train loss: [0.4394434]
batch 34 train loss: [0.43141398]
batch 35 train loss: [0.42072928]
batch 36 train loss: [0.59831464]
batch 37 train loss: [0.49729562]
batch 38 train loss: [0.4836162]
batch 39 train loss: [0.47775513]
batch 40 train loss: [0.48645052]
batch 41 train loss: [0.41789022]
batch 42 train loss: [0.41796005]
batch 43 train loss: [0.5250889]
batch 44 train loss: [0.5615512]
batch 45 train loss: [0.48283285]
batch 46 train loss: [0.5110997]
batch 47 train loss: [0.5191912]
batch 48 train loss: [0.4006515]
batch 49 train loss: [0.51258105]
batch 50 train loss: [0.46104774]
batch 51 train loss: [0.5098849]
batch 52 train loss: [0.49493042]
batch 53 train loss: [0.57398546]
batch 54 train loss: [0.48431998]
batch 55 train loss: [0.48621607]
batch 56 train loss: [0.5136368]
batch 57 train loss: [0.47732106]
batch 58 train loss: [0.5005461]
batch 59 train loss: [0.5579413]
batch 60 train loss: [0.5669143]
batch 61 train loss: [0.4850632]
batch 62 train loss: [0.531973]
batch 63 train loss: [0.49939328]
batch 64 train loss: [0.54579127]
batch 65 train loss: [0.6160696]
batch 66 train loss: [0.4936858]
batch 67 train loss: [0.45169365]
batch 68 train loss: [0.52143407]
batch 69 train loss: [0.46462452]
batch 70 train loss: [0.51716375]
batch 71 train loss: [0.46031314]
batch 72 train loss: [0.49440947]
batch 73 train loss: [0.52273834]
batch 74 train loss: [0.5051645]
batch 75 train loss: [0.54314435]
batch 76 train loss: [0.4869605]
batch 77 train loss: [0.52180856]
batch 78 train loss: [0.47398004]
batch 79 train loss: [0.5207602]
batch 80 train loss: [0.4679432]
batch 81 train loss: [0.47644365]
batch 82 train loss: [0.4529334]
batch 83 train loss: [0.50064474]
batch 84 train loss: [0.462637]
batch 85 train loss: [0.4623273]
batch 86 train loss: [0.5360557]
batch 87 train loss: [0.48221698]
batch 88 train loss: [0.6403588]
batch 89 train loss: [0.49746206]
batch 90 train loss: [0.46065938]
batch 91 train loss: [0.39543897]
batch 92 train loss: [0.49222496]
batch 93 train loss: [0.5120296]
batch 94 train loss: [0.47789696]
batch 95 train loss: [0.5327183]
batch 96 train loss: [0.4843046]
batch 97 train loss: [0.52481073]
batch 98 train loss: [0.52357537]
batch 99 train loss: [0.49396524]
epoch 2 mean train loss: [0.49795935]
Epoch 2/400=>  train_loss: [0.49795935], iou: nan, cd: 2.683857156028422, test_mse: [0.53894377]
CORRECT PROGRAMS: 9833
batch 0 train loss: [0.38969818]
batch 1 train loss: [0.41535032]
batch 2 train loss: [0.4449204]
batch 3 train loss: [0.49225035]
batch 4 train loss: [0.4166011]
batch 5 train loss: [0.50653607]
batch 6 train loss: [0.4851849]
batch 7 train loss: [0.40878174]
batch 8 train loss: [0.5117844]
batch 9 train loss: [0.45021552]
batch 10 train loss: [0.44497848]
batch 11 train loss: [0.5035972]
batch 12 train loss: [0.40706766]
batch 13 train loss: [0.44208893]
batch 14 train loss: [0.47803932]
batch 15 train loss: [0.41953415]
batch 16 train loss: [0.47636616]
batch 17 train loss: [0.4075533]
batch 18 train loss: [0.46675283]
batch 19 train loss: [0.39590544]
batch 20 train loss: [0.35139102]
batch 21 train loss: [0.4632255]
batch 22 train loss: [0.40660712]
batch 23 train loss: [0.38357073]
batch 24 train loss: [0.501306]
batch 25 train loss: [0.5183415]
batch 26 train loss: [0.42302153]
batch 27 train loss: [0.44957379]
batch 28 train loss: [0.34919137]
batch 29 train loss: [0.49336976]
batch 30 train loss: [0.42290673]
batch 31 train loss: [0.43557853]
batch 32 train loss: [0.49241117]
batch 33 train loss: [0.50741094]
batch 34 train loss: [0.42649922]
batch 35 train loss: [0.42548272]
batch 36 train loss: [0.42878425]
batch 37 train loss: [0.3808375]
batch 38 train loss: [0.48010853]
batch 39 train loss: [0.4271169]
batch 40 train loss: [0.38177565]
batch 41 train loss: [0.42012736]
batch 42 train loss: [0.50193125]
batch 43 train loss: [0.40356305]
batch 44 train loss: [0.4291684]
batch 45 train loss: [0.4456061]
batch 46 train loss: [0.4737537]
batch 47 train loss: [0.39816698]
batch 48 train loss: [0.4514824]
batch 49 train loss: [0.4383766]
batch 50 train loss: [0.41653714]
batch 51 train loss: [0.49306095]
batch 52 train loss: [0.4278421]
batch 53 train loss: [0.40541446]
batch 54 train loss: [0.533604]
batch 55 train loss: [0.50307894]
batch 56 train loss: [0.5063321]
batch 57 train loss: [0.47575778]
batch 58 train loss: [0.4479967]
batch 59 train loss: [0.43950823]
batch 60 train loss: [0.46935543]
batch 61 train loss: [0.47969827]
batch 62 train loss: [0.4886996]
batch 63 train loss: [0.47442612]
batch 64 train loss: [0.5153677]
batch 65 train loss: [0.48147243]
batch 66 train loss: [0.48393542]
batch 67 train loss: [0.5672983]
batch 68 train loss: [0.3607963]
batch 69 train loss: [0.48192066]
batch 70 train loss: [0.38610417]
batch 71 train loss: [0.38936022]
batch 72 train loss: [0.41881534]
batch 73 train loss: [0.47426394]
batch 74 train loss: [0.43373674]
batch 75 train loss: [0.5170858]
batch 76 train loss: [0.43812618]
batch 77 train loss: [0.45339116]
batch 78 train loss: [0.45631403]
batch 79 train loss: [0.5095174]
batch 80 train loss: [0.47766978]
batch 81 train loss: [0.43004876]
batch 82 train loss: [0.45832327]
batch 83 train loss: [0.44424877]
batch 84 train loss: [0.49494272]
batch 85 train loss: [0.4601406]
batch 86 train loss: [0.5088956]
batch 87 train loss: [0.46544823]
batch 88 train loss: [0.46084157]
batch 89 train loss: [0.4743477]
batch 90 train loss: [0.4799164]
batch 91 train loss: [0.5010287]
batch 92 train loss: [0.48801738]
batch 93 train loss: [0.5083605]
batch 94 train loss: [0.42492712]
batch 95 train loss: [0.4540442]
batch 96 train loss: [0.42130816]
batch 97 train loss: [0.44185203]
batch 98 train loss: [0.4671003]
batch 99 train loss: [0.49904826]
epoch 3 mean train loss: [0.45363212]
Epoch 3/400=>  train_loss: [0.45363212], iou: nan, cd: 2.8635662917589633, test_mse: [0.56631243]
CORRECT PROGRAMS: 9833
batch 0 train loss: [0.5261141]
batch 1 train loss: [0.41758344]
batch 2 train loss: [0.4531385]
batch 3 train loss: [0.41890672]
batch 4 train loss: [0.43374112]
batch 5 train loss: [0.36140612]
batch 6 train loss: [0.37681907]
batch 7 train loss: [0.38795093]
batch 8 train loss: [0.44289982]
batch 9 train loss: [0.36934963]
batch 10 train loss: [0.3926349]
batch 11 train loss: [0.40964094]
batch 12 train loss: [0.409223]
batch 13 train loss: [0.38854876]
batch 14 train loss: [0.3669184]
batch 15 train loss: [0.3977057]
batch 16 train loss: [0.39336732]
batch 17 train loss: [0.44740617]
batch 18 train loss: [0.45304662]
batch 19 train loss: [0.48359475]
batch 20 train loss: [0.48537484]
batch 21 train loss: [0.45987684]
batch 22 train loss: [0.44250077]
batch 23 train loss: [0.41305962]
batch 24 train loss: [0.3994814]
batch 25 train loss: [0.46365008]
batch 26 train loss: [0.36904106]
batch 27 train loss: [0.4907215]
batch 28 train loss: [0.3795443]
batch 29 train loss: [0.35091293]
batch 30 train loss: [0.45513824]
batch 31 train loss: [0.41043296]
batch 32 train loss: [0.3583327]
batch 33 train loss: [0.40197018]
batch 34 train loss: [0.4268492]
batch 35 train loss: [0.37996924]
batch 36 train loss: [0.38014767]
batch 37 train loss: [0.4559939]
batch 38 train loss: [0.46315604]
batch 39 train loss: [0.38342318]
batch 40 train loss: [0.49873435]
batch 41 train loss: [0.4012347]
batch 42 train loss: [0.40995347]
batch 43 train loss: [0.41194874]
batch 44 train loss: [0.48440173]
batch 45 train loss: [0.41769797]
batch 46 train loss: [0.30346096]
batch 47 train loss: [0.36177006]
batch 48 train loss: [0.457716]
batch 49 train loss: [0.39587063]
batch 50 train loss: [0.46080536]
batch 51 train loss: [0.3838747]
batch 52 train loss: [0.38225585]
batch 53 train loss: [0.40580332]
batch 54 train loss: [0.40625903]
batch 55 train loss: [0.3899118]
batch 56 train loss: [0.41670406]
batch 57 train loss: [0.43759155]
batch 58 train loss: [0.40308958]
batch 59 train loss: [0.43969253]
batch 60 train loss: [0.43263632]
batch 61 train loss: [0.44648913]
batch 62 train loss: [0.45492277]
batch 63 train loss: [0.46613872]
batch 64 train loss: [0.46073186]
batch 65 train loss: [0.42869958]
batch 66 train loss: [0.3801296]
batch 67 train loss: [0.38941485]
batch 68 train loss: [0.43008116]
batch 69 train loss: [0.4361645]
batch 70 train loss: [0.41698438]
batch 71 train loss: [0.47321168]
batch 72 train loss: [0.42040473]
batch 73 train loss: [0.41864768]
batch 74 train loss: [0.42325652]
batch 75 train loss: [0.53126234]
batch 76 train loss: [0.43514055]
batch 77 train loss: [0.38501018]
batch 78 train loss: [0.44144607]
batch 79 train loss: [0.45637664]
batch 80 train loss: [0.42588413]
batch 81 train loss: [0.40606835]
batch 82 train loss: [0.486316]
batch 83 train loss: [0.4362902]
batch 84 train loss: [0.3760126]
batch 85 train loss: [0.383217]
batch 86 train loss: [0.4491442]
batch 87 train loss: [0.42055053]
batch 88 train loss: [0.43434232]
batch 89 train loss: [0.47003463]
batch 90 train loss: [0.34924188]
batch 91 train loss: [0.41998857]
batch 92 train loss: [0.4227139]
batch 93 train loss: [0.42983714]
batch 94 train loss: [0.38491374]
batch 95 train loss: [0.4696785]
batch 96 train loss: [0.48742944]
batch 97 train loss: [0.43240646]
batch 98 train loss: [0.40828285]
batch 99 train loss: [0.44998768]
epoch 4 mean train loss: [0.42237833]
Epoch 4/400=>  train_loss: [0.42237833], iou: nan, cd: 2.6343456775762855, test_mse: [0.545256]
CORRECT PROGRAMS: 9833
batch 0 train loss: [0.39101225]
batch 1 train loss: [0.4653409]
batch 2 train loss: [0.37081322]
batch 3 train loss: [0.42445102]
batch 4 train loss: [0.38484523]
batch 5 train loss: [0.37534457]
batch 6 train loss: [0.42238414]
batch 7 train loss: [0.44102958]
batch 8 train loss: [0.38596603]
batch 9 train loss: [0.41396105]
batch 10 train loss: [0.40213257]
batch 11 train loss: [0.39100412]
batch 12 train loss: [0.34056088]
batch 13 train loss: [0.390645]
batch 14 train loss: [0.41413027]
batch 15 train loss: [0.3174597]
batch 16 train loss: [0.4000873]
batch 17 train loss: [0.41189793]
batch 18 train loss: [0.38842237]
batch 19 train loss: [0.4709164]
batch 20 train loss: [0.48477232]
batch 21 train loss: [0.3586511]
batch 22 train loss: [0.39059183]
batch 23 train loss: [0.36051926]
batch 24 train loss: [0.36914545]
batch 25 train loss: [0.43166623]
batch 26 train loss: [0.34482944]
batch 27 train loss: [0.35530573]
batch 28 train loss: [0.44214025]
batch 29 train loss: [0.37085858]
batch 30 train loss: [0.3287403]
batch 31 train loss: [0.36005625]
batch 32 train loss: [0.3986142]
batch 33 train loss: [0.38407534]
batch 34 train loss: [0.312353]
batch 35 train loss: [0.46856797]
batch 36 train loss: [0.4524178]
batch 37 train loss: [0.41818908]
batch 38 train loss: [0.35126674]
batch 39 train loss: [0.4080529]
batch 40 train loss: [0.3868136]
batch 41 train loss: [0.37214264]
batch 42 train loss: [0.46616277]
batch 43 train loss: [0.436276]
batch 44 train loss: [0.43775123]
batch 45 train loss: [0.3852463]
batch 46 train loss: [0.3661589]
batch 47 train loss: [0.4731462]
batch 48 train loss: [0.4461566]
batch 49 train loss: [0.3751919]
batch 50 train loss: [0.4707769]
batch 51 train loss: [0.37268588]
batch 52 train loss: [0.3955674]
batch 53 train loss: [0.31120202]
batch 54 train loss: [0.41780046]
batch 55 train loss: [0.32898042]
batch 56 train loss: [0.32832953]
batch 57 train loss: [0.3900107]
batch 58 train loss: [0.41090837]
batch 59 train loss: [0.47075036]
batch 60 train loss: [0.37687796]
batch 61 train loss: [0.36884376]
batch 62 train loss: [0.34683183]
batch 63 train loss: [0.33856615]
batch 64 train loss: [0.4319275]
batch 65 train loss: [0.41395035]
batch 66 train loss: [0.3519215]
batch 67 train loss: [0.39501032]
batch 68 train loss: [0.39740974]
batch 69 train loss: [0.3962688]
batch 70 train loss: [0.4574399]
batch 71 train loss: [0.41674224]
batch 72 train loss: [0.3778632]
batch 73 train loss: [0.34080634]
batch 74 train loss: [0.37409407]
batch 75 train loss: [0.45532417]
batch 76 train loss: [0.40205744]
batch 77 train loss: [0.4190046]
batch 78 train loss: [0.36522466]
batch 79 train loss: [0.39659402]
batch 80 train loss: [0.4069642]
batch 81 train loss: [0.37072447]
batch 82 train loss: [0.40155557]
batch 83 train loss: [0.37433326]
batch 84 train loss: [0.37619862]
batch 85 train loss: [0.3821092]
batch 86 train loss: [0.37998757]
batch 87 train loss: [0.346141]
batch 88 train loss: [0.4602957]
batch 89 train loss: [0.4649127]
batch 90 train loss: [0.36650375]
batch 91 train loss: [0.45040098]
batch 92 train loss: [0.36370638]
batch 93 train loss: [0.341149]
batch 94 train loss: [0.48664692]
batch 95 train loss: [0.46572867]
batch 96 train loss: [0.4315347]
batch 97 train loss: [0.34677598]
batch 98 train loss: [0.39069733]
batch 99 train loss: [0.3751392]
epoch 5 mean train loss: [0.39639533]
Epoch 5/400=>  train_loss: [0.39639533], iou: nan, cd: 2.654235730725847, test_mse: [0.5265419]
CORRECT PROGRAMS: 9833
batch 0 train loss: [0.26760396]
batch 1 train loss: [0.35452196]
batch 2 train loss: [0.3143652]
batch 3 train loss: [0.3762909]
batch 4 train loss: [0.39747676]
batch 5 train loss: [0.34526852]
batch 6 train loss: [0.42064634]
batch 7 train loss: [0.32585517]
batch 8 train loss: [0.42369482]
batch 9 train loss: [0.3889398]
batch 10 train loss: [0.35832822]
batch 11 train loss: [0.33648327]
batch 12 train loss: [0.30978376]
batch 13 train loss: [0.34714925]
batch 14 train loss: [0.4068926]
batch 15 train loss: [0.3517017]
batch 16 train loss: [0.39438692]
batch 17 train loss: [0.3560581]
batch 18 train loss: [0.40872872]
batch 19 train loss: [0.37544072]
batch 20 train loss: [0.34136727]
batch 21 train loss: [0.36402124]
batch 22 train loss: [0.33521298]
batch 23 train loss: [0.42325363]
batch 24 train loss: [0.32285172]
batch 25 train loss: [0.3357006]
batch 26 train loss: [0.40677512]
batch 27 train loss: [0.40613607]
batch 28 train loss: [0.38655913]
batch 29 train loss: [0.36085975]
batch 30 train loss: [0.37155324]
batch 31 train loss: [0.2733048]
batch 32 train loss: [0.3885337]
batch 33 train loss: [0.3845394]
batch 34 train loss: [0.3759505]
batch 35 train loss: [0.311387]
batch 36 train loss: [0.33752295]
batch 37 train loss: [0.42322382]
batch 38 train loss: [0.43712893]
batch 39 train loss: [0.34643218]
batch 40 train loss: [0.36034906]
batch 41 train loss: [0.3861875]
batch 42 train loss: [0.33768514]
batch 43 train loss: [0.43379053]
batch 44 train loss: [0.3665674]
batch 45 train loss: [0.31626123]
batch 46 train loss: [0.3697386]
batch 47 train loss: [0.33023202]
batch 48 train loss: [0.37837964]
batch 49 train loss: [0.3999655]
batch 50 train loss: [0.38607013]
batch 51 train loss: [0.3520637]
batch 52 train loss: [0.35747114]
batch 53 train loss: [0.33500755]
batch 54 train loss: [0.33954063]
batch 55 train loss: [0.32774556]
batch 56 train loss: [0.43777195]
batch 57 train loss: [0.38473913]
batch 58 train loss: [0.31550378]
batch 59 train loss: [0.34061736]
batch 60 train loss: [0.31746832]
batch 61 train loss: [0.36868912]
batch 62 train loss: [0.39712766]
batch 63 train loss: [0.32640043]
batch 64 train loss: [0.37257108]
batch 65 train loss: [0.35004038]
batch 66 train loss: [0.37510863]
batch 67 train loss: [0.3949733]
batch 68 train loss: [0.4307006]
batch 69 train loss: [0.41129336]
batch 70 train loss: [0.38583264]
batch 71 train loss: [0.39577088]
batch 72 train loss: [0.39915708]
batch 73 train loss: [0.3927318]
batch 74 train loss: [0.383134]
batch 75 train loss: [0.36903724]
batch 76 train loss: [0.34894946]
batch 77 train loss: [0.41518417]
batch 78 train loss: [0.3724249]
batch 79 train loss: [0.32801977]
batch 80 train loss: [0.31182665]
batch 81 train loss: [0.4746336]
batch 82 train loss: [0.38907155]
batch 83 train loss: [0.39351434]
batch 84 train loss: [0.32204747]
batch 85 train loss: [0.380634]
batch 86 train loss: [0.35369098]
batch 87 train loss: [0.37202254]
batch 88 train loss: [0.37954536]
batch 89 train loss: [0.39912495]
batch 90 train loss: [0.37474063]
batch 91 train loss: [0.4208804]
batch 92 train loss: [0.3581076]
batch 93 train loss: [0.3690847]
batch 94 train loss: [0.34511453]
batch 95 train loss: [0.42903173]
batch 96 train loss: [0.3428851]
batch 97 train loss: [0.40398043]
batch 98 train loss: [0.38848582]
batch 99 train loss: [0.43459776]
epoch 6 mean train loss: [0.37025255]
Epoch 6/400=>  train_loss: [0.37025255], iou: nan, cd: 2.6147330426507036, test_mse: [0.5339291]
CORRECT PROGRAMS: 9833
batch 0 train loss: [0.2986618]
batch 1 train loss: [0.2839732]
batch 2 train loss: [0.35487735]
batch 3 train loss: [0.34617582]
batch 4 train loss: [0.30482984]
batch 5 train loss: [0.29299724]
batch 6 train loss: [0.33332562]
batch 7 train loss: [0.37654665]
batch 8 train loss: [0.31123516]
batch 9 train loss: [0.347155]
batch 10 train loss: [0.31803462]
batch 11 train loss: [0.3601921]
batch 12 train loss: [0.33271623]
batch 13 train loss: [0.29425752]
batch 14 train loss: [0.31246987]
batch 15 train loss: [0.33109307]
batch 16 train loss: [0.36132273]
batch 17 train loss: [0.3516608]
batch 18 train loss: [0.25433567]
batch 19 train loss: [0.3390428]
batch 20 train loss: [0.32461333]
batch 21 train loss: [0.320997]
batch 22 train loss: [0.39334407]
batch 23 train loss: [0.26847062]
batch 24 train loss: [0.35931367]
batch 25 train loss: [0.37229058]
batch 26 train loss: [0.3261423]
batch 27 train loss: [0.35596138]
batch 28 train loss: [0.36233482]
batch 29 train loss: [0.32721254]
batch 30 train loss: [0.37567627]
batch 31 train loss: [0.28311354]
batch 32 train loss: [0.3347642]
batch 33 train loss: [0.3729567]
batch 34 train loss: [0.35132137]
batch 35 train loss: [0.3641222]
batch 36 train loss: [0.35163152]
batch 37 train loss: [0.34464705]
batch 38 train loss: [0.42157114]
batch 39 train loss: [0.3504288]
batch 40 train loss: [0.4041529]
batch 41 train loss: [0.3879182]
batch 42 train loss: [0.31239668]
batch 43 train loss: [0.3645677]
batch 44 train loss: [0.37994367]
batch 45 train loss: [0.3465049]
batch 46 train loss: [0.32077748]
batch 47 train loss: [0.3622648]
batch 48 train loss: [0.33509487]
batch 49 train loss: [0.3660393]
batch 50 train loss: [0.3555247]
batch 51 train loss: [0.40787843]
batch 52 train loss: [0.35865632]
batch 53 train loss: [0.33309406]
batch 54 train loss: [0.36961266]
batch 55 train loss: [0.45694607]
batch 56 train loss: [0.35515913]
batch 57 train loss: [0.2994917]
batch 58 train loss: [0.33629787]
batch 59 train loss: [0.33338434]
batch 60 train loss: [0.3691525]
batch 61 train loss: [0.35166204]
batch 62 train loss: [0.3683296]
batch 63 train loss: [0.32901043]
batch 64 train loss: [0.37092644]
batch 65 train loss: [0.35869044]
batch 66 train loss: [0.38511762]
batch 67 train loss: [0.3427256]
batch 68 train loss: [0.37101108]
batch 69 train loss: [0.34854692]
batch 70 train loss: [0.32945767]
batch 71 train loss: [0.35139072]
batch 72 train loss: [0.3879333]
batch 73 train loss: [0.33331975]
batch 74 train loss: [0.29802814]
batch 75 train loss: [0.39149794]
batch 76 train loss: [0.37575513]
batch 77 train loss: [0.34631106]
batch 78 train loss: [0.33408532]
batch 79 train loss: [0.36098853]
batch 80 train loss: [0.35827747]
batch 81 train loss: [0.35522494]
batch 82 train loss: [0.3843378]
batch 83 train loss: [0.33176768]
batch 84 train loss: [0.34210876]
batch 85 train loss: [0.38202482]
batch 86 train loss: [0.34565753]
batch 87 train loss: [0.40458137]
batch 88 train loss: [0.37467206]
batch 89 train loss: [0.3367912]
batch 90 train loss: [0.3848339]
batch 91 train loss: [0.35643277]
batch 92 train loss: [0.3421137]
batch 93 train loss: [0.3882477]
batch 94 train loss: [0.3322]
batch 95 train loss: [0.37229952]
batch 96 train loss: [0.35744655]
batch 97 train loss: [0.35349542]
batch 98 train loss: [0.44346863]
batch 99 train loss: [0.44110447]
epoch 7 mean train loss: [0.35142556]
WAKE SLEEP ITERATION 3
Inferring cad batch: 0
Inferring cad batch: 1
Inferring cad batch: 2
Inferring cad batch: 3
Inferring cad batch: 4
Inferring cad batch: 5
Inferring cad batch: 6
Inferring cad batch: 7
Inferring cad batch: 8
Inferring cad batch: 9
Inferring cad batch: 10
Inferring cad batch: 11
Inferring cad batch: 12
Inferring cad batch: 13
Inferring cad batch: 14
Inferring cad batch: 15
Inferring cad batch: 16
Inferring cad batch: 17
Inferring cad batch: 18
Inferring cad batch: 19
Inferring cad batch: 20
Inferring cad batch: 21
Inferring cad batch: 22
Inferring cad batch: 23
Inferring cad batch: 24
Inferring cad batch: 25
Inferring cad batch: 26
Inferring cad batch: 27
Inferring cad batch: 28
Inferring cad batch: 29
Inferring cad batch: 30
Inferring cad batch: 31
Inferring cad batch: 32
Inferring cad average chamfer distance: 1.482032446009172
0.575765166104356 1.482032446009172
generator epoch 0 loss: 1.1623236807686943                 accuracy: 0.8721428513526917
generator epoch 1 loss: 1.0615250148228237                 accuracy: 0.8849999904632568
generator epoch 2 loss: 1.0180203142438615                 accuracy: 0.889285683631897
generator epoch 3 loss: 0.9977941929408483                 accuracy: 0.8999999761581421
generator epoch 4 loss: 0.9746981767926898                 accuracy: 0.9092857241630554
generator epoch 5 loss: 0.963642635672433                 accuracy: 0.8985714316368103
generator epoch 6 loss: 0.9502568080357143                 accuracy: 0.904285728931427
generator epoch 7 loss: 0.9433762913295201                 accuracy: 0.8935714364051819
generator epoch 8 loss: 0.9373442042759487                 accuracy: 0.9021428227424622
generator epoch 9 loss: 0.9303614763532366                 accuracy: 0.8807142972946167
generator epoch 10 loss: 0.9171441371372768                 accuracy: 0.8885714411735535
generator epoch 11 loss: 0.9179916582380022                 accuracy: 0.8928571343421936
generator epoch 12 loss: 0.9063850306919643                 accuracy: 0.9085714221000671
generator epoch 13 loss: 0.9037890808105469                 accuracy: 0.8921428322792053
generator epoch 14 loss: 0.9055232360839843                 accuracy: 0.9335713982582092
generator epoch 15 loss: 0.8958879490443639                 accuracy: 0.9099999666213989
generator epoch 16 loss: 0.8973098894391741                 accuracy: 0.897857129573822
generator epoch 17 loss: 0.894344633265904                 accuracy: 0.9035714268684387
generator epoch 18 loss: 0.8822302655901227                 accuracy: 0.9200000166893005
generator epoch 19 loss: 0.881271497453962                 accuracy: 0.9157142639160156
generator epoch 20 loss: 0.8830444510323661                 accuracy: 0.9064285755157471
generator epoch 21 loss: 0.8812070338657925                 accuracy: 0.9171428680419922
generator epoch 22 loss: 0.8759518877301897                 accuracy: 0.9128571152687073
generator epoch 23 loss: 0.8703298078264509                 accuracy: 0.9214285612106323
generator epoch 24 loss: 0.8724017272949218                 accuracy: 0.8935714364051819
generator epoch 25 loss: 0.8668898184640067                 accuracy: 0.9057142734527588
generator epoch 26 loss: 0.8659187761579241                 accuracy: 0.9242857098579407
generator epoch 27 loss: 0.8636007629394531                 accuracy: 0.9099999666213989
generator epoch 28 loss: 0.8603173078264509                 accuracy: 0.9049999713897705
generator epoch 29 loss: 0.8604455976213727                 accuracy: 0.9221428632736206
generator epoch 30 loss: 0.8615028145926339                 accuracy: 0.920714259147644
generator epoch 31 loss: 0.8577048522949219                 accuracy: 0.9228571057319641
generator epoch 32 loss: 0.8516689322335379                 accuracy: 0.9014285802841187
generator epoch 33 loss: 0.8547551600864955                 accuracy: 0.920714259147644
generator epoch 34 loss: 0.8527215157645089                 accuracy: 0.9021428227424622
generator epoch 35 loss: 0.8493834359305246                 accuracy: 0.9242857098579407
generator epoch 36 loss: 0.8534278712681361                 accuracy: 0.9257142543792725
generator epoch 37 loss: 0.849490509905134                 accuracy: 0.9214285612106323
generator epoch 38 loss: 0.8463571367536272                 accuracy: 0.8964285850524902
generator epoch 39 loss: 0.8482132734026228                 accuracy: 0.9135714173316956
generator epoch 40 loss: 0.8489838282993861                 accuracy: 0.9285714030265808
generator epoch 41 loss: 0.8414577802385602                 accuracy: 0.918571412563324
generator epoch 42 loss: 0.8389477757045201                 accuracy: 0.920714259147644
generator epoch 43 loss: 0.8370727085658483                 accuracy: 0.9192857146263123
generator epoch 44 loss: 0.833809232875279                 accuracy: 0.9114285707473755
generator epoch 45 loss: 0.8408592407226563                 accuracy: 0.9178571105003357
generator epoch 46 loss: 0.8356719020298549                 accuracy: 0.9221428632736206
generator epoch 47 loss: 0.8397557364327567                 accuracy: 0.927142858505249
generator epoch 48 loss: 0.8355193420410156                 accuracy: 0.9392856955528259
generator epoch 49 loss: 0.8309193551199777                 accuracy: 0.9278571605682373
generator epoch 50 loss: 0.8326306544712612                 accuracy: 0.9149999618530273
generator epoch 51 loss: 0.8285187412806919                 accuracy: 0.9221428632736206
generator epoch 52 loss: 0.8311516348702567                 accuracy: 0.9328571557998657
generator epoch 53 loss: 0.8268670471191406                 accuracy: 0.9350000023841858
generator epoch 54 loss: 0.827100341796875                 accuracy: 0.9114285707473755
generator epoch 55 loss: 0.8257588675362724                 accuracy: 0.9292857050895691
generator epoch 56 loss: 0.8307444091796875                 accuracy: 0.9371428489685059
generator epoch 57 loss: 0.8325456002371652                 accuracy: 0.9257142543792725
generator epoch 58 loss: 0.8274751900809152                 accuracy: 0.9221428632736206
generator epoch 59 loss: 0.8333327976771764                 accuracy: 0.920714259147644
generator epoch 60 loss: 0.8260090759277344                 accuracy: 0.9371428489685059
generator epoch 61 loss: 0.8273169703892299                 accuracy: 0.9257142543792725
generator epoch 62 loss: 0.8226836321149553                 accuracy: 0.9099999666213989
generator epoch 63 loss: 0.820555226789202                 accuracy: 0.9264285564422607
generator epoch 64 loss: 0.8205523332868303                 accuracy: 0.9335713982582092
generator epoch 65 loss: 0.8236403625488281                 accuracy: 0.9285714030265808
generator epoch 66 loss: 0.8210444292340959                 accuracy: 0.9142857193946838
generator epoch 67 loss: 0.824332066999163                 accuracy: 0.9392856955528259
generator epoch 68 loss: 0.8202384368896485                 accuracy: 0.9321428537368774
generator epoch 69 loss: 0.8177067714146206                 accuracy: 0.920714259147644
generator epoch 70 loss: 0.8214000217982701                 accuracy: 0.9107142686843872
generator epoch 71 loss: 0.8155077357700893                 accuracy: 0.925000011920929
generator epoch 72 loss: 0.8228908447265625                 accuracy: 0.9507142901420593
generator epoch 73 loss: 0.8194309858049665                 accuracy: 0.9228571057319641
generator epoch 74 loss: 0.8204537588936942                 accuracy: 0.9171428680419922
generator epoch 75 loss: 0.8156513349260602                 accuracy: 0.9214285612106323
generator epoch 76 loss: 0.8189899187360491                 accuracy: 0.9378571510314941
generator epoch 77 loss: 0.8160188581194197                 accuracy: 0.9235714077949524
generator epoch 78 loss: 0.8134384748186384                 accuracy: 0.9300000071525574
generator epoch 79 loss: 0.8160660208565849                 accuracy: 0.9364285469055176
generator epoch 80 loss: 0.8138150224958147                 accuracy: 0.9242857098579407
generator epoch 81 loss: 0.8149953351702008                 accuracy: 0.925000011920929
generator epoch 82 loss: 0.8122158150809152                 accuracy: 0.9364285469055176
generator epoch 83 loss: 0.8132825666155133                 accuracy: 0.9335713982582092
generator epoch 84 loss: 0.8110082083565848                 accuracy: 0.9350000023841858
generator epoch 85 loss: 0.8123417375837053                 accuracy: 0.9471428394317627
generator epoch 86 loss: 0.8125792096819197                 accuracy: 0.9278571605682373
generator epoch 87 loss: 0.8084597551618303                 accuracy: 0.9407142996788025
generator epoch 88 loss: 0.8109189601353236                 accuracy: 0.9214285612106323
generator epoch 89 loss: 0.8123678972516741                 accuracy: 0.9357143044471741
generator epoch 90 loss: 0.8085613743373326                 accuracy: 0.9135714173316956
generator epoch 91 loss: 0.8090715606689454                 accuracy: 0.927142858505249
generator epoch 92 loss: 0.8068310564313617                 accuracy: 0.9285714030265808
generator epoch 93 loss: 0.8076217197963169                 accuracy: 0.9435713887214661
generator epoch 94 loss: 0.8041600533621652                 accuracy: 0.9292857050895691
generator epoch 95 loss: 0.8066292471749442                 accuracy: 0.9264285564422607
generator epoch 96 loss: 0.8083378984723772                 accuracy: 0.9171428680419922
generator epoch 97 loss: 0.8072534301757812                 accuracy: 0.9321428537368774
generator epoch 98 loss: 0.804986461530413                 accuracy: 0.9342857003211975
generator epoch 99 loss: 0.8138428833007813                 accuracy: 0.9214285612106323
generator epoch 100 loss: 0.808411166381836                 accuracy: 0.9200000166893005
generator epoch 101 loss: 0.8064600062779018                 accuracy: 0.927142858505249
generator epoch 102 loss: 0.802185453578404                 accuracy: 0.941428542137146
generator epoch 103 loss: 0.8009725176130023                 accuracy: 0.9192857146263123
generator epoch 104 loss: 0.8040992518833705                 accuracy: 0.9235714077949524
generator epoch 105 loss: 0.803382326398577                 accuracy: 0.9214285612106323
generator epoch 106 loss: 0.8030417314801898                 accuracy: 0.9221428632736206
generator epoch 107 loss: 0.8057411193847657                 accuracy: 0.949999988079071
generator epoch 108 loss: 0.7982102743966238                 accuracy: 0.9521428346633911
generator epoch 109 loss: 0.8037022129603795                 accuracy: 0.9314285516738892
generator epoch 110 loss: 0.8048207362583706                 accuracy: 0.9314285516738892
generator epoch 111 loss: 0.8043022705078124                 accuracy: 0.9300000071525574
generator epoch 112 loss: 0.8071328425816128                 accuracy: 0.9235714077949524
generator epoch 113 loss: 0.798386483328683                 accuracy: 0.9142857193946838
generator epoch 114 loss: 0.7967385768345424                 accuracy: 0.9342857003211975
generator epoch 115 loss: 0.8001302089146205                 accuracy: 0.9328571557998657
generator epoch 116 loss: 0.8005144923618862                 accuracy: 0.9149999618530273
generator epoch 117 loss: 0.8015652082170759                 accuracy: 0.9178571105003357
generator epoch 118 loss: 0.8012375898088727                 accuracy: 0.9321428537368774
generator epoch 119 loss: 0.7981351335797991                 accuracy: 0.9257142543792725
generator epoch 120 loss: 0.7983994345528739                 accuracy: 0.9264285564422607
generator epoch 121 loss: 0.8004232090541294                 accuracy: 0.927142858505249
generator epoch 122 loss: 0.7949701520647321                 accuracy: 0.9278571605682373
generator epoch 123 loss: 0.7997809945242745                 accuracy: 0.9385713934898376
generator epoch 124 loss: 0.7962738909040179                 accuracy: 0.9307142496109009
generator epoch 125 loss: 0.8037627746582031                 accuracy: 0.9328571557998657
generator epoch 126 loss: 0.7992796059744699                 accuracy: 0.9407142996788025
generator epoch 127 loss: 0.7960465637207031                 accuracy: 0.9149999618530273
generator epoch 128 loss: 0.7992956970214844                 accuracy: 0.9421428442001343
generator epoch 129 loss: 0.7982407400948661                 accuracy: 0.9200000166893005
generator epoch 130 loss: 0.8004879564557756                 accuracy: 0.9435713887214661
generator epoch 131 loss: 0.7950074689592634                 accuracy: 0.9328571557998657
generator epoch 132 loss: 0.7950162057059151                 accuracy: 0.9264285564422607
generator epoch 133 loss: 0.7965108446393694                 accuracy: 0.947857141494751
generator epoch 134 loss: 0.7961940813337054                 accuracy: 0.9328571557998657
generator epoch 135 loss: 0.792223244367327                 accuracy: 0.9228571057319641
generator epoch 136 loss: 0.7942443028041295                 accuracy: 0.9464285373687744
generator epoch 137 loss: 0.794175794328962                 accuracy: 0.9228571057319641
generator epoch 138 loss: 0.7898004259381975                 accuracy: 0.9314285516738892
generator epoch 139 loss: 0.79290343976702                 accuracy: 0.9128571152687073
generator epoch 140 loss: 0.7964015686035156                 accuracy: 0.9357143044471741
generator epoch 141 loss: 0.7959200892857143                 accuracy: 0.941428542137146
generator epoch 142 loss: 0.792656929234096                 accuracy: 0.9328571557998657
generator epoch 143 loss: 0.7911315830775669                 accuracy: 0.9350000023841858
generator epoch 144 loss: 0.7988008091517858                 accuracy: 0.9421428442001343
generator epoch 145 loss: 0.7948794834681919                 accuracy: 0.9442856907844543
generator epoch 146 loss: 0.7938707462855747                 accuracy: 0.9399999976158142
generator epoch 147 loss: 0.7943491402762277                 accuracy: 0.9435713887214661
generator epoch 148 loss: 0.7936191755022322                 accuracy: 0.947857141494751
generator epoch 149 loss: 0.7861060450962611                 accuracy: 0.9235714077949524
generator epoch 150 loss: 0.7916359505789621                 accuracy: 0.9314285516738892
generator epoch 151 loss: 0.78697535269601                 accuracy: 0.9378571510314941
generator epoch 152 loss: 0.7933963330950056                 accuracy: 0.9357143044471741
generator epoch 153 loss: 0.7941563062395368                 accuracy: 0.9314285516738892
generator epoch 154 loss: 0.7870516366141183                 accuracy: 0.9328571557998657
generator epoch 155 loss: 0.787752872140067                 accuracy: 0.9378571510314941
generator epoch 156 loss: 0.7888146536690849                 accuracy: 0.9428571462631226
generator epoch 157 loss: 0.7919327684674944                 accuracy: 0.9407142996788025
generator epoch 158 loss: 0.7907002371651786                 accuracy: 0.9321428537368774
generator epoch 159 loss: 0.786280093383789                 accuracy: 0.947857141494751
generator epoch 160 loss: 0.7884392124720982                 accuracy: 0.9264285564422607
generator epoch 161 loss: 0.7887228672572545                 accuracy: 0.9242857098579407
generator epoch 162 loss: 0.7880979910714285                 accuracy: 0.9421428442001343
generator epoch 163 loss: 0.7863383780343192                 accuracy: 0.941428542137146
generator epoch 164 loss: 0.7876165095738002                 accuracy: 0.9285714030265808
generator epoch 165 loss: 0.786700486101423                 accuracy: 0.9442856907844543
generator epoch 166 loss: 0.7915523005894253                 accuracy: 0.9321428537368774
generator epoch 167 loss: 0.7847290928431919                 accuracy: 0.927142858505249
generator epoch 168 loss: 0.7884583805629185                 accuracy: 0.9200000166893005
generator epoch 169 loss: 0.7880520359584263                 accuracy: 0.9464285373687744
generator epoch 170 loss: 0.7869275377546038                 accuracy: 0.9357143044471741
generator epoch 171 loss: 0.7839279680524553                 accuracy: 0.949999988079071
generator epoch 172 loss: 0.7807491716657367                 accuracy: 0.9399999976158142
generator epoch 173 loss: 0.7877613630022321                 accuracy: 0.9335713982582092
generator epoch 174 loss: 0.7825957567487444                 accuracy: 0.9321428537368774
generator epoch 175 loss: 0.7856705797467913                 accuracy: 0.9307142496109009
generator epoch 176 loss: 0.787135247366769                 accuracy: 0.947857141494751
generator epoch 177 loss: 0.7816184225899833                 accuracy: 0.927142858505249
generator epoch 178 loss: 0.785058689226423                 accuracy: 0.9385713934898376
generator epoch 179 loss: 0.7852238778250558                 accuracy: 0.9392856955528259
generator epoch 180 loss: 0.7838454616001674                 accuracy: 0.9192857146263123
generator epoch 181 loss: 0.7827942291259765                 accuracy: 0.9471428394317627
generator epoch 182 loss: 0.7829845846993583                 accuracy: 0.9257142543792725
generator epoch 183 loss: 0.7823592973981585                 accuracy: 0.9314285516738892
generator epoch 184 loss: 0.7897393563406808                 accuracy: 0.9449999928474426
generator epoch 185 loss: 0.7863246154785156                 accuracy: 0.927142858505249
generator epoch 186 loss: 0.7801958945138114                 accuracy: 0.9364285469055176
generator epoch 187 loss: 0.7821922411237444                 accuracy: 0.9242857098579407
generator epoch 188 loss: 0.7802946411132813                 accuracy: 0.9507142901420593
generator epoch 189 loss: 0.7792468645368303                 accuracy: 0.9471428394317627
generator epoch 190 loss: 0.7853821184430804                 accuracy: 0.9321428537368774
generator epoch 191 loss: 0.7858189762660436                 accuracy: 0.918571412563324
generator epoch 192 loss: 0.7829525826590402                 accuracy: 0.9485714435577393
generator epoch 193 loss: 0.7803751007080079                 accuracy: 0.9292857050895691
generator epoch 194 loss: 0.782343905203683                 accuracy: 0.9378571510314941
generator epoch 195 loss: 0.781086068725586                 accuracy: 0.9321428537368774
generator epoch 196 loss: 0.7850780247279576                 accuracy: 0.9378571510314941
generator epoch 197 loss: 0.7811909515380859                 accuracy: 0.9449999928474426
generator epoch 198 loss: 0.7777714093889508                 accuracy: 0.9292857050895691
generator epoch 199 loss: 0.7800624481201172                 accuracy: 0.9235714077949524
generator epoch 200 loss: 0.7783005161830358                 accuracy: 0.9328571557998657
generator epoch 201 loss: 0.7805904789515904                 accuracy: 0.920714259147644
generator epoch 202 loss: 0.7771307586669922                 accuracy: 0.9428571462631226
generator epoch 203 loss: 0.780192398071289                 accuracy: 0.9449999928474426
generator epoch 204 loss: 0.7853450112479073                 accuracy: 0.9464285373687744
generator epoch 205 loss: 0.7862210968017578                 accuracy: 0.9399999976158142
generator epoch 206 loss: 0.7801520424979074                 accuracy: 0.9407142996788025
generator epoch 207 loss: 0.781067739868164                 accuracy: 0.9307142496109009
generator epoch 208 loss: 0.777264988054548                 accuracy: 0.9435713887214661
generator epoch 209 loss: 0.7761797236851283                 accuracy: 0.9371428489685059
generator epoch 210 loss: 0.7768384238106864                 accuracy: 0.9392856955528259
generator epoch 211 loss: 0.7786761339460101                 accuracy: 0.949999988079071
generator epoch 212 loss: 0.7819399850027902                 accuracy: 0.9278571605682373
generator epoch 213 loss: 0.7826444989885603                 accuracy: 0.9364285469055176
generator epoch 214 loss: 0.7756016292027065                 accuracy: 0.9421428442001343
generator epoch 215 loss: 0.7800719587053572                 accuracy: 0.9385713934898376
generator epoch 216 loss: 0.7797530190604074                 accuracy: 0.9457142949104309
generator epoch 217 loss: 0.7797008976527623                 accuracy: 0.9228571057319641
generator epoch 218 loss: 0.7757564161028181                 accuracy: 0.9328571557998657
generator epoch 219 loss: 0.7781340506417411                 accuracy: 0.9385713934898376
generator epoch 220 loss: 0.7738024941580636                 accuracy: 0.9285714030265808
generator epoch 221 loss: 0.7808045968191965                 accuracy: 0.927142858505249
generator epoch 222 loss: 0.7718164855957032                 accuracy: 0.9521428346633911
generator epoch 223 loss: 0.777096197945731                 accuracy: 0.9385713934898376
generator epoch 224 loss: 0.7747008924211775                 accuracy: 0.9399999976158142
generator epoch 225 loss: 0.7767891056605748                 accuracy: 0.9442856907844543
generator epoch 226 loss: 0.7776886766706195                 accuracy: 0.9528571367263794
generator epoch 227 loss: 0.7734752672467913                 accuracy: 0.9471428394317627
generator epoch 228 loss: 0.7738140812465123                 accuracy: 0.9492856860160828
generator epoch 229 loss: 0.7726936553955078                 accuracy: 0.9464285373687744
generator epoch 230 loss: 0.7738408883231027                 accuracy: 0.9335713982582092
generator epoch 231 loss: 0.777425783429827                 accuracy: 0.9407142996788025
generator epoch 232 loss: 0.776015516444615                 accuracy: 0.9421428442001343
generator epoch 233 loss: 0.7783775739397322                 accuracy: 0.9535714387893677
generator epoch 234 loss: 0.7786256578717913                 accuracy: 0.9449999928474426
generator epoch 235 loss: 0.7840626251220704                 accuracy: 0.9350000023841858
generator epoch 236 loss: 0.7747371765136719                 accuracy: 0.9399999976158142
generator epoch 237 loss: 0.7746615753173828                 accuracy: 0.9421428442001343
generator epoch 238 loss: 0.7717754978724889                 accuracy: 0.9471428394317627
generator epoch 239 loss: 0.7748684927804129                 accuracy: 0.9442856907844543
generator epoch 240 loss: 0.7808323298863002                 accuracy: 0.9421428442001343
generator epoch 241 loss: 0.7728462524414063                 accuracy: 0.9257142543792725
generator epoch 242 loss: 0.7783383340018136                 accuracy: 0.9471428394317627
generator epoch 243 loss: 0.7759620108468192                 accuracy: 0.9449999928474426
generator epoch 244 loss: 0.772450250680106                 accuracy: 0.9335713982582092
generator epoch 245 loss: 0.7723377358572824                 accuracy: 0.9407142996788025
generator epoch 246 loss: 0.7732151916503907                 accuracy: 0.9464285373687744
generator epoch 247 loss: 0.7762072387695312                 accuracy: 0.9421428442001343
generator epoch 248 loss: 0.773345197405134                 accuracy: 0.9457142949104309
generator epoch 249 loss: 0.77868267691476                 accuracy: 0.9257142543792725
generator epoch 250 loss: 0.7748182076590402                 accuracy: 0.9464285373687744
generator epoch 251 loss: 0.7716834760393415                 accuracy: 0.9364285469055176
generator epoch 252 loss: 0.7767679779052734                 accuracy: 0.9542856812477112
generator epoch 253 loss: 0.7706827139718192                 accuracy: 0.9528571367263794
generator epoch 254 loss: 0.7743733450753348                 accuracy: 0.9485714435577393
generator epoch 255 loss: 0.7772098314557757                 accuracy: 0.9485714435577393
generator epoch 256 loss: 0.7725825400216239                 accuracy: 0.927142858505249
generator epoch 257 loss: 0.7789038312639509                 accuracy: 0.9371428489685059
generator epoch 258 loss: 0.7764425214494978                 accuracy: 0.947857141494751
generator epoch 259 loss: 0.7763621010916574                 accuracy: 0.9421428442001343
generator epoch 260 loss: 0.7724662588936942                 accuracy: 0.9307142496109009
generator epoch 261 loss: 0.7746204445975168                 accuracy: 0.9399999976158142
generator epoch 262 loss: 0.7780124193464006                 accuracy: 0.9342857003211975
generator epoch 263 loss: 0.7762354060581752                 accuracy: 0.941428542137146
generator epoch 264 loss: 0.7718537475585937                 accuracy: 0.9407142996788025
generator epoch 265 loss: 0.7741664921351842                 accuracy: 0.9385713934898376
generator epoch 266 loss: 0.774077492414202                 accuracy: 0.9585714340209961
generator epoch 267 loss: 0.7726774017333984                 accuracy: 0.9342857003211975
generator epoch 268 loss: 0.7714156302315848                 accuracy: 0.9407142996788025
generator epoch 269 loss: 0.7714217956542969                 accuracy: 0.9442856907844543
generator epoch 270 loss: 0.7710292676653181                 accuracy: 0.9428571462631226
generator epoch 271 loss: 0.7715357325962612                 accuracy: 0.949999988079071
generator epoch 272 loss: 0.7744979832240514                 accuracy: 0.9371428489685059
generator epoch 273 loss: 0.7659480573381696                 accuracy: 0.9392856955528259
generator epoch 274 loss: 0.7723579851422991                 accuracy: 0.947857141494751
generator epoch 275 loss: 0.7691764199393136                 accuracy: 0.9392856955528259
generator epoch 276 loss: 0.7726203513009208                 accuracy: 0.9428571462631226
generator epoch 277 loss: 0.7677617863246373                 accuracy: 0.9407142996788025
generator epoch 278 loss: 0.7676543169294084                 accuracy: 0.9342857003211975
generator epoch 279 loss: 0.7712099735804967                 accuracy: 0.9378571510314941
generator epoch 280 loss: 0.7725996285574777                 accuracy: 0.9528571367263794
generator epoch 281 loss: 0.7702191881452288                 accuracy: 0.9421428442001343
generator epoch 282 loss: 0.772149345615932                 accuracy: 0.9350000023841858
generator epoch 283 loss: 0.7726853772844587                 accuracy: 0.9314285516738892
generator epoch 284 loss: 0.7688798217773437                 accuracy: 0.9342857003211975
generator epoch 285 loss: 0.7712802115304129                 accuracy: 0.9528571367263794
generator epoch 286 loss: 0.7731463060651507                 accuracy: 0.9428571462631226
generator epoch 287 loss: 0.7703675136021205                 accuracy: 0.9449999928474426
generator epoch 288 loss: 0.7706007319859096                 accuracy: 0.9428571462631226
generator epoch 289 loss: 0.76898330078125                 accuracy: 0.9485714435577393
generator epoch 290 loss: 0.7688567971365793                 accuracy: 0.947857141494751
generator epoch 291 loss: 0.7705223070417132                 accuracy: 0.9392856955528259
generator epoch 292 loss: 0.7727335457938058                 accuracy: 0.9357143044471741
generator epoch 293 loss: 0.7746720694405692                 accuracy: 0.9335713982582092
generator epoch 294 loss: 0.7675281393868583                 accuracy: 0.9378571510314941
generator epoch 295 loss: 0.7733863041469029                 accuracy: 0.9471428394317627
generator epoch 296 loss: 0.7688144343784877                 accuracy: 0.9392856955528259
generator epoch 297 loss: 0.7660590990339007                 accuracy: 0.9392856955528259
generator epoch 298 loss: 0.7709226048060825                 accuracy: 0.9407142996788025
generator epoch 299 loss: 0.7645957209995815                 accuracy: 0.9399999976158142
generator epoch 300 loss: 0.7674940211704799                 accuracy: 0.9449999928474426
generator epoch 301 loss: 0.7689360970633371                 accuracy: 0.9471428394317627
generator epoch 302 loss: 0.7694102944510324                 accuracy: 0.9385713934898376
generator epoch 303 loss: 0.7705453002929687                 accuracy: 0.9292857050895691
generator epoch 304 loss: 0.7672829786028181                 accuracy: 0.9471428394317627
generator epoch 305 loss: 0.7710716295514788                 accuracy: 0.9521428346633911
generator epoch 306 loss: 0.7702376565115793                 accuracy: 0.9428571462631226
generator epoch 307 loss: 0.7674529876708984                 accuracy: 0.9328571557998657
generator epoch 308 loss: 0.7698948521205358                 accuracy: 0.9164285659790039
generator epoch 309 loss: 0.7681561920166016                 accuracy: 0.9407142996788025
generator epoch 310 loss: 0.7636732230050223                 accuracy: 0.9571428298950195
generator epoch 311 loss: 0.7676363159179688                 accuracy: 0.9585714340209961
generator epoch 312 loss: 0.7670462345668247                 accuracy: 0.941428542137146
generator epoch 313 loss: 0.7659775970458984                 accuracy: 0.9392856955528259
generator epoch 314 loss: 0.7668466352190291                 accuracy: 0.9264285564422607
generator epoch 315 loss: 0.7627076559884207                 accuracy: 0.9435713887214661
generator epoch 316 loss: 0.7719684936523438                 accuracy: 0.947857141494751
generator epoch 317 loss: 0.7696188446044921                 accuracy: 0.9278571605682373
generator epoch 318 loss: 0.7652975385393416                 accuracy: 0.9435713887214661
generator epoch 319 loss: 0.7651238595145089                 accuracy: 0.9342857003211975
generator epoch 320 loss: 0.7722194937569754                 accuracy: 0.9321428537368774
generator epoch 321 loss: 0.7657732382638114                 accuracy: 0.925000011920929
generator epoch 322 loss: 0.7659349081856864                 accuracy: 0.9350000023841858
generator epoch 323 loss: 0.7660975115094866                 accuracy: 0.9385713934898376
generator epoch 324 loss: 0.765718013218471                 accuracy: 0.9535714387893677
generator epoch 325 loss: 0.7719729675292969                 accuracy: 0.956428587436676
generator epoch 326 loss: 0.7683768628801618                 accuracy: 0.9328571557998657
generator epoch 327 loss: 0.7674964460100446                 accuracy: 0.9449999928474426
generator epoch 328 loss: 0.7668363146100725                 accuracy: 0.9435713887214661
generator epoch 329 loss: 0.7660835688999721                 accuracy: 0.9571428298950195
generator epoch 330 loss: 0.7670964133126396                 accuracy: 0.9364285469055176
generator epoch 331 loss: 0.7626973815917969                 accuracy: 0.9357143044471741
generator epoch 332 loss: 0.7716481807163783                 accuracy: 0.9464285373687744
generator epoch 333 loss: 0.7663359889439174                 accuracy: 0.9535714387893677
generator epoch 334 loss: 0.7654409920828683                 accuracy: 0.9257142543792725
generator epoch 335 loss: 0.7626570726667131                 accuracy: 0.9485714435577393
generator epoch 336 loss: 0.765632601928711                 accuracy: 0.9457142949104309
generator epoch 337 loss: 0.7643214006696428                 accuracy: 0.941428542137146
generator epoch 338 loss: 0.7688766610281808                 accuracy: 0.9514285326004028
generator epoch 339 loss: 0.7635166486467634                 accuracy: 0.9628571271896362
generator epoch 340 loss: 0.7642935494559152                 accuracy: 0.9485714435577393
generator epoch 341 loss: 0.7657805162702288                 accuracy: 0.9392856955528259
generator epoch 342 loss: 0.7633304827008929                 accuracy: 0.9364285469055176
generator epoch 343 loss: 0.7655413709368024                 accuracy: 0.9378571510314941
generator epoch 344 loss: 0.7614572937011719                 accuracy: 0.9428571462631226
generator epoch 345 loss: 0.766245734514509                 accuracy: 0.9449999928474426
generator epoch 346 loss: 0.7660606571742467                 accuracy: 0.9578571319580078
generator epoch 347 loss: 0.765798863874163                 accuracy: 0.918571412563324
generator epoch 348 loss: 0.7647021009172712                 accuracy: 0.9442856907844543
generator epoch 349 loss: 0.7603690259660993                 accuracy: 0.9492856860160828
generator epoch 350 loss: 0.7665701799665179                 accuracy: 0.9442856907844543
generator epoch 351 loss: 0.7619660836356027                 accuracy: 0.9385713934898376
generator epoch 352 loss: 0.7656637590680804                 accuracy: 0.9585714340209961
generator epoch 353 loss: 0.765397509765625                 accuracy: 0.9278571605682373
generator epoch 354 loss: 0.7643399387904576                 accuracy: 0.9521428346633911
generator epoch 355 loss: 0.7636123517717633                 accuracy: 0.9585714340209961
generator epoch 356 loss: 0.7602862117222378                 accuracy: 0.9485714435577393
generator epoch 357 loss: 0.7735859980991908                 accuracy: 0.9385713934898376
generator epoch 358 loss: 0.7678291011265346                 accuracy: 0.9300000071525574
generator epoch 359 loss: 0.7673471801757813                 accuracy: 0.9457142949104309
generator epoch 360 loss: 0.7669851989746094                 accuracy: 0.9449999928474426
generator epoch 361 loss: 0.7647629847935268                 accuracy: 0.9471428394317627
generator epoch 362 loss: 0.7691074327741351                 accuracy: 0.9514285326004028
generator epoch 363 loss: 0.763420993913923                 accuracy: 0.9464285373687744
generator epoch 364 loss: 0.7679627768380302                 accuracy: 0.9485714435577393
generator epoch 365 loss: 0.7642856615339007                 accuracy: 0.9435713887214661
generator epoch 366 loss: 0.7665772670200893                 accuracy: 0.9257142543792725
generator epoch 367 loss: 0.7641967150006975                 accuracy: 0.9342857003211975
generator epoch 368 loss: 0.7612084080287388                 accuracy: 0.9407142996788025
generator epoch 369 loss: 0.7654997144426618                 accuracy: 0.9300000071525574
generator epoch 370 loss: 0.7601488268171038                 accuracy: 0.9457142949104309
generator epoch 371 loss: 0.7584824044363839                 accuracy: 0.9292857050895691
generator epoch 372 loss: 0.7684609444754464                 accuracy: 0.947857141494751
generator epoch 373 loss: 0.7616978040422712                 accuracy: 0.9428571462631226
generator epoch 374 loss: 0.7656567020961217                 accuracy: 0.9385713934898376
generator epoch 375 loss: 0.763773479788644                 accuracy: 0.9321428537368774
generator epoch 376 loss: 0.7621342006138393                 accuracy: 0.9399999976158142
generator epoch 377 loss: 0.7636358899797712                 accuracy: 0.9435713887214661
generator epoch 378 loss: 0.7556253243582589                 accuracy: 0.9335713982582092
generator epoch 379 loss: 0.7598484388078962                 accuracy: 0.9464285373687744
generator epoch 380 loss: 0.7597687648228236                 accuracy: 0.9449999928474426
generator epoch 381 loss: 0.7594498565673828                 accuracy: 0.9571428298950195
generator epoch 382 loss: 0.757359710257394                 accuracy: 0.9507142901420593
generator epoch 383 loss: 0.7649732883998326                 accuracy: 0.9335713982582092
generator epoch 384 loss: 0.7600982840401785                 accuracy: 0.9292857050895691
generator epoch 385 loss: 0.761455615234375                 accuracy: 0.9399999976158142
generator epoch 386 loss: 0.7624301025390625                 accuracy: 0.9557142853736877
generator epoch 387 loss: 0.7627097913469587                 accuracy: 0.9399999976158142
generator epoch 388 loss: 0.7602078866141183                 accuracy: 0.9399999976158142
generator epoch 389 loss: 0.7590751294817243                 accuracy: 0.9399999976158142
generator epoch 390 loss: 0.7612337223597935                 accuracy: 0.941428542137146
generator epoch 391 loss: 0.7641753631591797                 accuracy: 0.9342857003211975
generator epoch 392 loss: 0.7583295959472657                 accuracy: 0.9471428394317627
generator epoch 393 loss: 0.7605863978794642                 accuracy: 0.9449999928474426
generator epoch 394 loss: 0.7606362422398159                 accuracy: 0.9428571462631226
generator epoch 395 loss: 0.7637196816580636                 accuracy: 0.9471428394317627
generator epoch 396 loss: 0.7640553096226284                 accuracy: 0.941428542137146
generator epoch 397 loss: 0.7598339172363281                 accuracy: 0.9407142996788025
generator epoch 398 loss: 0.7634345759800503                 accuracy: 0.9521428346633911
generator epoch 399 loss: 0.7577030931745257                 accuracy: 0.9428571462631226
generator epoch 400 loss: 0.7588726000104632                 accuracy: 0.949999988079071
generator epoch 401 loss: 0.7575987104143416                 accuracy: 0.9307142496109009
generator epoch 402 loss: 0.7604837393624442                 accuracy: 0.9549999833106995
generator epoch 403 loss: 0.7658200474330357                 accuracy: 0.9578571319580078
generator epoch 404 loss: 0.7585842864990234                 accuracy: 0.9421428442001343
generator epoch 405 loss: 0.7599828730991909                 accuracy: 0.9514285326004028
generator epoch 406 loss: 0.7580047101702009                 accuracy: 0.941428542137146
generator epoch 407 loss: 0.7540128252301898                 accuracy: 0.9485714435577393
generator epoch 408 loss: 0.7602614933558873                 accuracy: 0.9421428442001343
generator epoch 409 loss: 0.7626038029261998                 accuracy: 0.9428571462631226
generator epoch 410 loss: 0.7620195752825056                 accuracy: 0.9385713934898376
generator epoch 411 loss: 0.7619852848597936                 accuracy: 0.9449999928474426
generator epoch 412 loss: 0.7621721187046596                 accuracy: 0.9428571462631226
generator epoch 413 loss: 0.7621819994245257                 accuracy: 0.9485714435577393
generator epoch 414 loss: 0.7630870064871652                 accuracy: 0.9442856907844543
generator epoch 415 loss: 0.7590509599958147                 accuracy: 0.9214285612106323
generator epoch 416 loss: 0.7638318376813616                 accuracy: 0.9357143044471741
generator epoch 417 loss: 0.7637943516322545                 accuracy: 0.9314285516738892
generator epoch 418 loss: 0.7567585981096541                 accuracy: 0.9300000071525574
generator epoch 419 loss: 0.7600506352015904                 accuracy: 0.9457142949104309
generator epoch 420 loss: 0.756191823904855                 accuracy: 0.9350000023841858
generator epoch 421 loss: 0.7549688703264509                 accuracy: 0.9485714435577393
generator epoch 422 loss: 0.7636075692313058                 accuracy: 0.9435713887214661
generator epoch 423 loss: 0.7589576372419085                 accuracy: 0.9514285326004028
generator epoch 424 loss: 0.758692584664481                 accuracy: 0.9242857098579407
generator epoch 425 loss: 0.7626444183349609                 accuracy: 0.9371428489685059
generator epoch 426 loss: 0.7590878452845982                 accuracy: 0.9485714435577393
generator epoch 427 loss: 0.7602753954206194                 accuracy: 0.9449999928474426
generator epoch 428 loss: 0.7597200339181083                 accuracy: 0.9578571319580078
generator epoch 429 loss: 0.7619159109933036                 accuracy: 0.9471428394317627
generator epoch 430 loss: 0.7573908961704799                 accuracy: 0.949999988079071
generator epoch 431 loss: 0.7604299704415458                 accuracy: 0.9399999976158142
generator epoch 432 loss: 0.7598999385288784                 accuracy: 0.9392856955528259
generator epoch 433 loss: 0.7624668954031808                 accuracy: 0.9314285516738892
generator epoch 434 loss: 0.761728761945452                 accuracy: 0.9449999928474426
generator epoch 435 loss: 0.7637795815604074                 accuracy: 0.9421428442001343
generator epoch 436 loss: 0.7592013201032366                 accuracy: 0.949999988079071
generator epoch 437 loss: 0.7618631430489676                 accuracy: 0.947857141494751
generator epoch 438 loss: 0.7570818032400949                 accuracy: 0.9371428489685059
generator epoch 439 loss: 0.7571577763148717                 accuracy: 0.9364285469055176
generator epoch 440 loss: 0.7611049360002791                 accuracy: 0.949999988079071
generator epoch 441 loss: 0.7588200465611049                 accuracy: 0.9371428489685059
generator epoch 442 loss: 0.7548646920340402                 accuracy: 0.9492856860160828
generator epoch 443 loss: 0.7542576398577009                 accuracy: 0.9528571367263794
generator epoch 444 loss: 0.7560956028529576                 accuracy: 0.9399999976158142
generator epoch 445 loss: 0.7591764774867467                 accuracy: 0.9421428442001343
generator epoch 446 loss: 0.7613721601213728                 accuracy: 0.9449999928474426
generator epoch 447 loss: 0.7592849134172712                 accuracy: 0.9385713934898376
generator epoch 448 loss: 0.75865830078125                 accuracy: 0.9514285326004028
generator epoch 449 loss: 0.7633155500139509                 accuracy: 0.9464285373687744
generator epoch 450 loss: 0.7588620348249163                 accuracy: 0.9442856907844543
generator epoch 451 loss: 0.7564868831089565                 accuracy: 0.9485714435577393
generator epoch 452 loss: 0.7572711992536272                 accuracy: 0.949999988079071
generator epoch 453 loss: 0.7569724448067802                 accuracy: 0.9335713982582092
generator epoch 454 loss: 0.7594883732386998                 accuracy: 0.9507142901420593
generator epoch 455 loss: 0.7572007306780134                 accuracy: 0.9378571510314941
generator epoch 456 loss: 0.7558601026262556                 accuracy: 0.9300000071525574
generator epoch 457 loss: 0.7614471217564174                 accuracy: 0.9407142996788025
generator epoch 458 loss: 0.7569329528808594                 accuracy: 0.9485714435577393
generator epoch 459 loss: 0.7571368983677456                 accuracy: 0.9442856907844543
generator epoch 460 loss: 0.7598484475272043                 accuracy: 0.9507142901420593
generator epoch 461 loss: 0.756010404750279                 accuracy: 0.9578571319580078
generator epoch 462 loss: 0.7556233742850167                 accuracy: 0.949999988079071
generator epoch 463 loss: 0.7576058907645089                 accuracy: 0.9350000023841858
generator epoch 464 loss: 0.7561078700474331                 accuracy: 0.9514285326004028
generator epoch 465 loss: 0.7695439867292132                 accuracy: 0.9378571510314941
generator epoch 466 loss: 0.7589334978376117                 accuracy: 0.9371428489685059
generator epoch 467 loss: 0.7600709446498326                 accuracy: 0.9307142496109009
generator epoch 468 loss: 0.7616348584856306                 accuracy: 0.9407142996788025
generator epoch 469 loss: 0.7565179639543805                 accuracy: 0.9578571319580078
generator epoch 470 loss: 0.7582105752127511                 accuracy: 0.947857141494751
generator epoch 471 loss: 0.756225399344308                 accuracy: 0.941428542137146
generator epoch 472 loss: 0.759527146257673                 accuracy: 0.9492856860160828
generator epoch 473 loss: 0.754577390398298                 accuracy: 0.9535714387893677
generator epoch 474 loss: 0.7591565726143973                 accuracy: 0.9300000071525574
generator epoch 475 loss: 0.7639195983886718                 accuracy: 0.9357143044471741
generator epoch 476 loss: 0.7578890629359654                 accuracy: 0.9364285469055176
generator epoch 477 loss: 0.7557248530796596                 accuracy: 0.9542856812477112
generator epoch 478 loss: 0.7563969076974051                 accuracy: 0.9449999928474426
generator epoch 479 loss: 0.7567559731619699                 accuracy: 0.9392856955528259
generator epoch 480 loss: 0.757457421875                 accuracy: 0.9521428346633911
generator epoch 481 loss: 0.754499900163923                 accuracy: 0.9535714387893677
generator epoch 482 loss: 0.7581784572056361                 accuracy: 0.9378571510314941
generator epoch 483 loss: 0.7627169760567801                 accuracy: 0.9549999833106995
generator epoch 484 loss: 0.7555237056187221                 accuracy: 0.9542856812477112
generator epoch 485 loss: 0.7542102098737444                 accuracy: 0.9385713934898376
generator epoch 486 loss: 0.7573619354248047                 accuracy: 0.9485714435577393
generator epoch 487 loss: 0.7548458177839007                 accuracy: 0.9471428394317627
generator epoch 488 loss: 0.7543104518345424                 accuracy: 0.9221428632736206
generator epoch 489 loss: 0.7556745993477958                 accuracy: 0.9449999928474426
generator epoch 490 loss: 0.7538679225376674                 accuracy: 0.9457142949104309
generator epoch 491 loss: 0.7546172982352121                 accuracy: 0.9557142853736877
generator epoch 492 loss: 0.7565733934674944                 accuracy: 0.9350000023841858
generator epoch 493 loss: 0.7607284384591239                 accuracy: 0.9549999833106995
generator epoch 494 loss: 0.7647719508579799                 accuracy: 0.956428587436676
generator epoch 495 loss: 0.7656686597551619                 accuracy: 0.9442856907844543
generator epoch 496 loss: 0.7572569213867187                 accuracy: 0.9364285469055176
generator epoch 497 loss: 0.7552407523018974                 accuracy: 0.9421428442001343
generator epoch 498 loss: 0.755149753679548                 accuracy: 0.949999988079071
generator epoch 499 loss: 0.7597424124581473                 accuracy: 0.9449999928474426
batch 0 train loss: [0.5746334]
batch 1 train loss: [0.6805545]
batch 2 train loss: [0.6901006]
batch 3 train loss: [0.50122297]
batch 4 train loss: [0.6057475]
batch 5 train loss: [0.59169805]
batch 6 train loss: [0.61044294]
batch 7 train loss: [0.62263966]
batch 8 train loss: [0.59282345]
batch 9 train loss: [0.51561326]
batch 10 train loss: [0.52480054]
batch 11 train loss: [0.5102292]
batch 12 train loss: [0.57456446]
batch 13 train loss: [0.45626152]
batch 14 train loss: [0.51796657]
batch 15 train loss: [0.47640288]
batch 16 train loss: [0.58145714]
batch 17 train loss: [0.613773]
batch 18 train loss: [0.63802016]
batch 19 train loss: [0.53681684]
batch 20 train loss: [0.47166544]
batch 21 train loss: [0.56850344]
batch 22 train loss: [0.59799564]
batch 23 train loss: [0.59404135]
batch 24 train loss: [0.5997832]
batch 25 train loss: [0.58990586]
batch 26 train loss: [0.5702142]
batch 27 train loss: [0.5587621]
batch 28 train loss: [0.48356473]
batch 29 train loss: [0.56787467]
batch 30 train loss: [0.53426445]
batch 31 train loss: [0.5079377]
batch 32 train loss: [0.53820443]
batch 33 train loss: [0.5536628]
batch 34 train loss: [0.57053953]
batch 35 train loss: [0.5233198]
batch 36 train loss: [0.55702555]
batch 37 train loss: [0.5894934]
batch 38 train loss: [0.5447577]
batch 39 train loss: [0.60382414]
batch 40 train loss: [0.597062]
batch 41 train loss: [0.5901761]
batch 42 train loss: [0.561068]
batch 43 train loss: [0.61228216]
batch 44 train loss: [0.5098168]
batch 45 train loss: [0.50946987]
batch 46 train loss: [0.56615806]
batch 47 train loss: [0.5523617]
batch 48 train loss: [0.672464]
batch 49 train loss: [0.6209601]
batch 50 train loss: [0.50558865]
batch 51 train loss: [0.54493874]
batch 52 train loss: [0.5605054]
batch 53 train loss: [0.5026893]
batch 54 train loss: [0.5267007]
batch 55 train loss: [0.65919554]
batch 56 train loss: [0.5406712]
batch 57 train loss: [0.57387394]
batch 58 train loss: [0.3829965]
batch 59 train loss: [0.45530063]
batch 60 train loss: [0.53157616]
batch 61 train loss: [0.53946227]
batch 62 train loss: [0.5589952]
batch 63 train loss: [0.4593645]
batch 64 train loss: [0.58854944]
batch 65 train loss: [0.48633912]
batch 66 train loss: [0.53867763]
batch 67 train loss: [0.4552781]
batch 68 train loss: [0.52609205]
batch 69 train loss: [0.5858467]
batch 70 train loss: [0.5347267]
batch 71 train loss: [0.59717655]
batch 72 train loss: [0.5567531]
batch 73 train loss: [0.5447614]
batch 74 train loss: [0.5650236]
batch 75 train loss: [0.44709325]
batch 76 train loss: [0.46047002]
batch 77 train loss: [0.577801]
batch 78 train loss: [0.58372086]
batch 79 train loss: [0.5072685]
batch 80 train loss: [0.59343284]
batch 81 train loss: [0.45640787]
batch 82 train loss: [0.592932]
batch 83 train loss: [0.59443444]
batch 84 train loss: [0.43399787]
batch 85 train loss: [0.5045223]
batch 86 train loss: [0.5272462]
batch 87 train loss: [0.570976]
batch 88 train loss: [0.59636605]
batch 89 train loss: [0.5028327]
batch 90 train loss: [0.5664838]
batch 91 train loss: [0.5963832]
batch 92 train loss: [0.51355726]
batch 93 train loss: [0.5120627]
batch 94 train loss: [0.50981843]
batch 95 train loss: [0.57537043]
batch 96 train loss: [0.44569612]
batch 97 train loss: [0.45239294]
batch 98 train loss: [0.6298279]
batch 99 train loss: [0.6180324]
epoch 0 mean train loss: [0.5502313]
Epoch 0/400=>  train_loss: [0.5502313], iou: nan, cd: 2.319736548226123, test_mse: [0.46024814]
CORRECT PROGRAMS: 9818
batch 0 train loss: [0.44166738]
batch 1 train loss: [0.5108974]
batch 2 train loss: [0.4986875]
batch 3 train loss: [0.42569864]
batch 4 train loss: [0.40515882]
batch 5 train loss: [0.5143942]
batch 6 train loss: [0.46179703]
batch 7 train loss: [0.4632026]
batch 8 train loss: [0.42851284]
batch 9 train loss: [0.49541086]
batch 10 train loss: [0.3977353]
batch 11 train loss: [0.4458746]
batch 12 train loss: [0.51610184]
batch 13 train loss: [0.41037196]
batch 14 train loss: [0.36676377]
batch 15 train loss: [0.5641868]
batch 16 train loss: [0.47518975]
batch 17 train loss: [0.4270218]
batch 18 train loss: [0.54016984]
batch 19 train loss: [0.4618004]
batch 20 train loss: [0.44994074]
batch 21 train loss: [0.40877324]
batch 22 train loss: [0.40982983]
batch 23 train loss: [0.36108568]
batch 24 train loss: [0.45200294]
batch 25 train loss: [0.3604743]
batch 26 train loss: [0.5180566]
batch 27 train loss: [0.45678082]
batch 28 train loss: [0.45501837]
batch 29 train loss: [0.3752422]
batch 30 train loss: [0.38291892]
batch 31 train loss: [0.45545748]
batch 32 train loss: [0.5051266]
batch 33 train loss: [0.44764176]
batch 34 train loss: [0.48283473]
batch 35 train loss: [0.48800498]
batch 36 train loss: [0.4793746]
batch 37 train loss: [0.5102724]
batch 38 train loss: [0.4019899]
batch 39 train loss: [0.4389588]
batch 40 train loss: [0.48579296]
batch 41 train loss: [0.50034]
batch 42 train loss: [0.49002805]
batch 43 train loss: [0.47242978]
batch 44 train loss: [0.46483958]
batch 45 train loss: [0.499822]
batch 46 train loss: [0.35536256]
batch 47 train loss: [0.51115006]
batch 48 train loss: [0.5285475]
batch 49 train loss: [0.627073]
batch 50 train loss: [0.48473293]
batch 51 train loss: [0.534188]
batch 52 train loss: [0.48142758]
batch 53 train loss: [0.41788962]
batch 54 train loss: [0.44070768]
batch 55 train loss: [0.43560675]
batch 56 train loss: [0.42240435]
batch 57 train loss: [0.4236339]
batch 58 train loss: [0.38831255]
batch 59 train loss: [0.40989077]
batch 60 train loss: [0.41058734]
batch 61 train loss: [0.42998755]
batch 62 train loss: [0.5079975]
batch 63 train loss: [0.48089078]
batch 64 train loss: [0.36257374]
batch 65 train loss: [0.47779283]
batch 66 train loss: [0.46575645]
batch 67 train loss: [0.4045254]
batch 68 train loss: [0.3833531]
batch 69 train loss: [0.51638865]
batch 70 train loss: [0.3521024]
batch 71 train loss: [0.4254869]
batch 72 train loss: [0.5355958]
batch 73 train loss: [0.5450468]
batch 74 train loss: [0.43640912]
batch 75 train loss: [0.41070014]
batch 76 train loss: [0.47574195]
batch 77 train loss: [0.48487404]
batch 78 train loss: [0.45927477]
batch 79 train loss: [0.43248072]
batch 80 train loss: [0.42871898]
batch 81 train loss: [0.43966785]
batch 82 train loss: [0.44096833]
batch 83 train loss: [0.35532957]
batch 84 train loss: [0.5262851]
batch 85 train loss: [0.46800175]
batch 86 train loss: [0.44513655]
batch 87 train loss: [0.5336728]
batch 88 train loss: [0.48720628]
batch 89 train loss: [0.39474067]
batch 90 train loss: [0.49263793]
batch 91 train loss: [0.4787578]
batch 92 train loss: [0.43245912]
batch 93 train loss: [0.4895079]
batch 94 train loss: [0.44601122]
batch 95 train loss: [0.49014]
batch 96 train loss: [0.48797026]
batch 97 train loss: [0.38531432]
batch 98 train loss: [0.44677368]
batch 99 train loss: [0.43458045]
epoch 1 mean train loss: [0.45566055]
Epoch 1/400=>  train_loss: [0.45566055], iou: nan, cd: 2.291342539361493, test_mse: [0.4246064]
CORRECT PROGRAMS: 9818
batch 0 train loss: [0.41493216]
batch 1 train loss: [0.3748916]
batch 2 train loss: [0.41541296]
batch 3 train loss: [0.3580461]
batch 4 train loss: [0.4616154]
batch 5 train loss: [0.37777546]
batch 6 train loss: [0.34922203]
batch 7 train loss: [0.42681786]
batch 8 train loss: [0.5195403]
batch 9 train loss: [0.4128822]
batch 10 train loss: [0.44141293]
batch 11 train loss: [0.38786986]
batch 12 train loss: [0.42902797]
batch 13 train loss: [0.41860092]
batch 14 train loss: [0.39419386]
batch 15 train loss: [0.35615888]
batch 16 train loss: [0.4557675]
batch 17 train loss: [0.35781962]
batch 18 train loss: [0.3742043]
batch 19 train loss: [0.4995183]
batch 20 train loss: [0.35476607]
batch 21 train loss: [0.3398235]
batch 22 train loss: [0.4014708]
batch 23 train loss: [0.37110692]
batch 24 train loss: [0.46327868]
batch 25 train loss: [0.3757053]
batch 26 train loss: [0.43976468]
batch 27 train loss: [0.34022105]
batch 28 train loss: [0.41862762]
batch 29 train loss: [0.40365285]
batch 30 train loss: [0.48044404]
batch 31 train loss: [0.41948798]
batch 32 train loss: [0.38974527]
batch 33 train loss: [0.4780672]
batch 34 train loss: [0.3962358]
batch 35 train loss: [0.37700683]
batch 36 train loss: [0.4551609]
batch 37 train loss: [0.37147772]
batch 38 train loss: [0.43510222]
batch 39 train loss: [0.29894233]
batch 40 train loss: [0.53692347]
batch 41 train loss: [0.31927338]
batch 42 train loss: [0.36861643]
batch 43 train loss: [0.37540182]
batch 44 train loss: [0.41049328]
batch 45 train loss: [0.40073064]
batch 46 train loss: [0.50481623]
batch 47 train loss: [0.4106349]
batch 48 train loss: [0.56008315]
batch 49 train loss: [0.4036933]
batch 50 train loss: [0.3972306]
batch 51 train loss: [0.35247877]
batch 52 train loss: [0.45545542]
batch 53 train loss: [0.38465235]
batch 54 train loss: [0.36052692]
batch 55 train loss: [0.46376374]
batch 56 train loss: [0.38528126]
batch 57 train loss: [0.52402264]
batch 58 train loss: [0.504057]
batch 59 train loss: [0.48899704]
batch 60 train loss: [0.42631024]
batch 61 train loss: [0.4397243]
batch 62 train loss: [0.36841476]
batch 63 train loss: [0.41903433]
batch 64 train loss: [0.5087696]
batch 65 train loss: [0.34645554]
batch 66 train loss: [0.40596426]
batch 67 train loss: [0.34504852]
batch 68 train loss: [0.4047311]
batch 69 train loss: [0.4279466]
batch 70 train loss: [0.46241438]
batch 71 train loss: [0.34365258]
batch 72 train loss: [0.4036081]
batch 73 train loss: [0.48108917]
batch 74 train loss: [0.4820961]
batch 75 train loss: [0.30036566]
batch 76 train loss: [0.37012446]
batch 77 train loss: [0.3986982]
batch 78 train loss: [0.3547826]
batch 79 train loss: [0.38773358]
batch 80 train loss: [0.4072735]
batch 81 train loss: [0.42066708]
batch 82 train loss: [0.49379742]
batch 83 train loss: [0.36025506]
batch 84 train loss: [0.3980273]
batch 85 train loss: [0.46136272]
batch 86 train loss: [0.4336684]
batch 87 train loss: [0.4186424]
batch 88 train loss: [0.39223662]
batch 89 train loss: [0.33493367]
batch 90 train loss: [0.47898826]
batch 91 train loss: [0.4292202]
batch 92 train loss: [0.37763733]
batch 93 train loss: [0.36487046]
batch 94 train loss: [0.4218871]
batch 95 train loss: [0.38573635]
batch 96 train loss: [0.3634597]
batch 97 train loss: [0.40596]
batch 98 train loss: [0.40498418]
batch 99 train loss: [0.36132252]
epoch 2 mean train loss: [0.41034824]
Epoch 2/400=>  train_loss: [0.41034824], iou: nan, cd: 2.2315818643051744, test_mse: [0.40545338]
CORRECT PROGRAMS: 9818
batch 0 train loss: [0.42545834]
batch 1 train loss: [0.3660963]
batch 2 train loss: [0.3356635]
batch 3 train loss: [0.35437265]
batch 4 train loss: [0.31306285]
batch 5 train loss: [0.44201422]
batch 6 train loss: [0.3480324]
batch 7 train loss: [0.33834487]
batch 8 train loss: [0.38385648]
batch 9 train loss: [0.28250378]
batch 10 train loss: [0.39512244]
batch 11 train loss: [0.32106912]
batch 12 train loss: [0.45059967]
batch 13 train loss: [0.3639424]
batch 14 train loss: [0.3960942]
batch 15 train loss: [0.2958954]
batch 16 train loss: [0.42376092]
batch 17 train loss: [0.39037645]
batch 18 train loss: [0.4960872]
batch 19 train loss: [0.3008615]
batch 20 train loss: [0.41473708]
batch 21 train loss: [0.41545382]
batch 22 train loss: [0.41585693]
batch 23 train loss: [0.37758175]
batch 24 train loss: [0.31220782]
batch 25 train loss: [0.47955474]
batch 26 train loss: [0.37354764]
batch 27 train loss: [0.3652175]
batch 28 train loss: [0.38763434]
batch 29 train loss: [0.40393677]
batch 30 train loss: [0.32024512]
batch 31 train loss: [0.3488928]
batch 32 train loss: [0.33984867]
batch 33 train loss: [0.38468796]
batch 34 train loss: [0.3395851]
batch 35 train loss: [0.42104813]
batch 36 train loss: [0.31748295]
batch 37 train loss: [0.415453]
batch 38 train loss: [0.4303205]
batch 39 train loss: [0.3634849]
batch 40 train loss: [0.28466082]
batch 41 train loss: [0.3887757]
batch 42 train loss: [0.39186567]
batch 43 train loss: [0.39935076]
batch 44 train loss: [0.38991797]
batch 45 train loss: [0.39801374]
batch 46 train loss: [0.3441567]
batch 47 train loss: [0.33791077]
batch 48 train loss: [0.4231745]
batch 49 train loss: [0.2879413]
batch 50 train loss: [0.3351627]
batch 51 train loss: [0.40251577]
batch 52 train loss: [0.3523175]
batch 53 train loss: [0.425535]
batch 54 train loss: [0.369633]
batch 55 train loss: [0.4474448]
batch 56 train loss: [0.38742486]
batch 57 train loss: [0.38289207]
batch 58 train loss: [0.31841132]
batch 59 train loss: [0.39119703]
batch 60 train loss: [0.36494794]
batch 61 train loss: [0.37240693]
batch 62 train loss: [0.39167336]
batch 63 train loss: [0.37720785]
batch 64 train loss: [0.37921134]
batch 65 train loss: [0.39550912]
batch 66 train loss: [0.38918096]
batch 67 train loss: [0.37544724]
batch 68 train loss: [0.33142433]
batch 69 train loss: [0.41340292]
batch 70 train loss: [0.3344994]
batch 71 train loss: [0.38583672]
batch 72 train loss: [0.3477296]
batch 73 train loss: [0.41616088]
batch 74 train loss: [0.36372364]
batch 75 train loss: [0.3214144]
batch 76 train loss: [0.34756592]
batch 77 train loss: [0.35315716]
batch 78 train loss: [0.3195679]
batch 79 train loss: [0.38132003]
batch 80 train loss: [0.46513146]
batch 81 train loss: [0.38394755]
batch 82 train loss: [0.41000316]
batch 83 train loss: [0.37084052]
batch 84 train loss: [0.38973263]
batch 85 train loss: [0.40572327]
batch 86 train loss: [0.40098193]
batch 87 train loss: [0.39543346]
batch 88 train loss: [0.3893213]
batch 89 train loss: [0.42114174]
batch 90 train loss: [0.35764596]
batch 91 train loss: [0.3913245]
batch 92 train loss: [0.4085007]
batch 93 train loss: [0.34766632]
batch 94 train loss: [0.46348932]
batch 95 train loss: [0.39298066]
batch 96 train loss: [0.3622743]
batch 97 train loss: [0.2917067]
batch 98 train loss: [0.32835823]
batch 99 train loss: [0.37879288]
epoch 3 mean train loss: [0.37624687]
Epoch 3/400=>  train_loss: [0.37624687], iou: nan, cd: 2.168203122988998, test_mse: [0.394501]
CORRECT PROGRAMS: 9818
batch 0 train loss: [0.3470705]
batch 1 train loss: [0.30017644]
batch 2 train loss: [0.37163597]
batch 3 train loss: [0.33745214]
batch 4 train loss: [0.35868725]
batch 5 train loss: [0.3616175]
batch 6 train loss: [0.28898662]
batch 7 train loss: [0.33893415]
batch 8 train loss: [0.34253237]
batch 9 train loss: [0.38513127]
batch 10 train loss: [0.28161916]
batch 11 train loss: [0.32666612]
batch 12 train loss: [0.36809814]
batch 13 train loss: [0.29150686]
batch 14 train loss: [0.38222486]
batch 15 train loss: [0.3167111]
batch 16 train loss: [0.26718563]
batch 17 train loss: [0.32772017]
batch 18 train loss: [0.38039306]
batch 19 train loss: [0.3249957]
batch 20 train loss: [0.30762237]
batch 21 train loss: [0.34722912]
batch 22 train loss: [0.39147055]
batch 23 train loss: [0.28133357]
batch 24 train loss: [0.29717427]
batch 25 train loss: [0.3463169]
batch 26 train loss: [0.31980056]
batch 27 train loss: [0.36864817]
batch 28 train loss: [0.32521868]
batch 29 train loss: [0.427324]
batch 30 train loss: [0.2942173]
batch 31 train loss: [0.38547054]
batch 32 train loss: [0.26351023]
batch 33 train loss: [0.35949647]
batch 34 train loss: [0.33682954]
batch 35 train loss: [0.3546929]
batch 36 train loss: [0.3509825]
batch 37 train loss: [0.3262559]
batch 38 train loss: [0.29691142]
batch 39 train loss: [0.33315533]
batch 40 train loss: [0.35505953]
batch 41 train loss: [0.39767376]
batch 42 train loss: [0.33631596]
batch 43 train loss: [0.4064576]
batch 44 train loss: [0.38143578]
batch 45 train loss: [0.33461648]
batch 46 train loss: [0.37602246]
batch 47 train loss: [0.3643177]
batch 48 train loss: [0.36468613]
batch 49 train loss: [0.29557067]
batch 50 train loss: [0.34785587]
batch 51 train loss: [0.31144318]
batch 52 train loss: [0.397108]
batch 53 train loss: [0.30409497]
batch 54 train loss: [0.35157117]
batch 55 train loss: [0.3837267]
batch 56 train loss: [0.42333815]
batch 57 train loss: [0.36934868]
batch 58 train loss: [0.3472936]
batch 59 train loss: [0.31303373]
batch 60 train loss: [0.32085764]
batch 61 train loss: [0.35906115]
batch 62 train loss: [0.36762208]
batch 63 train loss: [0.32446945]
batch 64 train loss: [0.34467477]
batch 65 train loss: [0.331352]
batch 66 train loss: [0.40975568]
batch 67 train loss: [0.33900583]
batch 68 train loss: [0.40451518]
batch 69 train loss: [0.34646276]
batch 70 train loss: [0.3554923]
batch 71 train loss: [0.30786985]
batch 72 train loss: [0.41888696]
batch 73 train loss: [0.3274397]
batch 74 train loss: [0.37457806]
batch 75 train loss: [0.47374362]
batch 76 train loss: [0.34605923]
batch 77 train loss: [0.35876572]
batch 78 train loss: [0.32966653]
batch 79 train loss: [0.42576203]
batch 80 train loss: [0.42102537]
batch 81 train loss: [0.30567107]
batch 82 train loss: [0.33689418]
batch 83 train loss: [0.37974474]
batch 84 train loss: [0.35706624]
batch 85 train loss: [0.4160512]
batch 86 train loss: [0.3461949]
batch 87 train loss: [0.35479203]
batch 88 train loss: [0.31538683]
batch 89 train loss: [0.31068012]
batch 90 train loss: [0.33754122]
batch 91 train loss: [0.32180202]
batch 92 train loss: [0.29905605]
batch 93 train loss: [0.32698414]
batch 94 train loss: [0.3688618]
batch 95 train loss: [0.39937365]
batch 96 train loss: [0.35546705]
batch 97 train loss: [0.3350324]
batch 98 train loss: [0.33286774]
batch 99 train loss: [0.42415074]
epoch 4 mean train loss: [0.34884664]
Epoch 4/400=>  train_loss: [0.34884664], iou: nan, cd: 2.241118691729479, test_mse: [0.41069207]
CORRECT PROGRAMS: 9818
batch 0 train loss: [0.29011667]
batch 1 train loss: [0.29157886]
batch 2 train loss: [0.35531738]
batch 3 train loss: [0.27077335]
batch 4 train loss: [0.3181306]
batch 5 train loss: [0.3671427]
batch 6 train loss: [0.31036806]
batch 7 train loss: [0.3279456]
batch 8 train loss: [0.31415102]
batch 9 train loss: [0.2961741]
batch 10 train loss: [0.3723438]
batch 11 train loss: [0.2959101]
batch 12 train loss: [0.28623667]
batch 13 train loss: [0.31582534]
batch 14 train loss: [0.33400768]
batch 15 train loss: [0.34535697]
batch 16 train loss: [0.3052264]
batch 17 train loss: [0.38476843]
batch 18 train loss: [0.36637]
batch 19 train loss: [0.30389035]
batch 20 train loss: [0.22005694]
batch 21 train loss: [0.27497834]
batch 22 train loss: [0.32428712]
batch 23 train loss: [0.38609514]
batch 24 train loss: [0.26625815]
batch 25 train loss: [0.29453874]
batch 26 train loss: [0.35949814]
batch 27 train loss: [0.32148787]
batch 28 train loss: [0.33580342]
batch 29 train loss: [0.3355191]
batch 30 train loss: [0.3330855]
batch 31 train loss: [0.35102078]
batch 32 train loss: [0.3617543]
batch 33 train loss: [0.30275866]
batch 34 train loss: [0.30724987]
batch 35 train loss: [0.3389813]
batch 36 train loss: [0.3013838]
batch 37 train loss: [0.3448306]
batch 38 train loss: [0.32975507]
batch 39 train loss: [0.34905574]
batch 40 train loss: [0.33296007]
batch 41 train loss: [0.37044075]
batch 42 train loss: [0.34252852]
batch 43 train loss: [0.30861983]
batch 44 train loss: [0.23408881]
batch 45 train loss: [0.3096435]
batch 46 train loss: [0.34732655]
batch 47 train loss: [0.32649764]
batch 48 train loss: [0.32647508]
batch 49 train loss: [0.32164568]
batch 50 train loss: [0.29985756]
batch 51 train loss: [0.32191867]
batch 52 train loss: [0.29471025]
batch 53 train loss: [0.3632725]
batch 54 train loss: [0.4018297]
batch 55 train loss: [0.38684905]
batch 56 train loss: [0.37267533]
batch 57 train loss: [0.32613823]
batch 58 train loss: [0.37231892]
batch 59 train loss: [0.32787472]
batch 60 train loss: [0.3095131]
batch 61 train loss: [0.3186475]
batch 62 train loss: [0.29069886]
batch 63 train loss: [0.37093672]
batch 64 train loss: [0.3065005]
batch 65 train loss: [0.27901205]
batch 66 train loss: [0.30678815]
batch 67 train loss: [0.32987657]
batch 68 train loss: [0.34326947]
batch 69 train loss: [0.31242758]
batch 70 train loss: [0.34005553]
batch 71 train loss: [0.3157264]
batch 72 train loss: [0.34731442]
batch 73 train loss: [0.3151447]
batch 74 train loss: [0.31803164]
batch 75 train loss: [0.3688794]
batch 76 train loss: [0.31960297]
batch 77 train loss: [0.2596711]
batch 78 train loss: [0.28979123]
batch 79 train loss: [0.34620208]
batch 80 train loss: [0.29181468]
batch 81 train loss: [0.31745288]
batch 82 train loss: [0.3480222]
batch 83 train loss: [0.32262173]
batch 84 train loss: [0.3702881]
batch 85 train loss: [0.38980344]
batch 86 train loss: [0.3025622]
batch 87 train loss: [0.3791355]
batch 88 train loss: [0.334577]
batch 89 train loss: [0.3098098]
batch 90 train loss: [0.34603512]
batch 91 train loss: [0.37193263]
batch 92 train loss: [0.43189913]
batch 93 train loss: [0.31350383]
batch 94 train loss: [0.35274392]
batch 95 train loss: [0.32674855]
batch 96 train loss: [0.34682903]
batch 97 train loss: [0.3740382]
batch 98 train loss: [0.27271888]
batch 99 train loss: [0.35489768]
epoch 5 mean train loss: [0.32823226]
WAKE SLEEP ITERATION 4
Inferring cad batch: 0
Inferring cad batch: 1
Inferring cad batch: 2
Inferring cad batch: 3
Inferring cad batch: 4
Inferring cad batch: 5
Inferring cad batch: 6
Inferring cad batch: 7
Inferring cad batch: 8
Inferring cad batch: 9
Inferring cad batch: 10
Inferring cad batch: 11
Inferring cad batch: 12
Inferring cad batch: 13
Inferring cad batch: 14
Inferring cad batch: 15
Inferring cad batch: 16
Inferring cad batch: 17
Inferring cad batch: 18
Inferring cad batch: 19
Inferring cad batch: 20
Inferring cad batch: 21
Inferring cad batch: 22
Inferring cad batch: 23
Inferring cad batch: 24
Inferring cad batch: 25
Inferring cad batch: 26
Inferring cad batch: 27
Inferring cad batch: 28
Inferring cad batch: 29
Inferring cad batch: 30
Inferring cad batch: 31
Inferring cad batch: 32
Inferring cad average chamfer distance: 1.4717230754836057
0.5824467222070078 1.4717230754836057
generator epoch 0 loss: 1.0623536507742746                 accuracy: 0.8721428513526917
generator epoch 1 loss: 0.9894714381626674                 accuracy: 0.8828571438789368
generator epoch 2 loss: 0.9587568455287389                 accuracy: 0.9064285755157471
generator epoch 3 loss: 0.9315602129255023                 accuracy: 0.9157142639160156
generator epoch 4 loss: 0.9242611633300781                 accuracy: 0.8864285349845886
generator epoch 5 loss: 0.9095612784249442                 accuracy: 0.9078571200370789
generator epoch 6 loss: 0.9028531223842076                 accuracy: 0.9028571248054504
generator epoch 7 loss: 0.888494446672712                 accuracy: 0.9214285612106323
generator epoch 8 loss: 0.8887868887765067                 accuracy: 0.9164285659790039
generator epoch 9 loss: 0.8776062735421317                 accuracy: 0.9128571152687073
generator epoch 10 loss: 0.8732753836495536                 accuracy: 0.9028571248054504
generator epoch 11 loss: 0.8710590942382812                 accuracy: 0.9135714173316956
generator epoch 12 loss: 0.8656030221121652                 accuracy: 0.8992857336997986
generator epoch 13 loss: 0.8616580235072545                 accuracy: 0.9021428227424622
generator epoch 14 loss: 0.8595071751185825                 accuracy: 0.9149999618530273
generator epoch 15 loss: 0.8572341160365513                 accuracy: 0.9121428728103638
generator epoch 16 loss: 0.8557462271554129                 accuracy: 0.9071428179740906
generator epoch 17 loss: 0.8475786804199219                 accuracy: 0.9221428632736206
generator epoch 18 loss: 0.8429533020019532                 accuracy: 0.9178571105003357
generator epoch 19 loss: 0.8405414219447545                 accuracy: 0.9178571105003357
generator epoch 20 loss: 0.839551762172154                 accuracy: 0.9121428728103638
generator epoch 21 loss: 0.8412260855538505                 accuracy: 0.9121428728103638
generator epoch 22 loss: 0.8364234244210379                 accuracy: 0.9149999618530273
generator epoch 23 loss: 0.8386546587262835                 accuracy: 0.9292857050895691
generator epoch 24 loss: 0.8315849051339286                 accuracy: 0.9350000023841858
generator epoch 25 loss: 0.8297007245744977                 accuracy: 0.9192857146263123
generator epoch 26 loss: 0.8320333731515067                 accuracy: 0.9328571557998657
generator epoch 27 loss: 0.8312111598423549                 accuracy: 0.9371428489685059
generator epoch 28 loss: 0.8299730329241072                 accuracy: 0.918571412563324
generator epoch 29 loss: 0.8290635053362165                 accuracy: 0.9235714077949524
generator epoch 30 loss: 0.8308714172363282                 accuracy: 0.9228571057319641
generator epoch 31 loss: 0.8216840323311942                 accuracy: 0.9235714077949524
generator epoch 32 loss: 0.826358625139509                 accuracy: 0.9192857146263123
generator epoch 33 loss: 0.8173645856584821                 accuracy: 0.918571412563324
generator epoch 34 loss: 0.8189029584612165                 accuracy: 0.927142858505249
generator epoch 35 loss: 0.8192565743582589                 accuracy: 0.9300000071525574
generator epoch 36 loss: 0.822684162248884                 accuracy: 0.9214285612106323
generator epoch 37 loss: 0.8210008884974889                 accuracy: 0.9149999618530273
generator epoch 38 loss: 0.818197660609654                 accuracy: 0.9228571057319641
generator epoch 39 loss: 0.8221508518763951                 accuracy: 0.9142857193946838
generator epoch 40 loss: 0.8152800275530134                 accuracy: 0.9385713934898376
generator epoch 41 loss: 0.8138940403529575                 accuracy: 0.9314285516738892
generator epoch 42 loss: 0.8140000636509487                 accuracy: 0.9171428680419922
generator epoch 43 loss: 0.8115964242117746                 accuracy: 0.9314285516738892
generator epoch 44 loss: 0.8102815595354352                 accuracy: 0.9099999666213989
generator epoch 45 loss: 0.8135528669084822                 accuracy: 0.918571412563324
generator epoch 46 loss: 0.8141770080566406                 accuracy: 0.9278571605682373
generator epoch 47 loss: 0.8057831551688058                 accuracy: 0.9300000071525574
generator epoch 48 loss: 0.8084594630650112                 accuracy: 0.9214285612106323
generator epoch 49 loss: 0.8051638331821986                 accuracy: 0.9285714030265808
generator epoch 50 loss: 0.8081652775355748                 accuracy: 0.9307142496109009
generator epoch 51 loss: 0.8051310651506697                 accuracy: 0.9128571152687073
generator epoch 52 loss: 0.8062486075265067                 accuracy: 0.918571412563324
generator epoch 53 loss: 0.8040992649623326                 accuracy: 0.9099999666213989
generator epoch 54 loss: 0.7974831324986049                 accuracy: 0.9264285564422607
generator epoch 55 loss: 0.7994663739885602                 accuracy: 0.9221428632736206
generator epoch 56 loss: 0.8047620003836495                 accuracy: 0.9357143044471741
generator epoch 57 loss: 0.8011922672816685                 accuracy: 0.9328571557998657
generator epoch 58 loss: 0.8051653878348214                 accuracy: 0.918571412563324
generator epoch 59 loss: 0.8020435729980468                 accuracy: 0.9171428680419922
generator epoch 60 loss: 0.8028785339355469                 accuracy: 0.9335713982582092
generator epoch 61 loss: 0.7997222534179688                 accuracy: 0.9342857003211975
generator epoch 62 loss: 0.7991106157575335                 accuracy: 0.9164285659790039
generator epoch 63 loss: 0.7966710396902902                 accuracy: 0.9428571462631226
generator epoch 64 loss: 0.7970764526367188                 accuracy: 0.9192857146263123
generator epoch 65 loss: 0.7951787584577288                 accuracy: 0.925000011920929
generator epoch 66 loss: 0.7934726470947265                 accuracy: 0.9300000071525574
generator epoch 67 loss: 0.7964427716936384                 accuracy: 0.9242857098579407
generator epoch 68 loss: 0.796689128766741                 accuracy: 0.9221428632736206
generator epoch 69 loss: 0.7928715794154576                 accuracy: 0.9300000071525574
generator epoch 70 loss: 0.7947108494349888                 accuracy: 0.9135714173316956
generator epoch 71 loss: 0.7981721840994699                 accuracy: 0.9214285612106323
generator epoch 72 loss: 0.7916674325125558                 accuracy: 0.920714259147644
generator epoch 73 loss: 0.7927900970458984                 accuracy: 0.9142857193946838
generator epoch 74 loss: 0.7954726728166853                 accuracy: 0.9335713982582092
generator epoch 75 loss: 0.7967890101841518                 accuracy: 0.9228571057319641
generator epoch 76 loss: 0.7928294320242746                 accuracy: 0.9242857098579407
generator epoch 77 loss: 0.79507077898298                 accuracy: 0.9307142496109009
generator epoch 78 loss: 0.786367629132952                 accuracy: 0.9421428442001343
generator epoch 79 loss: 0.7916486633300781                 accuracy: 0.9278571605682373
generator epoch 80 loss: 0.7879598484584264                 accuracy: 0.9149999618530273
generator epoch 81 loss: 0.7899052407400948                 accuracy: 0.9128571152687073
generator epoch 82 loss: 0.7903107661655971                 accuracy: 0.9300000071525574
generator epoch 83 loss: 0.7970729997907366                 accuracy: 0.9371428489685059
generator epoch 84 loss: 0.7881775399344308                 accuracy: 0.9357143044471741
generator epoch 85 loss: 0.7904612819126674                 accuracy: 0.9142857193946838
generator epoch 86 loss: 0.7912230320521764                 accuracy: 0.9235714077949524
generator epoch 87 loss: 0.7883600128173828                 accuracy: 0.9214285612106323
generator epoch 88 loss: 0.7857378875732421                 accuracy: 0.9307142496109009
generator epoch 89 loss: 0.786897736467634                 accuracy: 0.9235714077949524
generator epoch 90 loss: 0.7888740870884486                 accuracy: 0.9442856907844543
generator epoch 91 loss: 0.7891016326904297                 accuracy: 0.9221428632736206
generator epoch 92 loss: 0.7842592302594866                 accuracy: 0.9321428537368774
generator epoch 93 loss: 0.7823615543910435                 accuracy: 0.9300000071525574
generator epoch 94 loss: 0.7847156223842076                 accuracy: 0.9328571557998657
generator epoch 95 loss: 0.7881829746791295                 accuracy: 0.9314285516738892
generator epoch 96 loss: 0.7853273193359375                 accuracy: 0.9328571557998657
generator epoch 97 loss: 0.7839430938720703                 accuracy: 0.918571412563324
generator epoch 98 loss: 0.7768154689243861                 accuracy: 0.9278571605682373
generator epoch 99 loss: 0.7819711434500558                 accuracy: 0.9228571057319641
generator epoch 100 loss: 0.7869741450718472                 accuracy: 0.9307142496109009
generator epoch 101 loss: 0.786759632219587                 accuracy: 0.9342857003211975
generator epoch 102 loss: 0.7794388022286551                 accuracy: 0.9557142853736877
generator epoch 103 loss: 0.7831366398402623                 accuracy: 0.9228571057319641
generator epoch 104 loss: 0.7802035147530691                 accuracy: 0.9314285516738892
generator epoch 105 loss: 0.7827173052106585                 accuracy: 0.9385713934898376
generator epoch 106 loss: 0.7814525290352957                 accuracy: 0.9321428537368774
generator epoch 107 loss: 0.7820401070731027                 accuracy: 0.9492856860160828
generator epoch 108 loss: 0.7833110866001675                 accuracy: 0.9350000023841858
generator epoch 109 loss: 0.7815208448137556                 accuracy: 0.9371428489685059
generator epoch 110 loss: 0.7813347176688058                 accuracy: 0.9314285516738892
generator epoch 111 loss: 0.7828517168317523                 accuracy: 0.9364285469055176
generator epoch 112 loss: 0.79006204964774                 accuracy: 0.9200000166893005
generator epoch 113 loss: 0.7799430376325335                 accuracy: 0.9228571057319641
generator epoch 114 loss: 0.7799431993756976                 accuracy: 0.9371428489685059
generator epoch 115 loss: 0.7809542184012277                 accuracy: 0.9392856955528259
generator epoch 116 loss: 0.7756724714006696                 accuracy: 0.9542856812477112
generator epoch 117 loss: 0.7798104614257813                 accuracy: 0.9428571462631226
generator epoch 118 loss: 0.780518796648298                 accuracy: 0.9257142543792725
generator epoch 119 loss: 0.7877220380510602                 accuracy: 0.9314285516738892
generator epoch 120 loss: 0.7800279510498047                 accuracy: 0.9364285469055176
generator epoch 121 loss: 0.7780332371303014                 accuracy: 0.9292857050895691
generator epoch 122 loss: 0.7749175602504186                 accuracy: 0.9428571462631226
generator epoch 123 loss: 0.7789055546351842                 accuracy: 0.9328571557998657
generator epoch 124 loss: 0.773239926147461                 accuracy: 0.9264285564422607
generator epoch 125 loss: 0.7765092716761998                 accuracy: 0.9328571557998657
generator epoch 126 loss: 0.7732910465785435                 accuracy: 0.9300000071525574
generator epoch 127 loss: 0.7730459320068359                 accuracy: 0.9449999928474426
generator epoch 128 loss: 0.7745185468401228                 accuracy: 0.9328571557998657
generator epoch 129 loss: 0.7724909694126674                 accuracy: 0.925000011920929
generator epoch 130 loss: 0.7747957114083426                 accuracy: 0.9342857003211975
generator epoch 131 loss: 0.7777937805175781                 accuracy: 0.925000011920929
generator epoch 132 loss: 0.7769428859165737                 accuracy: 0.927142858505249
generator epoch 133 loss: 0.7778600027901785                 accuracy: 0.9371428489685059
generator epoch 134 loss: 0.7752379629952567                 accuracy: 0.9328571557998657
generator epoch 135 loss: 0.7782556004115513                 accuracy: 0.9228571057319641
generator epoch 136 loss: 0.7724873604910715                 accuracy: 0.9392856955528259
generator epoch 137 loss: 0.7700976771763393                 accuracy: 0.947857141494751
generator epoch 138 loss: 0.7753929892403739                 accuracy: 0.9357143044471741
generator epoch 139 loss: 0.7729429931640625                 accuracy: 0.9421428442001343
generator epoch 140 loss: 0.7766215911865234                 accuracy: 0.9378571510314941
generator epoch 141 loss: 0.7781495740618024                 accuracy: 0.941428542137146
generator epoch 142 loss: 0.7707568559919085                 accuracy: 0.9235714077949524
generator epoch 143 loss: 0.7723962084089007                 accuracy: 0.941428542137146
generator epoch 144 loss: 0.7739478297642299                 accuracy: 0.9350000023841858
generator epoch 145 loss: 0.7699905875069755                 accuracy: 0.9364285469055176
generator epoch 146 loss: 0.7748814771379743                 accuracy: 0.9328571557998657
generator epoch 147 loss: 0.773419584437779                 accuracy: 0.9328571557998657
generator epoch 148 loss: 0.7716245893205915                 accuracy: 0.941428542137146
generator epoch 149 loss: 0.7723192313058036                 accuracy: 0.9285714030265808
generator epoch 150 loss: 0.7709885973249163                 accuracy: 0.9507142901420593
generator epoch 151 loss: 0.7733013214111328                 accuracy: 0.9442856907844543
generator epoch 152 loss: 0.7722406053815569                 accuracy: 0.925000011920929
generator epoch 153 loss: 0.777605850655692                 accuracy: 0.9457142949104309
generator epoch 154 loss: 0.7711222983224051                 accuracy: 0.9307142496109009
generator epoch 155 loss: 0.7727050061907087                 accuracy: 0.9328571557998657
generator epoch 156 loss: 0.7665290967668806                 accuracy: 0.9335713982582092
generator epoch 157 loss: 0.7689731515066964                 accuracy: 0.9121428728103638
generator epoch 158 loss: 0.7654012211390904                 accuracy: 0.925000011920929
generator epoch 159 loss: 0.7669618626185826                 accuracy: 0.9350000023841858
generator epoch 160 loss: 0.7713193276541573                 accuracy: 0.9300000071525574
generator epoch 161 loss: 0.7689853524344308                 accuracy: 0.9378571510314941
generator epoch 162 loss: 0.7690105442592076                 accuracy: 0.9421428442001343
generator epoch 163 loss: 0.7629797733851842                 accuracy: 0.9378571510314941
generator epoch 164 loss: 0.7687703918457032                 accuracy: 0.9492856860160828
generator epoch 165 loss: 0.7698446572440011                 accuracy: 0.9428571462631226
generator epoch 166 loss: 0.7708880602155413                 accuracy: 0.9328571557998657
generator epoch 167 loss: 0.769842058454241                 accuracy: 0.9371428489685059
generator epoch 168 loss: 0.7680872423444476                 accuracy: 0.9235714077949524
generator epoch 169 loss: 0.768318647984096                 accuracy: 0.9385713934898376
generator epoch 170 loss: 0.7718041115897042                 accuracy: 0.9342857003211975
generator epoch 171 loss: 0.7707350921630859                 accuracy: 0.9350000023841858
generator epoch 172 loss: 0.7698352369035993                 accuracy: 0.9300000071525574
generator epoch 173 loss: 0.7613828901018416                 accuracy: 0.9392856955528259
generator epoch 174 loss: 0.7665773158482143                 accuracy: 0.9221428632736206
generator epoch 175 loss: 0.770235342843192                 accuracy: 0.9428571462631226
generator epoch 176 loss: 0.7667515768868582                 accuracy: 0.9357143044471741
generator epoch 177 loss: 0.7668949336460659                 accuracy: 0.9285714030265808
generator epoch 178 loss: 0.7671536385672433                 accuracy: 0.9342857003211975
generator epoch 179 loss: 0.7631399775913783                 accuracy: 0.9307142496109009
generator epoch 180 loss: 0.7635666966029576                 accuracy: 0.9407142996788025
generator epoch 181 loss: 0.7631479252406529                 accuracy: 0.947857141494751
generator epoch 182 loss: 0.7656505593436105                 accuracy: 0.9300000071525574
generator epoch 183 loss: 0.7649328063964844                 accuracy: 0.9321428537368774
generator epoch 184 loss: 0.7669717843191964                 accuracy: 0.9492856860160828
generator epoch 185 loss: 0.765861705671038                 accuracy: 0.9371428489685059
generator epoch 186 loss: 0.7682132167271205                 accuracy: 0.9457142949104309
generator epoch 187 loss: 0.7630330684116908                 accuracy: 0.9342857003211975
generator epoch 188 loss: 0.765853719656808                 accuracy: 0.9492856860160828
generator epoch 189 loss: 0.7619598406110492                 accuracy: 0.9242857098579407
generator epoch 190 loss: 0.7663739170619419                 accuracy: 0.9321428537368774
generator epoch 191 loss: 0.7671044764927455                 accuracy: 0.941428542137146
generator epoch 192 loss: 0.7610692326136997                 accuracy: 0.9371428489685059
generator epoch 193 loss: 0.7750282584054129                 accuracy: 0.9392856955528259
generator epoch 194 loss: 0.7708830431256976                 accuracy: 0.9235714077949524
generator epoch 195 loss: 0.7643987422398159                 accuracy: 0.9385713934898376
generator epoch 196 loss: 0.7636940189906529                 accuracy: 0.9421428442001343
generator epoch 197 loss: 0.7667437029157366                 accuracy: 0.9350000023841858
generator epoch 198 loss: 0.761359463936942                 accuracy: 0.9350000023841858
generator epoch 199 loss: 0.7618700465611049                 accuracy: 0.9314285516738892
generator epoch 200 loss: 0.7639870234898158                 accuracy: 0.9399999976158142
generator epoch 201 loss: 0.7604614375523159                 accuracy: 0.9335713982582092
generator epoch 202 loss: 0.7630720271519252                 accuracy: 0.9285714030265808
generator epoch 203 loss: 0.7670884953090122                 accuracy: 0.9328571557998657
generator epoch 204 loss: 0.7577549482073103                 accuracy: 0.9392856955528259
generator epoch 205 loss: 0.7630218248639788                 accuracy: 0.9300000071525574
generator epoch 206 loss: 0.7646029615129744                 accuracy: 0.9364285469055176
generator epoch 207 loss: 0.7640684208461217                 accuracy: 0.9364285469055176
generator epoch 208 loss: 0.7596195792061942                 accuracy: 0.9492856860160828
generator epoch 209 loss: 0.759625698852539                 accuracy: 0.949999988079071
generator epoch 210 loss: 0.7599429299490792                 accuracy: 0.9378571510314941
generator epoch 211 loss: 0.7619579354422433                 accuracy: 0.9364285469055176
generator epoch 212 loss: 0.7630052403041294                 accuracy: 0.9278571605682373
generator epoch 213 loss: 0.7681477207728795                 accuracy: 0.9342857003211975
generator epoch 214 loss: 0.7551141906738281                 accuracy: 0.9307142496109009
generator epoch 215 loss: 0.7597471670968192                 accuracy: 0.9421428442001343
generator epoch 216 loss: 0.7634337602887835                 accuracy: 0.9221428632736206
generator epoch 217 loss: 0.7576795100620815                 accuracy: 0.9471428394317627
generator epoch 218 loss: 0.7613237649100167                 accuracy: 0.947857141494751
generator epoch 219 loss: 0.7617575330461774                 accuracy: 0.927142858505249
generator epoch 220 loss: 0.762763642665318                 accuracy: 0.9292857050895691
generator epoch 221 loss: 0.7631668409075055                 accuracy: 0.9264285564422607
generator epoch 222 loss: 0.7601969386509486                 accuracy: 0.9371428489685059
generator epoch 223 loss: 0.7572353751046317                 accuracy: 0.9421428442001343
generator epoch 224 loss: 0.765538314819336                 accuracy: 0.949999988079071
generator epoch 225 loss: 0.7602815813337054                 accuracy: 0.949999988079071
generator epoch 226 loss: 0.7641748713902065                 accuracy: 0.9350000023841858
generator epoch 227 loss: 0.7560364266531808                 accuracy: 0.9407142996788025
generator epoch 228 loss: 0.7596430010114398                 accuracy: 0.9385713934898376
generator epoch 229 loss: 0.7644869611467634                 accuracy: 0.9328571557998657
generator epoch 230 loss: 0.7603131770542689                 accuracy: 0.9328571557998657
generator epoch 231 loss: 0.7619953648158482                 accuracy: 0.9528571367263794
generator epoch 232 loss: 0.7599647247314453                 accuracy: 0.9300000071525574
generator epoch 233 loss: 0.7643597756522043                 accuracy: 0.9285714030265808
generator epoch 234 loss: 0.7609402757917132                 accuracy: 0.9399999976158142
generator epoch 235 loss: 0.7558332680838449                 accuracy: 0.9507142901420593
generator epoch 236 loss: 0.7568481100899832                 accuracy: 0.9435713887214661
generator epoch 237 loss: 0.7571269753592355                 accuracy: 0.9364285469055176
generator epoch 238 loss: 0.7623650665283204                 accuracy: 0.9407142996788025
generator epoch 239 loss: 0.7634578866141183                 accuracy: 0.9392856955528259
generator epoch 240 loss: 0.761536183820452                 accuracy: 0.9307142496109009
generator epoch 241 loss: 0.7605318359375                 accuracy: 0.9407142996788025
generator epoch 242 loss: 0.7601162418910435                 accuracy: 0.9242857098579407
generator epoch 243 loss: 0.7616850777762276                 accuracy: 0.9350000023841858
generator epoch 244 loss: 0.7582637416294643                 accuracy: 0.9457142949104309
generator epoch 245 loss: 0.7551219203404018                 accuracy: 0.9521428346633911
generator epoch 246 loss: 0.7561991128104074                 accuracy: 0.9378571510314941
generator epoch 247 loss: 0.7566100254603795                 accuracy: 0.9485714435577393
generator epoch 248 loss: 0.7595025442940848                 accuracy: 0.9485714435577393
generator epoch 249 loss: 0.759939402117048                 accuracy: 0.9257142543792725
generator epoch 250 loss: 0.7554865504673549                 accuracy: 0.9285714030265808
generator epoch 251 loss: 0.7633932080950055                 accuracy: 0.9257142543792725
generator epoch 252 loss: 0.7594904519217355                 accuracy: 0.9385713934898376
generator epoch 253 loss: 0.7599297236851283                 accuracy: 0.9307142496109009
generator epoch 254 loss: 0.7670896920340402                 accuracy: 0.9464285373687744
generator epoch 255 loss: 0.7664969111851283                 accuracy: 0.9428571462631226
generator epoch 256 loss: 0.7588853781563895                 accuracy: 0.9435713887214661
generator epoch 257 loss: 0.7553736934116908                 accuracy: 0.9507142901420593
generator epoch 258 loss: 0.7608957179478236                 accuracy: 0.9428571462631226
generator epoch 259 loss: 0.7577144252232143                 accuracy: 0.9521428346633911
generator epoch 260 loss: 0.7548354213169642                 accuracy: 0.9464285373687744
generator epoch 261 loss: 0.756879740687779                 accuracy: 0.9435713887214661
generator epoch 262 loss: 0.7578392229352678                 accuracy: 0.9492856860160828
generator epoch 263 loss: 0.7555239384242467                 accuracy: 0.9371428489685059
generator epoch 264 loss: 0.7529846631731306                 accuracy: 0.9399999976158142
generator epoch 265 loss: 0.752281052507673                 accuracy: 0.9442856907844543
generator epoch 266 loss: 0.7528281681605747                 accuracy: 0.947857141494751
generator epoch 267 loss: 0.7568905203683036                 accuracy: 0.9350000023841858
generator epoch 268 loss: 0.7522294847760882                 accuracy: 0.9464285373687744
generator epoch 269 loss: 0.75492392578125                 accuracy: 0.9428571462631226
generator epoch 270 loss: 0.7600618835449219                 accuracy: 0.9514285326004028
generator epoch 271 loss: 0.7550786917550223                 accuracy: 0.9371428489685059
generator epoch 272 loss: 0.755195032610212                 accuracy: 0.9457142949104309
generator epoch 273 loss: 0.753969069126674                 accuracy: 0.9471428394317627
generator epoch 274 loss: 0.7568896955217634                 accuracy: 0.947857141494751
generator epoch 275 loss: 0.7555024963378906                 accuracy: 0.9357143044471741
generator epoch 276 loss: 0.7508696058000837                 accuracy: 0.9428571462631226
generator epoch 277 loss: 0.7588535317557199                 accuracy: 0.9342857003211975
generator epoch 278 loss: 0.7594984335763114                 accuracy: 0.941428542137146
generator epoch 279 loss: 0.7500844678606305                 accuracy: 0.9549999833106995
generator epoch 280 loss: 0.7576333099365234                 accuracy: 0.9471428394317627
generator epoch 281 loss: 0.750105927821568                 accuracy: 0.9514285326004028
generator epoch 282 loss: 0.7520371878487723                 accuracy: 0.9442856907844543
generator epoch 283 loss: 0.7587296116420201                 accuracy: 0.9535714387893677
generator epoch 284 loss: 0.7508426409040179                 accuracy: 0.947857141494751
generator epoch 285 loss: 0.7601637978690011                 accuracy: 0.9378571510314941
generator epoch 286 loss: 0.759814557320731                 accuracy: 0.9328571557998657
generator epoch 287 loss: 0.7594122990199498                 accuracy: 0.9321428537368774
generator epoch 288 loss: 0.7522943603515625                 accuracy: 0.9314285516738892
generator epoch 289 loss: 0.7530871930803571                 accuracy: 0.9428571462631226
generator epoch 290 loss: 0.7532659877232143                 accuracy: 0.925000011920929
generator epoch 291 loss: 0.750839113507952                 accuracy: 0.9449999928474426
generator epoch 292 loss: 0.7573195343017578                 accuracy: 0.9421428442001343
generator epoch 293 loss: 0.7518456072126116                 accuracy: 0.9342857003211975
generator epoch 294 loss: 0.7613656350272042                 accuracy: 0.9485714435577393
generator epoch 295 loss: 0.7507351087297712                 accuracy: 0.9442856907844543
generator epoch 296 loss: 0.7513030914306641                 accuracy: 0.9557142853736877
generator epoch 297 loss: 0.7539209694998605                 accuracy: 0.9385713934898376
generator epoch 298 loss: 0.7509811017717634                 accuracy: 0.9542856812477112
generator epoch 299 loss: 0.748486852155413                 accuracy: 0.9407142996788025
generator epoch 300 loss: 0.7482887978690012                 accuracy: 0.9507142901420593
generator epoch 301 loss: 0.752936780657087                 accuracy: 0.9392856955528259
generator epoch 302 loss: 0.7540761635916574                 accuracy: 0.9449999928474426
generator epoch 303 loss: 0.7531562726702009                 accuracy: 0.9464285373687744
generator epoch 304 loss: 0.7552133013044084                 accuracy: 0.9292857050895691
generator epoch 305 loss: 0.7503180930001395                 accuracy: 0.941428542137146
generator epoch 306 loss: 0.7495789542061942                 accuracy: 0.9321428537368774
generator epoch 307 loss: 0.7531277526855469                 accuracy: 0.9535714387893677
generator epoch 308 loss: 0.7583579607282366                 accuracy: 0.949999988079071
generator epoch 309 loss: 0.7519875435965402                 accuracy: 0.9457142949104309
generator epoch 310 loss: 0.7503334655761719                 accuracy: 0.9314285516738892
generator epoch 311 loss: 0.7470275874546596                 accuracy: 0.9357143044471741
generator epoch 312 loss: 0.7507220563616072                 accuracy: 0.9542856812477112
generator epoch 313 loss: 0.7518182965959821                 accuracy: 0.9528571367263794
generator epoch 314 loss: 0.7525443734305246                 accuracy: 0.9378571510314941
generator epoch 315 loss: 0.7513952972412109                 accuracy: 0.9350000023841858
generator epoch 316 loss: 0.7508951655796596                 accuracy: 0.9385713934898376
generator epoch 317 loss: 0.7499630994524275                 accuracy: 0.9407142996788025
generator epoch 318 loss: 0.7536981340680804                 accuracy: 0.9507142901420593
generator epoch 319 loss: 0.7541025626046317                 accuracy: 0.9321428537368774
generator epoch 320 loss: 0.7461159820556641                 accuracy: 0.9378571510314941
generator epoch 321 loss: 0.7470600821358817                 accuracy: 0.9392856955528259
generator epoch 322 loss: 0.7469236720493861                 accuracy: 0.9471428394317627
generator epoch 323 loss: 0.7484128404889788                 accuracy: 0.9300000071525574
generator epoch 324 loss: 0.7495556605747767                 accuracy: 0.9350000023841858
generator epoch 325 loss: 0.7517827000209263                 accuracy: 0.9442856907844543
generator epoch 326 loss: 0.7455421970912388                 accuracy: 0.9392856955528259
generator epoch 327 loss: 0.7518132014683315                 accuracy: 0.9378571510314941
generator epoch 328 loss: 0.7496887398856027                 accuracy: 0.949999988079071
generator epoch 329 loss: 0.7520370243617467                 accuracy: 0.947857141494751
generator epoch 330 loss: 0.7468722416469029                 accuracy: 0.9457142949104309
generator epoch 331 loss: 0.7434248888288225                 accuracy: 0.9399999976158142
generator epoch 332 loss: 0.7574843505859375                 accuracy: 0.9492856860160828
generator epoch 333 loss: 0.7532286974225726                 accuracy: 0.9307142496109009
generator epoch 334 loss: 0.7505161381312779                 accuracy: 0.9407142996788025
generator epoch 335 loss: 0.7473334756033762                 accuracy: 0.9449999928474426
generator epoch 336 loss: 0.7483109767368862                 accuracy: 0.9300000071525574
generator epoch 337 loss: 0.7526854862758091                 accuracy: 0.9435713887214661
generator epoch 338 loss: 0.7572548993791852                 accuracy: 0.9464285373687744
generator epoch 339 loss: 0.7517685791015625                 accuracy: 0.9535714387893677
generator epoch 340 loss: 0.7492838854108538                 accuracy: 0.947857141494751
generator epoch 341 loss: 0.7503915296282087                 accuracy: 0.9442856907844543
generator epoch 342 loss: 0.7509127393450056                 accuracy: 0.9399999976158142
generator epoch 343 loss: 0.7486532828194754                 accuracy: 0.9457142949104309
generator epoch 344 loss: 0.7505316288539341                 accuracy: 0.9435713887214661
generator epoch 345 loss: 0.7510440665108817                 accuracy: 0.9471428394317627
generator epoch 346 loss: 0.7435406747000558                 accuracy: 0.9435713887214661
generator epoch 347 loss: 0.7491254900251116                 accuracy: 0.9521428346633911
generator epoch 348 loss: 0.7484398507254464                 accuracy: 0.9285714030265808
generator epoch 349 loss: 0.7488761287144252                 accuracy: 0.9364285469055176
generator epoch 350 loss: 0.7544251033238002                 accuracy: 0.9364285469055176
generator epoch 351 loss: 0.7526564705984933                 accuracy: 0.9449999928474426
generator epoch 352 loss: 0.7505181884765625                 accuracy: 0.9649999737739563
generator epoch 353 loss: 0.7499834171840123                 accuracy: 0.9599999785423279
generator epoch 354 loss: 0.7471717472621373                 accuracy: 0.9485714435577393
generator epoch 355 loss: 0.7507102931431362                 accuracy: 0.9535714387893677
generator epoch 356 loss: 0.754803908429827                 accuracy: 0.9435713887214661
generator epoch 357 loss: 0.7458197396414621                 accuracy: 0.9328571557998657
generator epoch 358 loss: 0.7467855922154018                 accuracy: 0.9457142949104309
generator epoch 359 loss: 0.748195949445452                 accuracy: 0.9442856907844543
generator epoch 360 loss: 0.7484726239885603                 accuracy: 0.9514285326004028
generator epoch 361 loss: 0.7481367030552455                 accuracy: 0.9535714387893677
generator epoch 362 loss: 0.7475234492710658                 accuracy: 0.947857141494751
generator epoch 363 loss: 0.747933251953125                 accuracy: 0.9449999928474426
generator epoch 364 loss: 0.7473255663190569                 accuracy: 0.9485714435577393
generator epoch 365 loss: 0.7477329820905413                 accuracy: 0.9521428346633911
generator epoch 366 loss: 0.7476872440883091                 accuracy: 0.9442856907844543
generator epoch 367 loss: 0.7444629603794642                 accuracy: 0.9435713887214661
generator epoch 368 loss: 0.7507663691929408                 accuracy: 0.9528571367263794
generator epoch 369 loss: 0.7497705344063895                 accuracy: 0.9428571462631226
generator epoch 370 loss: 0.744851198904855                 accuracy: 0.9428571462631226
generator epoch 371 loss: 0.747417953491211                 accuracy: 0.9392856955528259
generator epoch 372 loss: 0.7466195473807199                 accuracy: 0.9435713887214661
generator epoch 373 loss: 0.751524220929827                 accuracy: 0.941428542137146
generator epoch 374 loss: 0.7532284327915737                 accuracy: 0.9342857003211975
generator epoch 375 loss: 0.745517380632673                 accuracy: 0.9557142853736877
generator epoch 376 loss: 0.7436087049211775                 accuracy: 0.947857141494751
generator epoch 377 loss: 0.7444798069545201                 accuracy: 0.9449999928474426
generator epoch 378 loss: 0.743110109601702                 accuracy: 0.941428542137146
generator epoch 379 loss: 0.7503990221296037                 accuracy: 0.9442856907844543
generator epoch 380 loss: 0.7510909532819475                 accuracy: 0.941428542137146
generator epoch 381 loss: 0.7460657854352678                 accuracy: 0.9357143044471741
generator epoch 382 loss: 0.7515432242257254                 accuracy: 0.9421428442001343
generator epoch 383 loss: 0.744735071672712                 accuracy: 0.9549999833106995
generator epoch 384 loss: 0.7415898119245257                 accuracy: 0.9435713887214661
generator epoch 385 loss: 0.7494753893171038                 accuracy: 0.9649999737739563
generator epoch 386 loss: 0.7446210178920201                 accuracy: 0.9385713934898376
generator epoch 387 loss: 0.7476149121965681                 accuracy: 0.9378571510314941
generator epoch 388 loss: 0.7485038199288504                 accuracy: 0.9578571319580078
generator epoch 389 loss: 0.7488813459123884                 accuracy: 0.9449999928474426
generator epoch 390 loss: 0.7473587807791574                 accuracy: 0.9457142949104309
generator epoch 391 loss: 0.7438751739501953                 accuracy: 0.9428571462631226
generator epoch 392 loss: 0.7510606253487723                 accuracy: 0.9492856860160828
generator epoch 393 loss: 0.745578728376116                 accuracy: 0.9364285469055176
generator epoch 394 loss: 0.7431184605189732                 accuracy: 0.9471428394317627
generator epoch 395 loss: 0.7451702492850167                 accuracy: 0.9435713887214661
generator epoch 396 loss: 0.744792860194615                 accuracy: 0.9435713887214661
generator epoch 397 loss: 0.7454431178501674                 accuracy: 0.9364285469055176
generator epoch 398 loss: 0.7477303911481585                 accuracy: 0.9342857003211975
generator epoch 399 loss: 0.7479550284249442                 accuracy: 0.9521428346633911
generator epoch 400 loss: 0.7440247397286551                 accuracy: 0.9399999976158142
generator epoch 401 loss: 0.743009279523577                 accuracy: 0.9357143044471741
generator epoch 402 loss: 0.7465175118582589                 accuracy: 0.9442856907844543
generator epoch 403 loss: 0.7471265171595982                 accuracy: 0.9421428442001343
generator epoch 404 loss: 0.7525757690429687                 accuracy: 0.9464285373687744
generator epoch 405 loss: 0.7406977717808315                 accuracy: 0.9392856955528259
generator epoch 406 loss: 0.7467229963030134                 accuracy: 0.949999988079071
generator epoch 407 loss: 0.7439645634242467                 accuracy: 0.9464285373687744
generator epoch 408 loss: 0.7468017168317522                 accuracy: 0.9457142949104309
generator epoch 409 loss: 0.7500561257498605                 accuracy: 0.9385713934898376
generator epoch 410 loss: 0.7507343270438058                 accuracy: 0.9528571367263794
generator epoch 411 loss: 0.7456529370989118                 accuracy: 0.9599999785423279
generator epoch 412 loss: 0.7465011112758092                 accuracy: 0.9392856955528259
generator epoch 413 loss: 0.7529560150146485                 accuracy: 0.9528571367263794
generator epoch 414 loss: 0.7504244166782924                 accuracy: 0.925000011920929
generator epoch 415 loss: 0.7498998783656529                 accuracy: 0.9435713887214661
generator epoch 416 loss: 0.7471285409109933                 accuracy: 0.9378571510314941
generator epoch 417 loss: 0.7479927080426897                 accuracy: 0.9549999833106995
generator epoch 418 loss: 0.7465876390729632                 accuracy: 0.9571428298950195
generator epoch 419 loss: 0.7462672633579799                 accuracy: 0.9399999976158142
generator epoch 420 loss: 0.7454345694405692                 accuracy: 0.9578571319580078
generator epoch 421 loss: 0.7411619384765625                 accuracy: 0.9492856860160828
generator epoch 422 loss: 0.7452148267473493                 accuracy: 0.9328571557998657
generator epoch 423 loss: 0.7437497366768974                 accuracy: 0.9557142853736877
generator epoch 424 loss: 0.7500714237758092                 accuracy: 0.9399999976158142
generator epoch 425 loss: 0.7455158342633929                 accuracy: 0.9457142949104309
generator epoch 426 loss: 0.7493262860979353                 accuracy: 0.9507142901420593
generator epoch 427 loss: 0.7429547616141183                 accuracy: 0.9457142949104309
generator epoch 428 loss: 0.7418826960972377                 accuracy: 0.9421428442001343
generator epoch 429 loss: 0.7457188071114677                 accuracy: 0.9307142496109009
generator epoch 430 loss: 0.7392297101702009                 accuracy: 0.9435713887214661
generator epoch 431 loss: 0.7414840924944196                 accuracy: 0.9578571319580078
generator epoch 432 loss: 0.7449673854282924                 accuracy: 0.9435713887214661
generator epoch 433 loss: 0.7386477565220424                 accuracy: 0.9307142496109009
generator epoch 434 loss: 0.7430997501918247                 accuracy: 0.9471428394317627
generator epoch 435 loss: 0.7397369703020368                 accuracy: 0.9471428394317627
generator epoch 436 loss: 0.7418822583879743                 accuracy: 0.9535714387893677
generator epoch 437 loss: 0.7435983411516462                 accuracy: 0.9385713934898376
generator epoch 438 loss: 0.7425430637904575                 accuracy: 0.9342857003211975
generator epoch 439 loss: 0.7457293810163226                 accuracy: 0.9371428489685059
generator epoch 440 loss: 0.7479828643798828                 accuracy: 0.9378571510314941
generator epoch 441 loss: 0.7446430733816964                 accuracy: 0.9457142949104309
generator epoch 442 loss: 0.745949966430664                 accuracy: 0.9592856764793396
generator epoch 443 loss: 0.7464208993094308                 accuracy: 0.9492856860160828
generator epoch 444 loss: 0.743407517351423                 accuracy: 0.9385713934898376
generator epoch 445 loss: 0.7460687822614397                 accuracy: 0.9435713887214661
generator epoch 446 loss: 0.7426543714250837                 accuracy: 0.9464285373687744
generator epoch 447 loss: 0.7458564705984932                 accuracy: 0.9514285326004028
generator epoch 448 loss: 0.7472734793526786                 accuracy: 0.9407142996788025
generator epoch 449 loss: 0.7449050258091517                 accuracy: 0.9514285326004028
generator epoch 450 loss: 0.7408462546212332                 accuracy: 0.9557142853736877
generator epoch 451 loss: 0.743323040335519                 accuracy: 0.9585714340209961
generator epoch 452 loss: 0.7426845437186105                 accuracy: 0.941428542137146
generator epoch 453 loss: 0.7446207244873047                 accuracy: 0.9435713887214661
generator epoch 454 loss: 0.7418448996407645                 accuracy: 0.9614285826683044
generator epoch 455 loss: 0.7438548139299666                 accuracy: 0.9449999928474426
generator epoch 456 loss: 0.7480192539760044                 accuracy: 0.9464285373687744
generator epoch 457 loss: 0.7453430402483259                 accuracy: 0.9549999833106995
generator epoch 458 loss: 0.7403247876848493                 accuracy: 0.9278571605682373
generator epoch 459 loss: 0.7409559020996094                 accuracy: 0.9449999928474426
generator epoch 460 loss: 0.7387035452706473                 accuracy: 0.9535714387893677
generator epoch 461 loss: 0.7442142713274275                 accuracy: 0.9442856907844543
generator epoch 462 loss: 0.7420489855085101                 accuracy: 0.9485714435577393
generator epoch 463 loss: 0.745852443586077                 accuracy: 0.9492856860160828
generator epoch 464 loss: 0.744144442313058                 accuracy: 0.9542856812477112
generator epoch 465 loss: 0.7465246303013393                 accuracy: 0.9528571367263794
generator epoch 466 loss: 0.7468046800885881                 accuracy: 0.9514285326004028
generator epoch 467 loss: 0.7371818590436663                 accuracy: 0.9457142949104309
generator epoch 468 loss: 0.7459228999546595                 accuracy: 0.9464285373687744
generator epoch 469 loss: 0.7423127354213169                 accuracy: 0.9528571367263794
generator epoch 470 loss: 0.7413651620047433                 accuracy: 0.9485714435577393
generator epoch 471 loss: 0.7438453129359655                 accuracy: 0.9321428537368774
generator epoch 472 loss: 0.7428058266775949                 accuracy: 0.9471428394317627
generator epoch 473 loss: 0.7435985342843192                 accuracy: 0.9435713887214661
generator epoch 474 loss: 0.7441329463413784                 accuracy: 0.9599999785423279
generator epoch 475 loss: 0.7502227294921875                 accuracy: 0.9364285469055176
generator epoch 476 loss: 0.7403420436314174                 accuracy: 0.9228571057319641
generator epoch 477 loss: 0.7450829576764788                 accuracy: 0.9399999976158142
generator epoch 478 loss: 0.7442251774379185                 accuracy: 0.9485714435577393
generator epoch 479 loss: 0.741112529209682                 accuracy: 0.9571428298950195
generator epoch 480 loss: 0.7369181339808872                 accuracy: 0.9492856860160828
generator epoch 481 loss: 0.7408365862165178                 accuracy: 0.9507142901420593
generator epoch 482 loss: 0.7458901785714286                 accuracy: 0.941428542137146
generator epoch 483 loss: 0.740372121320452                 accuracy: 0.949999988079071
generator epoch 484 loss: 0.7428906555175782                 accuracy: 0.9300000071525574
generator epoch 485 loss: 0.7437447522844587                 accuracy: 0.9421428442001343
generator epoch 486 loss: 0.7385310224260603                 accuracy: 0.9549999833106995
generator epoch 487 loss: 0.7426042986188616                 accuracy: 0.941428542137146
generator epoch 488 loss: 0.7442448521205357                 accuracy: 0.9521428346633911
generator epoch 489 loss: 0.7411391723632812                 accuracy: 0.9285714030265808
generator epoch 490 loss: 0.7420258867536272                 accuracy: 0.9464285373687744
generator epoch 491 loss: 0.7436772848946708                 accuracy: 0.9521428346633911
generator epoch 492 loss: 0.7389749677385603                 accuracy: 0.9471428394317627
generator epoch 493 loss: 0.7347607622419084                 accuracy: 0.949999988079071
generator epoch 494 loss: 0.7429550724574497                 accuracy: 0.9485714435577393
generator epoch 495 loss: 0.7434017547607422                 accuracy: 0.9492856860160828
generator epoch 496 loss: 0.7389929970877511                 accuracy: 0.9307142496109009
generator epoch 497 loss: 0.7386954659598214                 accuracy: 0.9449999928474426
generator epoch 498 loss: 0.7448882014683315                 accuracy: 0.9592856764793396
generator epoch 499 loss: 0.7425950055803572                 accuracy: 0.9321428537368774
batch 0 train loss: [0.56189346]
batch 1 train loss: [0.4922831]
batch 2 train loss: [0.49795046]
batch 3 train loss: [0.5131907]
batch 4 train loss: [0.5069402]
batch 5 train loss: [0.54692185]
batch 6 train loss: [0.5338881]
batch 7 train loss: [0.47374547]
batch 8 train loss: [0.451787]
batch 9 train loss: [0.47976342]
batch 10 train loss: [0.5861252]
batch 11 train loss: [0.5680587]
batch 12 train loss: [0.6012929]
batch 13 train loss: [0.5626756]
batch 14 train loss: [0.5494008]
batch 15 train loss: [0.45588285]
batch 16 train loss: [0.46101916]
batch 17 train loss: [0.49859244]
batch 18 train loss: [0.43790096]
batch 19 train loss: [0.5137008]
batch 20 train loss: [0.57026356]
batch 21 train loss: [0.5205478]
batch 22 train loss: [0.43803176]
batch 23 train loss: [0.4824099]
batch 24 train loss: [0.45100525]
batch 25 train loss: [0.53520364]
batch 26 train loss: [0.40818295]
batch 27 train loss: [0.49444047]
batch 28 train loss: [0.49174908]
batch 29 train loss: [0.45682994]
batch 30 train loss: [0.55555904]
batch 31 train loss: [0.516391]
batch 32 train loss: [0.4889053]
batch 33 train loss: [0.54716796]
batch 34 train loss: [0.6028886]
batch 35 train loss: [0.5966043]
batch 36 train loss: [0.5450995]
batch 37 train loss: [0.50094193]
batch 38 train loss: [0.46178162]
batch 39 train loss: [0.48495203]
batch 40 train loss: [0.4638949]
batch 41 train loss: [0.44640833]
batch 42 train loss: [0.54033804]
batch 43 train loss: [0.45878115]
batch 44 train loss: [0.51144713]
batch 45 train loss: [0.48668462]
batch 46 train loss: [0.5627022]
batch 47 train loss: [0.45150274]
batch 48 train loss: [0.44593397]
batch 49 train loss: [0.48395258]
batch 50 train loss: [0.52964646]
batch 51 train loss: [0.40886864]
batch 52 train loss: [0.47612643]
batch 53 train loss: [0.54598117]
batch 54 train loss: [0.4417399]
batch 55 train loss: [0.5010042]
batch 56 train loss: [0.44982934]
batch 57 train loss: [0.4524285]
batch 58 train loss: [0.52729845]
batch 59 train loss: [0.58205026]
batch 60 train loss: [0.45698035]
batch 61 train loss: [0.48812255]
batch 62 train loss: [0.48848766]
batch 63 train loss: [0.47204974]
batch 64 train loss: [0.4822798]
batch 65 train loss: [0.5129833]
batch 66 train loss: [0.43517917]
batch 67 train loss: [0.5480888]
batch 68 train loss: [0.46795756]
batch 69 train loss: [0.5122286]
batch 70 train loss: [0.47717988]
batch 71 train loss: [0.42610365]
batch 72 train loss: [0.42078894]
batch 73 train loss: [0.4759904]
batch 74 train loss: [0.50040984]
batch 75 train loss: [0.50529957]
batch 76 train loss: [0.48694494]
batch 77 train loss: [0.5044899]
batch 78 train loss: [0.3797346]
batch 79 train loss: [0.59603894]
batch 80 train loss: [0.5269023]
batch 81 train loss: [0.46633625]
batch 82 train loss: [0.55094254]
batch 83 train loss: [0.4558013]
batch 84 train loss: [0.48098272]
batch 85 train loss: [0.51786065]
batch 86 train loss: [0.5027003]
batch 87 train loss: [0.5513656]
batch 88 train loss: [0.42537358]
batch 89 train loss: [0.43559232]
batch 90 train loss: [0.5242159]
batch 91 train loss: [0.42877972]
batch 92 train loss: [0.4972412]
batch 93 train loss: [0.47835344]
batch 94 train loss: [0.4275622]
batch 95 train loss: [0.46697077]
batch 96 train loss: [0.49114814]
batch 97 train loss: [0.3996449]
batch 98 train loss: [0.4732516]
batch 99 train loss: [0.47701937]
epoch 0 mean train loss: [0.4942398]
Epoch 0/400=>  train_loss: [0.4942398], iou: nan, cd: 2.341239330917777, test_mse: [0.42480573]
CORRECT PROGRAMS: 9794
batch 0 train loss: [0.3941434]
batch 1 train loss: [0.4753319]
batch 2 train loss: [0.47088605]
batch 3 train loss: [0.41879123]
batch 4 train loss: [0.39121217]
batch 5 train loss: [0.46942836]
batch 6 train loss: [0.4086468]
batch 7 train loss: [0.34238502]
batch 8 train loss: [0.4209603]
batch 9 train loss: [0.431688]
batch 10 train loss: [0.41504303]
batch 11 train loss: [0.41267952]
batch 12 train loss: [0.4064709]
batch 13 train loss: [0.46449172]
batch 14 train loss: [0.44443935]
batch 15 train loss: [0.42395565]
batch 16 train loss: [0.37430665]
batch 17 train loss: [0.31356978]
batch 18 train loss: [0.40573615]
batch 19 train loss: [0.39340088]
batch 20 train loss: [0.3839933]
batch 21 train loss: [0.45182642]
batch 22 train loss: [0.5404002]
batch 23 train loss: [0.4369409]
batch 24 train loss: [0.33471504]
batch 25 train loss: [0.38710007]
batch 26 train loss: [0.37133852]
batch 27 train loss: [0.38968343]
batch 28 train loss: [0.41407046]
batch 29 train loss: [0.47852674]
batch 30 train loss: [0.42255062]
batch 31 train loss: [0.4003473]
batch 32 train loss: [0.33837226]
batch 33 train loss: [0.39197534]
batch 34 train loss: [0.36997494]
batch 35 train loss: [0.4597848]
batch 36 train loss: [0.46130317]
batch 37 train loss: [0.39196923]
batch 38 train loss: [0.44117978]
batch 39 train loss: [0.5218234]
batch 40 train loss: [0.39303198]
batch 41 train loss: [0.36420932]
batch 42 train loss: [0.3688716]
batch 43 train loss: [0.42330018]
batch 44 train loss: [0.3705893]
batch 45 train loss: [0.4302382]
batch 46 train loss: [0.4497694]
batch 47 train loss: [0.47368053]
batch 48 train loss: [0.37486017]
batch 49 train loss: [0.47594336]
batch 50 train loss: [0.41181868]
batch 51 train loss: [0.43337405]
batch 52 train loss: [0.35695365]
batch 53 train loss: [0.52476984]
batch 54 train loss: [0.43395573]
batch 55 train loss: [0.4268047]
batch 56 train loss: [0.5066003]
batch 57 train loss: [0.40644255]
batch 58 train loss: [0.36133483]
batch 59 train loss: [0.41946894]
batch 60 train loss: [0.37754574]
batch 61 train loss: [0.45425048]
batch 62 train loss: [0.3765371]
batch 63 train loss: [0.3433978]
batch 64 train loss: [0.35970035]
batch 65 train loss: [0.35640523]
batch 66 train loss: [0.39094576]
batch 67 train loss: [0.40257874]
batch 68 train loss: [0.43140244]
batch 69 train loss: [0.42747638]
batch 70 train loss: [0.48816377]
batch 71 train loss: [0.44957227]
batch 72 train loss: [0.38958538]
batch 73 train loss: [0.32201353]
batch 74 train loss: [0.42893755]
batch 75 train loss: [0.38406876]
batch 76 train loss: [0.4088236]
batch 77 train loss: [0.41426513]
batch 78 train loss: [0.44749054]
batch 79 train loss: [0.44385654]
batch 80 train loss: [0.3613988]
batch 81 train loss: [0.4291278]
batch 82 train loss: [0.39199427]
batch 83 train loss: [0.47294098]
batch 84 train loss: [0.35744393]
batch 85 train loss: [0.392885]
batch 86 train loss: [0.41624096]
batch 87 train loss: [0.35679385]
batch 88 train loss: [0.3652421]
batch 89 train loss: [0.4959093]
batch 90 train loss: [0.34002286]
batch 91 train loss: [0.4457129]
batch 92 train loss: [0.39299804]
batch 93 train loss: [0.43607503]
batch 94 train loss: [0.38102695]
batch 95 train loss: [0.39960048]
batch 96 train loss: [0.3240401]
batch 97 train loss: [0.38576248]
batch 98 train loss: [0.4189204]
batch 99 train loss: [0.34600466]
epoch 1 mean train loss: [0.4107862]
Epoch 1/400=>  train_loss: [0.4107862], iou: nan, cd: 2.3470948416120305, test_mse: [0.41392273]
CORRECT PROGRAMS: 9794
batch 0 train loss: [0.34958288]
batch 1 train loss: [0.36920136]
batch 2 train loss: [0.30395475]
batch 3 train loss: [0.3471249]
batch 4 train loss: [0.32883674]
batch 5 train loss: [0.3217532]
batch 6 train loss: [0.33276707]
batch 7 train loss: [0.38174802]
batch 8 train loss: [0.45009643]
batch 9 train loss: [0.384421]
batch 10 train loss: [0.40492406]
batch 11 train loss: [0.37008542]
batch 12 train loss: [0.32747102]
batch 13 train loss: [0.43048272]
batch 14 train loss: [0.40144747]
batch 15 train loss: [0.42218855]
batch 16 train loss: [0.34283102]
batch 17 train loss: [0.36457226]
batch 18 train loss: [0.40162688]
batch 19 train loss: [0.38726962]
batch 20 train loss: [0.394837]
batch 21 train loss: [0.3160836]
batch 22 train loss: [0.37709585]
batch 23 train loss: [0.34987572]
batch 24 train loss: [0.31980997]
batch 25 train loss: [0.3807543]
batch 26 train loss: [0.35243163]
batch 27 train loss: [0.400674]
batch 28 train loss: [0.37576392]
batch 29 train loss: [0.30348814]
batch 30 train loss: [0.513803]
batch 31 train loss: [0.4093922]
batch 32 train loss: [0.3682884]
batch 33 train loss: [0.34513745]
batch 34 train loss: [0.43603954]
batch 35 train loss: [0.35470596]
batch 36 train loss: [0.30092683]
batch 37 train loss: [0.280189]
batch 38 train loss: [0.43002433]
batch 39 train loss: [0.3602537]
batch 40 train loss: [0.35571063]
batch 41 train loss: [0.32092556]
batch 42 train loss: [0.30389282]
batch 43 train loss: [0.35832757]
batch 44 train loss: [0.39041004]
batch 45 train loss: [0.40928462]
batch 46 train loss: [0.4316996]
batch 47 train loss: [0.3743722]
batch 48 train loss: [0.3828878]
batch 49 train loss: [0.40977782]
batch 50 train loss: [0.37063497]
batch 51 train loss: [0.34496385]
batch 52 train loss: [0.30668974]
batch 53 train loss: [0.34147942]
batch 54 train loss: [0.39156106]
batch 55 train loss: [0.394012]
batch 56 train loss: [0.38040155]
batch 57 train loss: [0.36007684]
batch 58 train loss: [0.36804613]
batch 59 train loss: [0.46471944]
batch 60 train loss: [0.36643067]
batch 61 train loss: [0.34267244]
batch 62 train loss: [0.3256505]
batch 63 train loss: [0.4324594]
batch 64 train loss: [0.34418467]
batch 65 train loss: [0.36727086]
batch 66 train loss: [0.38177907]
batch 67 train loss: [0.3395174]
batch 68 train loss: [0.26957726]
batch 69 train loss: [0.40774363]
batch 70 train loss: [0.49781942]
batch 71 train loss: [0.32937258]
batch 72 train loss: [0.3595487]
batch 73 train loss: [0.32633513]
batch 74 train loss: [0.3815684]
batch 75 train loss: [0.37779015]
batch 76 train loss: [0.340365]
batch 77 train loss: [0.32080516]
batch 78 train loss: [0.27040526]
batch 79 train loss: [0.39825994]
batch 80 train loss: [0.40665582]
batch 81 train loss: [0.390386]
batch 82 train loss: [0.27688628]
batch 83 train loss: [0.43622613]
batch 84 train loss: [0.32777795]
batch 85 train loss: [0.37486392]
batch 86 train loss: [0.34503648]
batch 87 train loss: [0.32145151]
batch 88 train loss: [0.38329208]
batch 89 train loss: [0.34625575]
batch 90 train loss: [0.34524533]
batch 91 train loss: [0.3706669]
batch 92 train loss: [0.394726]
batch 93 train loss: [0.35783714]
batch 94 train loss: [0.4963329]
batch 95 train loss: [0.33854035]
batch 96 train loss: [0.43194178]
batch 97 train loss: [0.2997474]
batch 98 train loss: [0.36735862]
batch 99 train loss: [0.40071452]
epoch 2 mean train loss: [0.36843333]
Epoch 2/400=>  train_loss: [0.36843333], iou: nan, cd: 2.1993564104287997, test_mse: [0.39497462]
CORRECT PROGRAMS: 9794
batch 0 train loss: [0.27586514]
batch 1 train loss: [0.32116067]
batch 2 train loss: [0.32290253]
batch 3 train loss: [0.3164753]
batch 4 train loss: [0.34924802]
batch 5 train loss: [0.38929313]
batch 6 train loss: [0.37122613]
batch 7 train loss: [0.37936538]
batch 8 train loss: [0.35384494]
batch 9 train loss: [0.30706698]
batch 10 train loss: [0.30998182]
batch 11 train loss: [0.25160637]
batch 12 train loss: [0.36811453]
batch 13 train loss: [0.31620818]
batch 14 train loss: [0.37767586]
batch 15 train loss: [0.28202075]
batch 16 train loss: [0.38710305]
batch 17 train loss: [0.34274986]
batch 18 train loss: [0.35157707]
batch 19 train loss: [0.34980968]
batch 20 train loss: [0.27276748]
batch 21 train loss: [0.39536265]
batch 22 train loss: [0.33282107]
batch 23 train loss: [0.26865783]
batch 24 train loss: [0.3222691]
batch 25 train loss: [0.4058818]
batch 26 train loss: [0.31121764]
batch 27 train loss: [0.29483625]
batch 28 train loss: [0.30926222]
batch 29 train loss: [0.36466724]
batch 30 train loss: [0.33943298]
batch 31 train loss: [0.34911093]
batch 32 train loss: [0.30622876]
batch 33 train loss: [0.29249614]
batch 34 train loss: [0.37674913]
batch 35 train loss: [0.317409]
batch 36 train loss: [0.29289955]
batch 37 train loss: [0.3113327]
batch 38 train loss: [0.34417537]
batch 39 train loss: [0.2980823]
batch 40 train loss: [0.3619769]
batch 41 train loss: [0.38810176]
batch 42 train loss: [0.39841783]
batch 43 train loss: [0.37479112]
batch 44 train loss: [0.3619998]
batch 45 train loss: [0.3929502]
batch 46 train loss: [0.38406602]
batch 47 train loss: [0.37905616]
batch 48 train loss: [0.33201706]
batch 49 train loss: [0.30765414]
batch 50 train loss: [0.31939927]
batch 51 train loss: [0.35633144]
batch 52 train loss: [0.361955]
batch 53 train loss: [0.31405938]
batch 54 train loss: [0.33030912]
batch 55 train loss: [0.34367603]
batch 56 train loss: [0.30682883]
batch 57 train loss: [0.3409446]
batch 58 train loss: [0.3188588]
batch 59 train loss: [0.32082307]
batch 60 train loss: [0.35802996]
batch 61 train loss: [0.36877587]
batch 62 train loss: [0.34209415]
batch 63 train loss: [0.35874212]
batch 64 train loss: [0.36807072]
batch 65 train loss: [0.3521134]
batch 66 train loss: [0.29531947]
batch 67 train loss: [0.3403331]
batch 68 train loss: [0.30798998]
batch 69 train loss: [0.3845903]
batch 70 train loss: [0.32345873]
batch 71 train loss: [0.33848354]
batch 72 train loss: [0.39434913]
batch 73 train loss: [0.33055815]
batch 74 train loss: [0.43592072]
batch 75 train loss: [0.37290064]
batch 76 train loss: [0.3348902]
batch 77 train loss: [0.4001828]
batch 78 train loss: [0.4110357]
batch 79 train loss: [0.35204664]
batch 80 train loss: [0.34149176]
batch 81 train loss: [0.33686408]
batch 82 train loss: [0.36515942]
batch 83 train loss: [0.3210106]
batch 84 train loss: [0.3139467]
batch 85 train loss: [0.35699242]
batch 86 train loss: [0.30985242]
batch 87 train loss: [0.25400186]
batch 88 train loss: [0.33075103]
batch 89 train loss: [0.31237426]
batch 90 train loss: [0.2767409]
batch 91 train loss: [0.41078028]
batch 92 train loss: [0.3688434]
batch 93 train loss: [0.3180012]
batch 94 train loss: [0.30787772]
batch 95 train loss: [0.31264636]
batch 96 train loss: [0.3744304]
batch 97 train loss: [0.3789596]
batch 98 train loss: [0.38227275]
batch 99 train loss: [0.253936]
epoch 3 mean train loss: [0.34019992]
Epoch 3/400=>  train_loss: [0.34019992], iou: nan, cd: 2.1396771099721863, test_mse: [0.37468332]
CORRECT PROGRAMS: 9794
batch 0 train loss: [0.30971396]
batch 1 train loss: [0.29065442]
batch 2 train loss: [0.28931582]
batch 3 train loss: [0.26585647]
batch 4 train loss: [0.24490266]
batch 5 train loss: [0.3265657]
batch 6 train loss: [0.33066404]
batch 7 train loss: [0.28426418]
batch 8 train loss: [0.3358579]
batch 9 train loss: [0.28320688]
batch 10 train loss: [0.26370305]
batch 11 train loss: [0.29326683]
batch 12 train loss: [0.32046548]
batch 13 train loss: [0.33008015]
batch 14 train loss: [0.28472346]
batch 15 train loss: [0.36882654]
batch 16 train loss: [0.26879436]
batch 17 train loss: [0.28530797]
batch 18 train loss: [0.33414286]
batch 19 train loss: [0.31641257]
batch 20 train loss: [0.29236954]
batch 21 train loss: [0.3294805]
batch 22 train loss: [0.36403295]
batch 23 train loss: [0.2851711]
batch 24 train loss: [0.24596365]
batch 25 train loss: [0.41971627]
batch 26 train loss: [0.33140025]
batch 27 train loss: [0.3270952]
batch 28 train loss: [0.2808717]
batch 29 train loss: [0.34171516]
batch 30 train loss: [0.31701604]
batch 31 train loss: [0.27888566]
batch 32 train loss: [0.3420932]
batch 33 train loss: [0.26649708]
batch 34 train loss: [0.29679418]
batch 35 train loss: [0.32108223]
batch 36 train loss: [0.29221827]
batch 37 train loss: [0.27222955]
batch 38 train loss: [0.31348118]
batch 39 train loss: [0.2611127]
batch 40 train loss: [0.28700203]
batch 41 train loss: [0.31765413]
batch 42 train loss: [0.38715065]
batch 43 train loss: [0.3048722]
batch 44 train loss: [0.30255666]
batch 45 train loss: [0.33239353]
batch 46 train loss: [0.33423173]
batch 47 train loss: [0.3579802]
batch 48 train loss: [0.299204]
batch 49 train loss: [0.36784878]
batch 50 train loss: [0.36559162]
batch 51 train loss: [0.3185026]
batch 52 train loss: [0.32656392]
batch 53 train loss: [0.31235284]
batch 54 train loss: [0.35192344]
batch 55 train loss: [0.29243413]
batch 56 train loss: [0.2614667]
batch 57 train loss: [0.29236883]
batch 58 train loss: [0.31614074]
batch 59 train loss: [0.28425306]
batch 60 train loss: [0.29683954]
batch 61 train loss: [0.34539384]
batch 62 train loss: [0.34086144]
batch 63 train loss: [0.36270392]
batch 64 train loss: [0.3481685]
batch 65 train loss: [0.30606252]
batch 66 train loss: [0.27188244]
batch 67 train loss: [0.3109218]
batch 68 train loss: [0.31212503]
batch 69 train loss: [0.2723102]
batch 70 train loss: [0.28824767]
batch 71 train loss: [0.3758015]
batch 72 train loss: [0.3274362]
batch 73 train loss: [0.33255458]
batch 74 train loss: [0.38443643]
batch 75 train loss: [0.3278687]
batch 76 train loss: [0.39579144]
batch 77 train loss: [0.26494968]
batch 78 train loss: [0.27646324]
batch 79 train loss: [0.36205396]
batch 80 train loss: [0.28405112]
batch 81 train loss: [0.27530345]
batch 82 train loss: [0.339826]
batch 83 train loss: [0.27859524]
batch 84 train loss: [0.30524194]
batch 85 train loss: [0.3035194]
batch 86 train loss: [0.33019507]
batch 87 train loss: [0.33150655]
batch 88 train loss: [0.317988]
batch 89 train loss: [0.2937183]
batch 90 train loss: [0.27804744]
batch 91 train loss: [0.3484055]
batch 92 train loss: [0.31224835]
batch 93 train loss: [0.32587233]
batch 94 train loss: [0.26867148]
batch 95 train loss: [0.30559823]
batch 96 train loss: [0.37875983]
batch 97 train loss: [0.34228548]
batch 98 train loss: [0.31975093]
batch 99 train loss: [0.32818776]
epoch 4 mean train loss: [0.31389087]
Epoch 4/400=>  train_loss: [0.31389087], iou: nan, cd: 2.1868427990199955, test_mse: [0.37290528]
CORRECT PROGRAMS: 9794
batch 0 train loss: [0.2782901]
batch 1 train loss: [0.35073897]
batch 2 train loss: [0.35176757]
batch 3 train loss: [0.2716821]
batch 4 train loss: [0.33984944]
batch 5 train loss: [0.36763102]
batch 6 train loss: [0.24190244]
batch 7 train loss: [0.2504961]
batch 8 train loss: [0.2730248]
batch 9 train loss: [0.32092166]
batch 10 train loss: [0.27670807]
batch 11 train loss: [0.30238792]
batch 12 train loss: [0.2659803]
batch 13 train loss: [0.28100345]
batch 14 train loss: [0.27788317]
batch 15 train loss: [0.263688]
batch 16 train loss: [0.2653951]
batch 17 train loss: [0.27061743]
batch 18 train loss: [0.35788143]
batch 19 train loss: [0.29125467]
batch 20 train loss: [0.30031285]
batch 21 train loss: [0.2769765]
batch 22 train loss: [0.24549428]
batch 23 train loss: [0.35078904]
batch 24 train loss: [0.314684]
batch 25 train loss: [0.25450468]
batch 26 train loss: [0.310692]
batch 27 train loss: [0.28301924]
batch 28 train loss: [0.29307666]
batch 29 train loss: [0.2817907]
batch 30 train loss: [0.2662333]
batch 31 train loss: [0.3005144]
batch 32 train loss: [0.2532714]
batch 33 train loss: [0.25903]
batch 34 train loss: [0.2755921]
batch 35 train loss: [0.2602701]
batch 36 train loss: [0.31492323]
batch 37 train loss: [0.3240174]
batch 38 train loss: [0.27117664]
batch 39 train loss: [0.31952378]
batch 40 train loss: [0.33164415]
batch 41 train loss: [0.24200357]
batch 42 train loss: [0.252194]
batch 43 train loss: [0.28048226]
batch 44 train loss: [0.2884773]
batch 45 train loss: [0.4146174]
batch 46 train loss: [0.34083876]
batch 47 train loss: [0.27736044]
batch 48 train loss: [0.2529622]
batch 49 train loss: [0.29310772]
batch 50 train loss: [0.2564615]
batch 51 train loss: [0.24458142]
batch 52 train loss: [0.29867464]
batch 53 train loss: [0.29322708]
batch 54 train loss: [0.30953524]
batch 55 train loss: [0.37151712]
batch 56 train loss: [0.28631067]
batch 57 train loss: [0.2894331]
batch 58 train loss: [0.26906407]
batch 59 train loss: [0.2455602]
batch 60 train loss: [0.3818309]
batch 61 train loss: [0.3175176]
batch 62 train loss: [0.31274977]
batch 63 train loss: [0.27464345]
batch 64 train loss: [0.33317348]
batch 65 train loss: [0.31511107]
batch 66 train loss: [0.27836376]
batch 67 train loss: [0.36611563]
batch 68 train loss: [0.29140002]
batch 69 train loss: [0.298655]
batch 70 train loss: [0.31550133]
batch 71 train loss: [0.4189874]
batch 72 train loss: [0.31190312]
batch 73 train loss: [0.26860797]
batch 74 train loss: [0.29974362]
batch 75 train loss: [0.27601355]
batch 76 train loss: [0.290768]
batch 77 train loss: [0.25801206]
batch 78 train loss: [0.23521425]
batch 79 train loss: [0.30145597]
batch 80 train loss: [0.30426717]
batch 81 train loss: [0.3040485]
batch 82 train loss: [0.22662275]
batch 83 train loss: [0.2550442]
batch 84 train loss: [0.34264436]
batch 85 train loss: [0.2829583]
batch 86 train loss: [0.33953562]
batch 87 train loss: [0.31691468]
batch 88 train loss: [0.36384934]
batch 89 train loss: [0.30215618]
batch 90 train loss: [0.26660442]
batch 91 train loss: [0.36032447]
batch 92 train loss: [0.21853554]
batch 93 train loss: [0.29348594]
batch 94 train loss: [0.3361438]
batch 95 train loss: [0.3343672]
batch 96 train loss: [0.38203794]
batch 97 train loss: [0.26880917]
batch 98 train loss: [0.2769905]
batch 99 train loss: [0.32683307]
epoch 5 mean train loss: [0.29740995]
Epoch 5/400=>  train_loss: [0.29740995], iou: nan, cd: 2.141683461173579, test_mse: [0.37819314]
CORRECT PROGRAMS: 9794
batch 0 train loss: [0.34576622]
batch 1 train loss: [0.22764629]
batch 2 train loss: [0.30220497]
batch 3 train loss: [0.26382315]
batch 4 train loss: [0.20463356]
batch 5 train loss: [0.34632787]
batch 6 train loss: [0.25490463]
batch 7 train loss: [0.29991856]
batch 8 train loss: [0.2875449]
batch 9 train loss: [0.20976847]
batch 10 train loss: [0.3054215]
batch 11 train loss: [0.24891272]
batch 12 train loss: [0.32229614]
batch 13 train loss: [0.20069571]
batch 14 train loss: [0.26812297]
batch 15 train loss: [0.26552582]
batch 16 train loss: [0.29057398]
batch 17 train loss: [0.2970325]
batch 18 train loss: [0.23884948]
batch 19 train loss: [0.28166196]
batch 20 train loss: [0.26621616]
batch 21 train loss: [0.25327644]
batch 22 train loss: [0.32165262]
batch 23 train loss: [0.28265685]
batch 24 train loss: [0.27528983]
batch 25 train loss: [0.199473]
batch 26 train loss: [0.32878405]
batch 27 train loss: [0.2437557]
batch 28 train loss: [0.20162597]
batch 29 train loss: [0.2644256]
batch 30 train loss: [0.25363776]
batch 31 train loss: [0.29875103]
batch 32 train loss: [0.29194373]
batch 33 train loss: [0.25654358]
batch 34 train loss: [0.29931638]
batch 35 train loss: [0.28735244]
batch 36 train loss: [0.2671921]
batch 37 train loss: [0.3360947]
batch 38 train loss: [0.27075392]
batch 39 train loss: [0.30712733]
batch 40 train loss: [0.2809129]
batch 41 train loss: [0.26927638]
batch 42 train loss: [0.32351765]
batch 43 train loss: [0.2701759]
batch 44 train loss: [0.28849488]
batch 45 train loss: [0.21103679]
batch 46 train loss: [0.22204532]
batch 47 train loss: [0.24215269]
batch 48 train loss: [0.31008208]
batch 49 train loss: [0.29819566]
batch 50 train loss: [0.2732962]
batch 51 train loss: [0.3028615]
batch 52 train loss: [0.29102537]
batch 53 train loss: [0.3052352]
batch 54 train loss: [0.30946204]
batch 55 train loss: [0.30795616]
batch 56 train loss: [0.32266688]
batch 57 train loss: [0.2576632]
batch 58 train loss: [0.3354552]
batch 59 train loss: [0.2903969]
batch 60 train loss: [0.2788536]
batch 61 train loss: [0.20136322]
batch 62 train loss: [0.29541555]
batch 63 train loss: [0.23991579]
batch 64 train loss: [0.28073683]
batch 65 train loss: [0.31113166]
batch 66 train loss: [0.32308808]
batch 67 train loss: [0.29606056]
batch 68 train loss: [0.3196386]
batch 69 train loss: [0.2770364]
batch 70 train loss: [0.29868993]
batch 71 train loss: [0.24696489]
batch 72 train loss: [0.326317]
batch 73 train loss: [0.28768983]
batch 74 train loss: [0.298632]
batch 75 train loss: [0.3083972]
batch 76 train loss: [0.27590913]
batch 77 train loss: [0.31285825]
batch 78 train loss: [0.27047017]
batch 79 train loss: [0.2320375]
batch 80 train loss: [0.29178607]
batch 81 train loss: [0.32183546]
batch 82 train loss: [0.32725224]
batch 83 train loss: [0.26155543]
batch 84 train loss: [0.23467125]
batch 85 train loss: [0.21302423]
batch 86 train loss: [0.3681979]
batch 87 train loss: [0.36014435]
batch 88 train loss: [0.20901449]
batch 89 train loss: [0.26028967]
batch 90 train loss: [0.2621366]
batch 91 train loss: [0.24679801]
batch 92 train loss: [0.26462817]
batch 93 train loss: [0.3264863]
batch 94 train loss: [0.31597292]
batch 95 train loss: [0.34864697]
batch 96 train loss: [0.26971322]
batch 97 train loss: [0.31447855]
batch 98 train loss: [0.28288224]
batch 99 train loss: [0.23685867]
epoch 6 mean train loss: [0.28076982]
Epoch 6/400=>  train_loss: [0.28076982], iou: nan, cd: 2.153530910547056, test_mse: [0.37240896]
CORRECT PROGRAMS: 9794
batch 0 train loss: [0.24820484]
batch 1 train loss: [0.26118112]
batch 2 train loss: [0.33293542]
batch 3 train loss: [0.27068317]
batch 4 train loss: [0.25511503]
batch 5 train loss: [0.26890078]
batch 6 train loss: [0.24290773]
batch 7 train loss: [0.2758175]
batch 8 train loss: [0.21430613]
batch 9 train loss: [0.30709633]
batch 10 train loss: [0.2924111]
batch 11 train loss: [0.25601852]
batch 12 train loss: [0.27539372]
batch 13 train loss: [0.23555104]
batch 14 train loss: [0.23770219]
batch 15 train loss: [0.27355975]
batch 16 train loss: [0.3227478]
batch 17 train loss: [0.3294891]
batch 18 train loss: [0.2674213]
batch 19 train loss: [0.34773007]
batch 20 train loss: [0.2573428]
batch 21 train loss: [0.27221215]
batch 22 train loss: [0.2831427]
batch 23 train loss: [0.27419752]
batch 24 train loss: [0.22961514]
batch 25 train loss: [0.2804451]
batch 26 train loss: [0.27357838]
batch 27 train loss: [0.2636588]
batch 28 train loss: [0.2445534]
batch 29 train loss: [0.28611088]
batch 30 train loss: [0.22912125]
batch 31 train loss: [0.20991655]
batch 32 train loss: [0.24792308]
batch 33 train loss: [0.25674102]
batch 34 train loss: [0.30363274]
batch 35 train loss: [0.26362166]
batch 36 train loss: [0.22332557]
batch 37 train loss: [0.27856463]
batch 38 train loss: [0.22016335]
batch 39 train loss: [0.2917823]
batch 40 train loss: [0.29236457]
batch 41 train loss: [0.28997988]
batch 42 train loss: [0.3110482]
batch 43 train loss: [0.29228258]
batch 44 train loss: [0.24554098]
batch 45 train loss: [0.19811267]
batch 46 train loss: [0.32437003]
batch 47 train loss: [0.28920245]
batch 48 train loss: [0.29839936]
batch 49 train loss: [0.23489806]
batch 50 train loss: [0.26807433]
batch 51 train loss: [0.24037927]
batch 52 train loss: [0.25208014]
batch 53 train loss: [0.3330666]
batch 54 train loss: [0.29344937]
batch 55 train loss: [0.24630816]
batch 56 train loss: [0.23515663]
batch 57 train loss: [0.2735401]
batch 58 train loss: [0.28936037]
batch 59 train loss: [0.24760024]
batch 60 train loss: [0.2630416]
batch 61 train loss: [0.25620627]
batch 62 train loss: [0.22582677]
batch 63 train loss: [0.23938422]
batch 64 train loss: [0.31417462]
batch 65 train loss: [0.24534029]
batch 66 train loss: [0.23332055]
batch 67 train loss: [0.3049025]
batch 68 train loss: [0.27397877]
batch 69 train loss: [0.24668631]
batch 70 train loss: [0.34678832]
batch 71 train loss: [0.2905297]
batch 72 train loss: [0.31868368]
batch 73 train loss: [0.33841503]
batch 74 train loss: [0.25921488]
batch 75 train loss: [0.2781725]
batch 76 train loss: [0.27699554]
batch 77 train loss: [0.27637872]
batch 78 train loss: [0.2975007]
batch 79 train loss: [0.24479261]
batch 80 train loss: [0.2644131]
batch 81 train loss: [0.26335186]
batch 82 train loss: [0.25205296]
batch 83 train loss: [0.23476104]
batch 84 train loss: [0.2532751]
batch 85 train loss: [0.30408087]
batch 86 train loss: [0.23981413]
batch 87 train loss: [0.24027924]
batch 88 train loss: [0.2970454]
batch 89 train loss: [0.2574752]
batch 90 train loss: [0.21583506]
batch 91 train loss: [0.27518067]
batch 92 train loss: [0.24673761]
batch 93 train loss: [0.28082293]
batch 94 train loss: [0.2547201]
batch 95 train loss: [0.34087363]
batch 96 train loss: [0.26191205]
batch 97 train loss: [0.2778748]
batch 98 train loss: [0.23808841]
batch 99 train loss: [0.27763984]
epoch 7 mean train loss: [0.269666]
Epoch 7/400=>  train_loss: [0.269666], iou: nan, cd: 2.1451993935335167, test_mse: [0.3778016]
CORRECT PROGRAMS: 9794
batch 0 train loss: [0.25787386]
batch 1 train loss: [0.26043883]
batch 2 train loss: [0.24686614]
batch 3 train loss: [0.26412934]
batch 4 train loss: [0.26381305]
batch 5 train loss: [0.2070468]
batch 6 train loss: [0.25213212]
batch 7 train loss: [0.20599057]
batch 8 train loss: [0.17338307]
batch 9 train loss: [0.24788785]
batch 10 train loss: [0.27376163]
batch 11 train loss: [0.26580974]
batch 12 train loss: [0.24486859]
batch 13 train loss: [0.2601156]
batch 14 train loss: [0.27617985]
batch 15 train loss: [0.2538221]
batch 16 train loss: [0.24681783]
batch 17 train loss: [0.2076553]
batch 18 train loss: [0.28244597]
batch 19 train loss: [0.22525021]
batch 20 train loss: [0.19856323]
batch 21 train loss: [0.2636128]
batch 22 train loss: [0.25778636]
batch 23 train loss: [0.31614572]
batch 24 train loss: [0.34173095]
batch 25 train loss: [0.28869614]
batch 26 train loss: [0.22054674]
batch 27 train loss: [0.28920147]
batch 28 train loss: [0.2579706]
batch 29 train loss: [0.21559767]
batch 30 train loss: [0.24569544]
batch 31 train loss: [0.25087345]
batch 32 train loss: [0.22098258]
batch 33 train loss: [0.29477534]
batch 34 train loss: [0.24089447]
batch 35 train loss: [0.22717077]
batch 36 train loss: [0.252938]
batch 37 train loss: [0.20631224]
batch 38 train loss: [0.25998706]
batch 39 train loss: [0.26453334]
batch 40 train loss: [0.26953968]
batch 41 train loss: [0.37201104]
batch 42 train loss: [0.22228438]
batch 43 train loss: [0.3077446]
batch 44 train loss: [0.23473255]
batch 45 train loss: [0.17096557]
batch 46 train loss: [0.2768798]
batch 47 train loss: [0.25674176]
batch 48 train loss: [0.25767088]
batch 49 train loss: [0.29730782]
batch 50 train loss: [0.31972238]
batch 51 train loss: [0.23669498]
batch 52 train loss: [0.26777083]
batch 53 train loss: [0.26330185]
batch 54 train loss: [0.23829311]
batch 55 train loss: [0.25937438]
batch 56 train loss: [0.27400815]
batch 57 train loss: [0.25512514]
batch 58 train loss: [0.19711022]
batch 59 train loss: [0.25414458]
batch 60 train loss: [0.28212827]
batch 61 train loss: [0.22046876]
batch 62 train loss: [0.22454396]
batch 63 train loss: [0.2890355]
batch 64 train loss: [0.26598024]
batch 65 train loss: [0.3390101]
batch 66 train loss: [0.25002223]
batch 67 train loss: [0.32203496]
batch 68 train loss: [0.2549361]
batch 69 train loss: [0.29291916]
batch 70 train loss: [0.27339527]
batch 71 train loss: [0.32677516]
batch 72 train loss: [0.29936117]
batch 73 train loss: [0.26682812]
batch 74 train loss: [0.19158992]
batch 75 train loss: [0.2666186]
batch 76 train loss: [0.24054922]
batch 77 train loss: [0.22649962]
batch 78 train loss: [0.29134583]
batch 79 train loss: [0.20961691]
batch 80 train loss: [0.24912947]
batch 81 train loss: [0.24369219]
batch 82 train loss: [0.32262582]
batch 83 train loss: [0.28710002]
batch 84 train loss: [0.2042193]
batch 85 train loss: [0.22771189]
batch 86 train loss: [0.2433531]
batch 87 train loss: [0.31512412]
batch 88 train loss: [0.26716343]
batch 89 train loss: [0.28254318]
batch 90 train loss: [0.28337038]
batch 91 train loss: [0.3223291]
batch 92 train loss: [0.30690908]
batch 93 train loss: [0.27101055]
batch 94 train loss: [0.25490874]
batch 95 train loss: [0.27036297]
batch 96 train loss: [0.27983174]
batch 97 train loss: [0.20044872]
batch 98 train loss: [0.23706034]
batch 99 train loss: [0.2482599]
epoch 8 mean train loss: [0.2591254]
WAKE SLEEP ITERATION 5
Inferring cad batch: 0
Inferring cad batch: 1
Inferring cad batch: 2
Inferring cad batch: 3
Inferring cad batch: 4
Inferring cad batch: 5
Inferring cad batch: 6
Inferring cad batch: 7
Inferring cad batch: 8
Inferring cad batch: 9
Inferring cad batch: 10
Inferring cad batch: 11
Inferring cad batch: 12
Inferring cad batch: 13
Inferring cad batch: 14
Inferring cad batch: 15
Inferring cad batch: 16
Inferring cad batch: 17
Inferring cad batch: 18
Inferring cad batch: 19
Inferring cad batch: 20
Inferring cad batch: 21
Inferring cad batch: 22
Inferring cad batch: 23
Inferring cad batch: 24
Inferring cad batch: 25
Inferring cad batch: 26
Inferring cad batch: 27
Inferring cad batch: 28
Inferring cad batch: 29
Inferring cad batch: 30
Inferring cad batch: 31
Inferring cad batch: 32
Inferring cad average chamfer distance: 1.4201575241423634
0.5922859419349817 1.4201575241423634
generator epoch 0 loss: 1.1225169093540737                 accuracy: 0.8878571391105652
generator epoch 1 loss: 1.0285170331682478                 accuracy: 0.8935714364051819
generator epoch 2 loss: 0.993019669015067                 accuracy: 0.9214285612106323
generator epoch 3 loss: 0.9752424734933036                 accuracy: 0.8721428513526917
generator epoch 4 loss: 0.9604293875558035                 accuracy: 0.8792856931686401
generator epoch 5 loss: 0.9455722830636161                 accuracy: 0.8935714364051819
generator epoch 6 loss: 0.9306678423200335                 accuracy: 0.895714282989502
generator epoch 7 loss: 0.9231691336495536                 accuracy: 0.904285728931427
generator epoch 8 loss: 0.9142881504603795                 accuracy: 0.9149999618530273
generator epoch 9 loss: 0.9109304164341517                 accuracy: 0.9214285612106323
generator epoch 10 loss: 0.8933920096261161                 accuracy: 0.8942856788635254
generator epoch 11 loss: 0.8974212079729352                 accuracy: 0.8985714316368103
generator epoch 12 loss: 0.8864173697335379                 accuracy: 0.9157142639160156
generator epoch 13 loss: 0.8832325081961495                 accuracy: 0.8999999761581421
generator epoch 14 loss: 0.8811826119559152                 accuracy: 0.904285728931427
generator epoch 15 loss: 0.8809456002371652                 accuracy: 0.9128571152687073
generator epoch 16 loss: 0.8802118198939732                 accuracy: 0.8942856788635254
generator epoch 17 loss: 0.8712435956682477                 accuracy: 0.9099999666213989
generator epoch 18 loss: 0.8730463448660715                 accuracy: 0.9071428179740906
generator epoch 19 loss: 0.866166592843192                 accuracy: 0.9057142734527588
generator epoch 20 loss: 0.8622800022670201                 accuracy: 0.9057142734527588
generator epoch 21 loss: 0.8593556509835379                 accuracy: 0.9149999618530273
generator epoch 22 loss: 0.8572610055106027                 accuracy: 0.9128571152687073
generator epoch 23 loss: 0.8592709551130022                 accuracy: 0.9278571605682373
generator epoch 24 loss: 0.8539823416573661                 accuracy: 0.9078571200370789
generator epoch 25 loss: 0.8526899893624442                 accuracy: 0.9149999618530273
generator epoch 26 loss: 0.8513315325055804                 accuracy: 0.9221428632736206
generator epoch 27 loss: 0.8494664114815849                 accuracy: 0.9114285707473755
generator epoch 28 loss: 0.8508485499790737                 accuracy: 0.9035714268684387
generator epoch 29 loss: 0.8482460239955357                 accuracy: 0.9099999666213989
generator epoch 30 loss: 0.8516168701171875                 accuracy: 0.9099999666213989
generator epoch 31 loss: 0.8452416695731026                 accuracy: 0.9128571152687073
generator epoch 32 loss: 0.8471893075125558                 accuracy: 0.918571412563324
generator epoch 33 loss: 0.8398573250906808                 accuracy: 0.9049999713897705
generator epoch 34 loss: 0.8428115426199777                 accuracy: 0.9007142782211304
generator epoch 35 loss: 0.8406198311941965                 accuracy: 0.9192857146263123
generator epoch 36 loss: 0.8376688058035714                 accuracy: 0.9114285707473755
generator epoch 37 loss: 0.8319551077706473                 accuracy: 0.9114285707473755
generator epoch 38 loss: 0.8335590000697545                 accuracy: 0.9007142782211304
generator epoch 39 loss: 0.8341307625906808                 accuracy: 0.9028571248054504
generator epoch 40 loss: 0.8358882664271763                 accuracy: 0.9149999618530273
generator epoch 41 loss: 0.8313379725864956                 accuracy: 0.918571412563324
generator epoch 42 loss: 0.8302240330287388                 accuracy: 0.918571412563324
generator epoch 43 loss: 0.829166175188337                 accuracy: 0.9157142639160156
generator epoch 44 loss: 0.8262359514508929                 accuracy: 0.9192857146263123
generator epoch 45 loss: 0.8281224365234375                 accuracy: 0.9171428680419922
generator epoch 46 loss: 0.8289904044015067                 accuracy: 0.9099999666213989
generator epoch 47 loss: 0.8313304050990513                 accuracy: 0.9235714077949524
generator epoch 48 loss: 0.8325342267717634                 accuracy: 0.9135714173316956
generator epoch 49 loss: 0.8238227438790457                 accuracy: 0.9171428680419922
generator epoch 50 loss: 0.8214994306291853                 accuracy: 0.918571412563324
generator epoch 51 loss: 0.8308022382463728                 accuracy: 0.920714259147644
generator epoch 52 loss: 0.823986190359933                 accuracy: 0.9178571105003357
generator epoch 53 loss: 0.8258985447474888                 accuracy: 0.8985714316368103
generator epoch 54 loss: 0.8222604021344866                 accuracy: 0.9314285516738892
generator epoch 55 loss: 0.8184511213030133                 accuracy: 0.9028571248054504
generator epoch 56 loss: 0.821673393031529                 accuracy: 0.9228571057319641
generator epoch 57 loss: 0.8204169904436384                 accuracy: 0.9157142639160156
generator epoch 58 loss: 0.8158030386788504                 accuracy: 0.9292857050895691
generator epoch 59 loss: 0.8215772365025111                 accuracy: 0.9242857098579407
generator epoch 60 loss: 0.8210239632742745                 accuracy: 0.9200000166893005
generator epoch 61 loss: 0.8141309579031808                 accuracy: 0.9228571057319641
generator epoch 62 loss: 0.8152689958844866                 accuracy: 0.9171428680419922
generator epoch 63 loss: 0.8169439287458148                 accuracy: 0.9307142496109009
generator epoch 64 loss: 0.8141766331263951                 accuracy: 0.9085714221000671
generator epoch 65 loss: 0.8170056623186384                 accuracy: 0.918571412563324
generator epoch 66 loss: 0.8147644801548549                 accuracy: 0.9221428632736206
generator epoch 67 loss: 0.8128111982073103                 accuracy: 0.9264285564422607
generator epoch 68 loss: 0.8046487208775112                 accuracy: 0.9278571605682373
generator epoch 69 loss: 0.806877605329241                 accuracy: 0.9142857193946838
generator epoch 70 loss: 0.814984281703404                 accuracy: 0.9214285612106323
generator epoch 71 loss: 0.8086280133928572                 accuracy: 0.9314285516738892
generator epoch 72 loss: 0.8119873291015625                 accuracy: 0.9128571152687073
generator epoch 73 loss: 0.8050161760602679                 accuracy: 0.918571412563324
generator epoch 74 loss: 0.8078310049874442                 accuracy: 0.9357143044471741
generator epoch 75 loss: 0.8137639513288225                 accuracy: 0.9264285564422607
generator epoch 76 loss: 0.8129072474888392                 accuracy: 0.927142858505249
generator epoch 77 loss: 0.8116839991978236                 accuracy: 0.9035714268684387
generator epoch 78 loss: 0.8110243709019253                 accuracy: 0.9178571105003357
generator epoch 79 loss: 0.8074020969935826                 accuracy: 0.9228571057319641
generator epoch 80 loss: 0.8079280055454799                 accuracy: 0.9171428680419922
generator epoch 81 loss: 0.804967400251116                 accuracy: 0.904285728931427
generator epoch 82 loss: 0.8032556134905134                 accuracy: 0.9314285516738892
generator epoch 83 loss: 0.8082329729352679                 accuracy: 0.9300000071525574
generator epoch 84 loss: 0.8047239318847657                 accuracy: 0.9107142686843872
generator epoch 85 loss: 0.8083702619280134                 accuracy: 0.9300000071525574
generator epoch 86 loss: 0.8039996904645648                 accuracy: 0.9257142543792725
generator epoch 87 loss: 0.8015664916992188                 accuracy: 0.9314285516738892
generator epoch 88 loss: 0.8021236040387835                 accuracy: 0.9192857146263123
generator epoch 89 loss: 0.7972928567068918                 accuracy: 0.9235714077949524
generator epoch 90 loss: 0.8037521048409598                 accuracy: 0.9278571605682373
generator epoch 91 loss: 0.8057456577845982                 accuracy: 0.9235714077949524
generator epoch 92 loss: 0.7990023154122489                 accuracy: 0.9342857003211975
generator epoch 93 loss: 0.8019680367606027                 accuracy: 0.9292857050895691
generator epoch 94 loss: 0.8010980119977679                 accuracy: 0.9292857050895691
generator epoch 95 loss: 0.79974287109375                 accuracy: 0.9328571557998657
generator epoch 96 loss: 0.8035028865269253                 accuracy: 0.9328571557998657
generator epoch 97 loss: 0.7941864153180803                 accuracy: 0.9314285516738892
generator epoch 98 loss: 0.8018553344726562                 accuracy: 0.9228571057319641
generator epoch 99 loss: 0.7948887773786273                 accuracy: 0.925000011920929
generator epoch 100 loss: 0.7987452610560826                 accuracy: 0.9064285755157471
generator epoch 101 loss: 0.7962561562674386                 accuracy: 0.918571412563324
generator epoch 102 loss: 0.8044223920549666                 accuracy: 0.9242857098579407
generator epoch 103 loss: 0.7961053109305245                 accuracy: 0.9192857146263123
generator epoch 104 loss: 0.7928782043457031                 accuracy: 0.9407142996788025
generator epoch 105 loss: 0.7960171657017299                 accuracy: 0.9228571057319641
generator epoch 106 loss: 0.7944773951939174                 accuracy: 0.9292857050895691
generator epoch 107 loss: 0.7973321040562221                 accuracy: 0.927142858505249
generator epoch 108 loss: 0.7951293273925781                 accuracy: 0.9471428394317627
generator epoch 109 loss: 0.7980270228794643                 accuracy: 0.9171428680419922
generator epoch 110 loss: 0.7982881766183035                 accuracy: 0.9221428632736206
generator epoch 111 loss: 0.8010694789341518                 accuracy: 0.9300000071525574
generator epoch 112 loss: 0.796518843296596                 accuracy: 0.9264285564422607
generator epoch 113 loss: 0.8005660797119141                 accuracy: 0.9371428489685059
generator epoch 114 loss: 0.8098275408063617                 accuracy: 0.9057142734527588
generator epoch 115 loss: 0.7971788879394531                 accuracy: 0.9300000071525574
generator epoch 116 loss: 0.7962122375488281                 accuracy: 0.9242857098579407
generator epoch 117 loss: 0.794396981375558                 accuracy: 0.9221428632736206
generator epoch 118 loss: 0.8043328456333705                 accuracy: 0.9149999618530273
generator epoch 119 loss: 0.7986226466587611                 accuracy: 0.9378571510314941
generator epoch 120 loss: 0.7990705213274275                 accuracy: 0.920714259147644
generator epoch 121 loss: 0.7924327680315291                 accuracy: 0.9149999618530273
generator epoch 122 loss: 0.7874797223772322                 accuracy: 0.9300000071525574
generator epoch 123 loss: 0.7904487871442523                 accuracy: 0.9392856955528259
generator epoch 124 loss: 0.7912202113560268                 accuracy: 0.9264285564422607
generator epoch 125 loss: 0.7935249302455357                 accuracy: 0.9335713982582092
generator epoch 126 loss: 0.7905072004045759                 accuracy: 0.9257142543792725
generator epoch 127 loss: 0.7927672746930804                 accuracy: 0.9057142734527588
generator epoch 128 loss: 0.7884059282575335                 accuracy: 0.9235714077949524
generator epoch 129 loss: 0.7918284794398717                 accuracy: 0.9350000023841858
generator epoch 130 loss: 0.7889658316476005                 accuracy: 0.925000011920929
generator epoch 131 loss: 0.7856141531808035                 accuracy: 0.9214285612106323
generator epoch 132 loss: 0.7884250209263393                 accuracy: 0.9242857098579407
generator epoch 133 loss: 0.7836987649100168                 accuracy: 0.9357143044471741
generator epoch 134 loss: 0.7907582576206752                 accuracy: 0.9292857050895691
generator epoch 135 loss: 0.7982028067452567                 accuracy: 0.9392856955528259
generator epoch 136 loss: 0.7873090724400111                 accuracy: 0.9278571605682373
generator epoch 137 loss: 0.7883746996198382                 accuracy: 0.9371428489685059
generator epoch 138 loss: 0.7904029453822544                 accuracy: 0.9142857193946838
generator epoch 139 loss: 0.7836441214425223                 accuracy: 0.925000011920929
generator epoch 140 loss: 0.7841627598353794                 accuracy: 0.9107142686843872
generator epoch 141 loss: 0.7877397513253348                 accuracy: 0.9328571557998657
generator epoch 142 loss: 0.7867947562081473                 accuracy: 0.9321428537368774
generator epoch 143 loss: 0.7842269204275949                 accuracy: 0.9257142543792725
generator epoch 144 loss: 0.7870650259835379                 accuracy: 0.918571412563324
generator epoch 145 loss: 0.7860419712611607                 accuracy: 0.9392856955528259
generator epoch 146 loss: 0.785887546648298                 accuracy: 0.9285714030265808
generator epoch 147 loss: 0.7911126207624163                 accuracy: 0.9214285612106323
generator epoch 148 loss: 0.782143399483817                 accuracy: 0.9314285516738892
generator epoch 149 loss: 0.7895748439243861                 accuracy: 0.9328571557998657
generator epoch 150 loss: 0.7886653712681362                 accuracy: 0.9392856955528259
generator epoch 151 loss: 0.7788711608886719                 accuracy: 0.9399999976158142
generator epoch 152 loss: 0.7907958587646484                 accuracy: 0.9214285612106323
generator epoch 153 loss: 0.7815815747942243                 accuracy: 0.9342857003211975
generator epoch 154 loss: 0.7812681370326451                 accuracy: 0.941428542137146
generator epoch 155 loss: 0.7853541534423828                 accuracy: 0.9407142996788025
generator epoch 156 loss: 0.7833765036446707                 accuracy: 0.9235714077949524
generator epoch 157 loss: 0.783798910522461                 accuracy: 0.9371428489685059
generator epoch 158 loss: 0.7869757298060825                 accuracy: 0.941428542137146
generator epoch 159 loss: 0.7884822828020368                 accuracy: 0.9435713887214661
generator epoch 160 loss: 0.7848029728480748                 accuracy: 0.9228571057319641
generator epoch 161 loss: 0.781442143031529                 accuracy: 0.9314285516738892
generator epoch 162 loss: 0.7862401681082589                 accuracy: 0.9371428489685059
generator epoch 163 loss: 0.7863072134835379                 accuracy: 0.9385713934898376
generator epoch 164 loss: 0.7847463261195592                 accuracy: 0.9285714030265808
generator epoch 165 loss: 0.7844709254673549                 accuracy: 0.9449999928474426
generator epoch 166 loss: 0.7825437979561942                 accuracy: 0.925000011920929
generator epoch 167 loss: 0.7842640747070313                 accuracy: 0.9350000023841858
generator epoch 168 loss: 0.7834296901157924                 accuracy: 0.9264285564422607
generator epoch 169 loss: 0.7849219765799386                 accuracy: 0.949999988079071
generator epoch 170 loss: 0.7825272744315012                 accuracy: 0.9307142496109009
generator epoch 171 loss: 0.7813489924839565                 accuracy: 0.9292857050895691
generator epoch 172 loss: 0.7802969050816128                 accuracy: 0.925000011920929
generator epoch 173 loss: 0.7809822998046875                 accuracy: 0.9178571105003357
generator epoch 174 loss: 0.7797889587402344                 accuracy: 0.9357143044471741
generator epoch 175 loss: 0.7820920510428292                 accuracy: 0.9457142949104309
generator epoch 176 loss: 0.7820661254882812                 accuracy: 0.9300000071525574
generator epoch 177 loss: 0.7762683310372489                 accuracy: 0.9307142496109009
generator epoch 178 loss: 0.7746830182756697                 accuracy: 0.9335713982582092
generator epoch 179 loss: 0.7781469975062779                 accuracy: 0.9442856907844543
generator epoch 180 loss: 0.7783948900495257                 accuracy: 0.9392856955528259
generator epoch 181 loss: 0.7786935381208148                 accuracy: 0.9357143044471741
generator epoch 182 loss: 0.7783807918003627                 accuracy: 0.9228571057319641
generator epoch 183 loss: 0.782922269984654                 accuracy: 0.925000011920929
generator epoch 184 loss: 0.7784032788957869                 accuracy: 0.9307142496109009
generator epoch 185 loss: 0.7779138105119978                 accuracy: 0.925000011920929
generator epoch 186 loss: 0.7787890459333148                 accuracy: 0.925000011920929
generator epoch 187 loss: 0.7797203922816686                 accuracy: 0.9385713934898376
generator epoch 188 loss: 0.7788414393833706                 accuracy: 0.9335713982582092
generator epoch 189 loss: 0.7775441580636161                 accuracy: 0.9235714077949524
generator epoch 190 loss: 0.7764375244140626                 accuracy: 0.9342857003211975
generator epoch 191 loss: 0.7692928828648159                 accuracy: 0.9421428442001343
generator epoch 192 loss: 0.7782619001116071                 accuracy: 0.9385713934898376
generator epoch 193 loss: 0.7780735246930803                 accuracy: 0.9492856860160828
generator epoch 194 loss: 0.7757777522495815                 accuracy: 0.9364285469055176
generator epoch 195 loss: 0.7793414467947823                 accuracy: 0.9264285564422607
generator epoch 196 loss: 0.7735928571428572                 accuracy: 0.941428542137146
generator epoch 197 loss: 0.774911954171317                 accuracy: 0.9407142996788025
generator epoch 198 loss: 0.7751933654785156                 accuracy: 0.9278571605682373
generator epoch 199 loss: 0.7744341094970704                 accuracy: 0.9307142496109009
generator epoch 200 loss: 0.77605728628976                 accuracy: 0.9242857098579407
generator epoch 201 loss: 0.7752074179513114                 accuracy: 0.9264285564422607
generator epoch 202 loss: 0.7791545135498047                 accuracy: 0.9342857003211975
generator epoch 203 loss: 0.7727286272321429                 accuracy: 0.9257142543792725
generator epoch 204 loss: 0.7738152548653738                 accuracy: 0.9435713887214661
generator epoch 205 loss: 0.7700365138462612                 accuracy: 0.9335713982582092
generator epoch 206 loss: 0.7730271096365793                 accuracy: 0.9464285373687744
generator epoch 207 loss: 0.7737661102294922                 accuracy: 0.9242857098579407
generator epoch 208 loss: 0.776692624773298                 accuracy: 0.9549999833106995
generator epoch 209 loss: 0.7739283011300223                 accuracy: 0.927142858505249
generator epoch 210 loss: 0.7740307647705078                 accuracy: 0.9421428442001343
generator epoch 211 loss: 0.7733998413085937                 accuracy: 0.9428571462631226
generator epoch 212 loss: 0.775247804914202                 accuracy: 0.9328571557998657
generator epoch 213 loss: 0.7686678828648158                 accuracy: 0.9435713887214661
generator epoch 214 loss: 0.7678156546456473                 accuracy: 0.9549999833106995
generator epoch 215 loss: 0.7777105032784598                 accuracy: 0.9257142543792725
generator epoch 216 loss: 0.7753327226911272                 accuracy: 0.9435713887214661
generator epoch 217 loss: 0.775294098336356                 accuracy: 0.9357143044471741
generator epoch 218 loss: 0.7696655247279576                 accuracy: 0.9350000023841858
generator epoch 219 loss: 0.7732800615583147                 accuracy: 0.9492856860160828
generator epoch 220 loss: 0.7744198913574218                 accuracy: 0.9457142949104309
generator epoch 221 loss: 0.7737394374302455                 accuracy: 0.9314285516738892
generator epoch 222 loss: 0.7740695513044085                 accuracy: 0.9278571605682373
generator epoch 223 loss: 0.7773546783447266                 accuracy: 0.9335713982582092
generator epoch 224 loss: 0.7757317653111049                 accuracy: 0.9307142496109009
generator epoch 225 loss: 0.7744562377929688                 accuracy: 0.9335713982582092
generator epoch 226 loss: 0.7678292236328125                 accuracy: 0.9357143044471741
generator epoch 227 loss: 0.7683211591448103                 accuracy: 0.927142858505249
generator epoch 228 loss: 0.7708073019845145                 accuracy: 0.9264285564422607
generator epoch 229 loss: 0.7730762778145926                 accuracy: 0.9399999976158142
generator epoch 230 loss: 0.7677193995884487                 accuracy: 0.9449999928474426
generator epoch 231 loss: 0.7714073364257813                 accuracy: 0.9300000071525574
generator epoch 232 loss: 0.772287382725307                 accuracy: 0.9357143044471741
generator epoch 233 loss: 0.7721968401227679                 accuracy: 0.9371428489685059
generator epoch 234 loss: 0.7660578050885881                 accuracy: 0.9399999976158142
generator epoch 235 loss: 0.768687268938337                 accuracy: 0.9435713887214661
generator epoch 236 loss: 0.7721189989362445                 accuracy: 0.9385713934898376
generator epoch 237 loss: 0.7696979282924107                 accuracy: 0.9278571605682373
generator epoch 238 loss: 0.76753515625                 accuracy: 0.9514285326004028
generator epoch 239 loss: 0.7692065355573382                 accuracy: 0.9471428394317627
generator epoch 240 loss: 0.7748057072230747                 accuracy: 0.9371428489685059
generator epoch 241 loss: 0.7774036451067243                 accuracy: 0.9307142496109009
generator epoch 242 loss: 0.7724693394252232                 accuracy: 0.9385713934898376
generator epoch 243 loss: 0.7684131399972098                 accuracy: 0.9457142949104309
generator epoch 244 loss: 0.7704447705950056                 accuracy: 0.9321428537368774
generator epoch 245 loss: 0.7676440599714006                 accuracy: 0.9457142949104309
generator epoch 246 loss: 0.766220880998884                 accuracy: 0.9428571462631226
generator epoch 247 loss: 0.7686395878383091                 accuracy: 0.9457142949104309
generator epoch 248 loss: 0.7679896741594587                 accuracy: 0.9421428442001343
generator epoch 249 loss: 0.7640803296770369                 accuracy: 0.9242857098579407
generator epoch 250 loss: 0.7662611454554966                 accuracy: 0.9557142853736877
generator epoch 251 loss: 0.7688136051722936                 accuracy: 0.9350000023841858
generator epoch 252 loss: 0.7718803981236049                 accuracy: 0.9542856812477112
generator epoch 253 loss: 0.7665497685023717                 accuracy: 0.9485714435577393
generator epoch 254 loss: 0.7655931230817522                 accuracy: 0.9214285612106323
generator epoch 255 loss: 0.7655551208496094                 accuracy: 0.9357143044471741
generator epoch 256 loss: 0.7680350612095425                 accuracy: 0.9421428442001343
generator epoch 257 loss: 0.7669731767926897                 accuracy: 0.9371428489685059
generator epoch 258 loss: 0.7651405600411552                 accuracy: 0.9457142949104309
generator epoch 259 loss: 0.7674249699183873                 accuracy: 0.9421428442001343
generator epoch 260 loss: 0.7622169106619698                 accuracy: 0.9492856860160828
generator epoch 261 loss: 0.7714495287214007                 accuracy: 0.9392856955528259
generator epoch 262 loss: 0.7702631186349052                 accuracy: 0.9492856860160828
generator epoch 263 loss: 0.775669768851144                 accuracy: 0.9164285659790039
generator epoch 264 loss: 0.7694809007917132                 accuracy: 0.9449999928474426
generator epoch 265 loss: 0.7626019317626953                 accuracy: 0.9435713887214661
generator epoch 266 loss: 0.7702004856654576                 accuracy: 0.9399999976158142
generator epoch 267 loss: 0.7675549364362444                 accuracy: 0.9292857050895691
generator epoch 268 loss: 0.7692490007672991                 accuracy: 0.9471428394317627
generator epoch 269 loss: 0.7676512808663505                 accuracy: 0.9585714340209961
generator epoch 270 loss: 0.7608177638462612                 accuracy: 0.9364285469055176
generator epoch 271 loss: 0.7648904514857701                 accuracy: 0.9557142853736877
generator epoch 272 loss: 0.7637577946254185                 accuracy: 0.9421428442001343
generator epoch 273 loss: 0.7651759360177176                 accuracy: 0.941428542137146
generator epoch 274 loss: 0.7608140284946987                 accuracy: 0.9492856860160828
generator epoch 275 loss: 0.7681274300711496                 accuracy: 0.941428542137146
generator epoch 276 loss: 0.7628381129673549                 accuracy: 0.9364285469055176
generator epoch 277 loss: 0.764813401576451                 accuracy: 0.9449999928474426
generator epoch 278 loss: 0.7624543657575334                 accuracy: 0.9442856907844543
generator epoch 279 loss: 0.769064697265625                 accuracy: 0.9421428442001343
generator epoch 280 loss: 0.7606291730608259                 accuracy: 0.9221428632736206
generator epoch 281 loss: 0.7620882494245257                 accuracy: 0.9385713934898376
generator epoch 282 loss: 0.7643713675362723                 accuracy: 0.9407142996788025
generator epoch 283 loss: 0.768646932547433                 accuracy: 0.9314285516738892
generator epoch 284 loss: 0.7679042733328683                 accuracy: 0.9392856955528259
generator epoch 285 loss: 0.7614225690569196                 accuracy: 0.9428571462631226
generator epoch 286 loss: 0.7615565377371651                 accuracy: 0.9464285373687744
generator epoch 287 loss: 0.7636474029541016                 accuracy: 0.9350000023841858
generator epoch 288 loss: 0.7647943424769811                 accuracy: 0.9314285516738892
generator epoch 289 loss: 0.7590713548932757                 accuracy: 0.9371428489685059
generator epoch 290 loss: 0.7663468030657087                 accuracy: 0.9335713982582092
generator epoch 291 loss: 0.761060409109933                 accuracy: 0.927142858505249
generator epoch 292 loss: 0.7622283115931919                 accuracy: 0.9335713982582092
generator epoch 293 loss: 0.7615452178955078                 accuracy: 0.9457142949104309
generator epoch 294 loss: 0.7571793871198381                 accuracy: 0.9292857050895691
generator epoch 295 loss: 0.7613583413260324                 accuracy: 0.9392856955528259
generator epoch 296 loss: 0.7597439531598772                 accuracy: 0.9378571510314941
generator epoch 297 loss: 0.7612088906424386                 accuracy: 0.9492856860160828
generator epoch 298 loss: 0.7591954472133091                 accuracy: 0.947857141494751
generator epoch 299 loss: 0.7601058728899275                 accuracy: 0.9292857050895691
generator epoch 300 loss: 0.7590984322684152                 accuracy: 0.9392856955528259
generator epoch 301 loss: 0.7644819893973215                 accuracy: 0.9307142496109009
generator epoch 302 loss: 0.7641315499441964                 accuracy: 0.9378571510314941
generator epoch 303 loss: 0.7615970310756138                 accuracy: 0.9278571605682373
generator epoch 304 loss: 0.7588297454833984                 accuracy: 0.9507142901420593
generator epoch 305 loss: 0.7619237919398717                 accuracy: 0.9557142853736877
generator epoch 306 loss: 0.7602800410679409                 accuracy: 0.9392856955528259
generator epoch 307 loss: 0.765464142717634                 accuracy: 0.9428571462631226
generator epoch 308 loss: 0.7623191798618861                 accuracy: 0.9257142543792725
generator epoch 309 loss: 0.7598176108224052                 accuracy: 0.9399999976158142
generator epoch 310 loss: 0.7596282688685826                 accuracy: 0.9285714030265808
generator epoch 311 loss: 0.7565482452392578                 accuracy: 0.9364285469055176
generator epoch 312 loss: 0.7601569122314453                 accuracy: 0.9399999976158142
generator epoch 313 loss: 0.7604193852015904                 accuracy: 0.9399999976158142
generator epoch 314 loss: 0.7600192522321428                 accuracy: 0.9464285373687744
generator epoch 315 loss: 0.7609211190359934                 accuracy: 0.9428571462631226
generator epoch 316 loss: 0.7599294564383371                 accuracy: 0.9557142853736877
generator epoch 317 loss: 0.7647462572370257                 accuracy: 0.9407142996788025
generator epoch 318 loss: 0.7660516732352121                 accuracy: 0.9350000023841858
generator epoch 319 loss: 0.761765270124163                 accuracy: 0.9385713934898376
generator epoch 320 loss: 0.7620813424246652                 accuracy: 0.9257142543792725
generator epoch 321 loss: 0.7619238961356026                 accuracy: 0.9571428298950195
generator epoch 322 loss: 0.7576569287981306                 accuracy: 0.947857141494751
generator epoch 323 loss: 0.7595080801827567                 accuracy: 0.949999988079071
generator epoch 324 loss: 0.7635948468889509                 accuracy: 0.9357143044471741
generator epoch 325 loss: 0.7603162039620536                 accuracy: 0.9442856907844543
generator epoch 326 loss: 0.7604206974574498                 accuracy: 0.9442856907844543
generator epoch 327 loss: 0.756354252406529                 accuracy: 0.947857141494751
generator epoch 328 loss: 0.7605938607352121                 accuracy: 0.9485714435577393
generator epoch 329 loss: 0.7630658351353237                 accuracy: 0.949999988079071
generator epoch 330 loss: 0.7634130933489118                 accuracy: 0.9492856860160828
generator epoch 331 loss: 0.7636148149762835                 accuracy: 0.9371428489685059
generator epoch 332 loss: 0.7571285888671875                 accuracy: 0.956428587436676
generator epoch 333 loss: 0.7605798649379185                 accuracy: 0.9385713934898376
generator epoch 334 loss: 0.7589938642229352                 accuracy: 0.9278571605682373
generator epoch 335 loss: 0.7601334655761719                 accuracy: 0.956428587436676
generator epoch 336 loss: 0.7585578883579799                 accuracy: 0.947857141494751
generator epoch 337 loss: 0.7586233141217913                 accuracy: 0.9357143044471741
generator epoch 338 loss: 0.7605212559291294                 accuracy: 0.9385713934898376
generator epoch 339 loss: 0.7664568036760603                 accuracy: 0.9421428442001343
generator epoch 340 loss: 0.7548727739606584                 accuracy: 0.9399999976158142
generator epoch 341 loss: 0.7633423710414341                 accuracy: 0.9378571510314941
generator epoch 342 loss: 0.7597231449672154                 accuracy: 0.9464285373687744
generator epoch 343 loss: 0.7612498574393136                 accuracy: 0.941428542137146
generator epoch 344 loss: 0.7572227408272879                 accuracy: 0.9535714387893677
generator epoch 345 loss: 0.7553307604108538                 accuracy: 0.927142858505249
generator epoch 346 loss: 0.7564472691127232                 accuracy: 0.927142858505249
generator epoch 347 loss: 0.7594820220947266                 accuracy: 0.9264285564422607
generator epoch 348 loss: 0.7556259150913783                 accuracy: 0.949999988079071
generator epoch 349 loss: 0.7539530644008091                 accuracy: 0.949999988079071
generator epoch 350 loss: 0.7593192199707032                 accuracy: 0.941428542137146
generator epoch 351 loss: 0.7630229688371931                 accuracy: 0.9385713934898376
generator epoch 352 loss: 0.7573266292027064                 accuracy: 0.9164285659790039
generator epoch 353 loss: 0.7551052324567522                 accuracy: 0.9449999928474426
generator epoch 354 loss: 0.7607840371268136                 accuracy: 0.9435713887214661
generator epoch 355 loss: 0.7567343675885881                 accuracy: 0.9528571367263794
generator epoch 356 loss: 0.7547169573102679                 accuracy: 0.9392856955528259
generator epoch 357 loss: 0.7561418518066406                 accuracy: 0.9342857003211975
generator epoch 358 loss: 0.7599119471958705                 accuracy: 0.9371428489685059
generator epoch 359 loss: 0.7600803192138672                 accuracy: 0.9428571462631226
generator epoch 360 loss: 0.7591734143938337                 accuracy: 0.9457142949104309
generator epoch 361 loss: 0.7588174412318638                 accuracy: 0.9421428442001343
generator epoch 362 loss: 0.7592622453962053                 accuracy: 0.9364285469055176
generator epoch 363 loss: 0.7576657453264509                 accuracy: 0.9442856907844543
generator epoch 364 loss: 0.7596856157575335                 accuracy: 0.9442856907844543
generator epoch 365 loss: 0.7540428771972656                 accuracy: 0.9200000166893005
generator epoch 366 loss: 0.7573884068080358                 accuracy: 0.947857141494751
generator epoch 367 loss: 0.7572387690952846                 accuracy: 0.9385713934898376
generator epoch 368 loss: 0.7638474605015346                 accuracy: 0.9328571557998657
generator epoch 369 loss: 0.7612639565604074                 accuracy: 0.947857141494751
generator epoch 370 loss: 0.7532259434291295                 accuracy: 0.9435713887214661
generator epoch 371 loss: 0.7563023755754743                 accuracy: 0.9392856955528259
generator epoch 372 loss: 0.758111145891462                 accuracy: 0.9528571367263794
generator epoch 373 loss: 0.7554075435093471                 accuracy: 0.9442856907844543
generator epoch 374 loss: 0.7589161433628627                 accuracy: 0.9421428442001343
generator epoch 375 loss: 0.7589085314069476                 accuracy: 0.9492856860160828
generator epoch 376 loss: 0.7605199737548828                 accuracy: 0.9535714387893677
generator epoch 377 loss: 0.7602844059535435                 accuracy: 0.941428542137146
generator epoch 378 loss: 0.7578803318568639                 accuracy: 0.9542856812477112
generator epoch 379 loss: 0.7499538099016462                 accuracy: 0.9485714435577393
generator epoch 380 loss: 0.7588464037214007                 accuracy: 0.9421428442001343
generator epoch 381 loss: 0.7557458844866072                 accuracy: 0.9442856907844543
generator epoch 382 loss: 0.7544590053013392                 accuracy: 0.9471428394317627
generator epoch 383 loss: 0.7564139273507254                 accuracy: 0.949999988079071
generator epoch 384 loss: 0.7586856100899833                 accuracy: 0.9407142996788025
generator epoch 385 loss: 0.7557703390938895                 accuracy: 0.9457142949104309
generator epoch 386 loss: 0.7587752777099609                 accuracy: 0.9428571462631226
generator epoch 387 loss: 0.7571985517229353                 accuracy: 0.9471428394317627
generator epoch 388 loss: 0.7549058781215123                 accuracy: 0.9407142996788025
generator epoch 389 loss: 0.7574129023960658                 accuracy: 0.949999988079071
generator epoch 390 loss: 0.7561909528459821                 accuracy: 0.9378571510314941
generator epoch 391 loss: 0.7556783682686942                 accuracy: 0.9378571510314941
generator epoch 392 loss: 0.7502667275565011                 accuracy: 0.9464285373687744
generator epoch 393 loss: 0.7546277356828962                 accuracy: 0.9357143044471741
generator epoch 394 loss: 0.754695654296875                 accuracy: 0.9464285373687744
generator epoch 395 loss: 0.7532052389962333                 accuracy: 0.9364285469055176
generator epoch 396 loss: 0.755129880632673                 accuracy: 0.9485714435577393
generator epoch 397 loss: 0.7529396663120814                 accuracy: 0.9457142949104309
generator epoch 398 loss: 0.7552358572823661                 accuracy: 0.9421428442001343
generator epoch 399 loss: 0.7594520276750837                 accuracy: 0.9485714435577393
generator epoch 400 loss: 0.7596477813720703                 accuracy: 0.9392856955528259
generator epoch 401 loss: 0.7476142059326172                 accuracy: 0.947857141494751
generator epoch 402 loss: 0.7479142477852958                 accuracy: 0.9607142806053162
generator epoch 403 loss: 0.7538887952532087                 accuracy: 0.9392856955528259
generator epoch 404 loss: 0.7534501085553851                 accuracy: 0.9399999976158142
generator epoch 405 loss: 0.7542507524762835                 accuracy: 0.9428571462631226
generator epoch 406 loss: 0.754921764264788                 accuracy: 0.9557142853736877
generator epoch 407 loss: 0.7521182246616909                 accuracy: 0.9385713934898376
generator epoch 408 loss: 0.7538776624407088                 accuracy: 0.941428542137146
generator epoch 409 loss: 0.7569723946707589                 accuracy: 0.9471428394317627
generator epoch 410 loss: 0.7579554103306362                 accuracy: 0.9457142949104309
generator epoch 411 loss: 0.7563036852155413                 accuracy: 0.9485714435577393
generator epoch 412 loss: 0.7549801121303014                 accuracy: 0.9457142949104309
generator epoch 413 loss: 0.7560323181152344                 accuracy: 0.9464285373687744
generator epoch 414 loss: 0.761793745640346                 accuracy: 0.947857141494751
generator epoch 415 loss: 0.7505079149518694                 accuracy: 0.9357143044471741
generator epoch 416 loss: 0.7505779650006975                 accuracy: 0.949999988079071
generator epoch 417 loss: 0.7528472508021763                 accuracy: 0.9357143044471741
generator epoch 418 loss: 0.7495596309116909                 accuracy: 0.9378571510314941
generator epoch 419 loss: 0.7481301365443639                 accuracy: 0.9385713934898376
generator epoch 420 loss: 0.7558054949079241                 accuracy: 0.9364285469055176
generator epoch 421 loss: 0.7505854187011719                 accuracy: 0.9392856955528259
generator epoch 422 loss: 0.7531367906842913                 accuracy: 0.9557142853736877
generator epoch 423 loss: 0.7555500348772322                 accuracy: 0.956428587436676
generator epoch 424 loss: 0.7539367475237165                 accuracy: 0.949999988079071
generator epoch 425 loss: 0.7520255868094308                 accuracy: 0.9642857313156128
generator epoch 426 loss: 0.7505271388462612                 accuracy: 0.9399999976158142
generator epoch 427 loss: 0.7549912972586496                 accuracy: 0.941428542137146
generator epoch 428 loss: 0.7575071629115513                 accuracy: 0.9385713934898376
generator epoch 429 loss: 0.7516138772147043                 accuracy: 0.947857141494751
generator epoch 430 loss: 0.7545613464355468                 accuracy: 0.9407142996788025
generator epoch 431 loss: 0.7594719547816685                 accuracy: 0.9449999928474426
generator epoch 432 loss: 0.7567607674734933                 accuracy: 0.941428542137146
generator epoch 433 loss: 0.750592554146903                 accuracy: 0.9421428442001343
generator epoch 434 loss: 0.754568465750558                 accuracy: 0.9485714435577393
generator epoch 435 loss: 0.7581452301025391                 accuracy: 0.9342857003211975
generator epoch 436 loss: 0.7523175746372768                 accuracy: 0.9464285373687744
generator epoch 437 loss: 0.7547498971121652                 accuracy: 0.9428571462631226
generator epoch 438 loss: 0.7536247519356863                 accuracy: 0.9457142949104309
generator epoch 439 loss: 0.7524957868303571                 accuracy: 0.9321428537368774
generator epoch 440 loss: 0.7513005977085658                 accuracy: 0.9557142853736877
generator epoch 441 loss: 0.7515979322160994                 accuracy: 0.9378571510314941
generator epoch 442 loss: 0.7551563345772879                 accuracy: 0.9492856860160828
generator epoch 443 loss: 0.7519308872767857                 accuracy: 0.9592856764793396
generator epoch 444 loss: 0.7493440717424665                 accuracy: 0.947857141494751
generator epoch 445 loss: 0.7562208971296038                 accuracy: 0.956428587436676
generator epoch 446 loss: 0.7531096269880022                 accuracy: 0.9521428346633911
generator epoch 447 loss: 0.7537277239118304                 accuracy: 0.9421428442001343
generator epoch 448 loss: 0.7560858363560268                 accuracy: 0.9442856907844543
generator epoch 449 loss: 0.7512456041608538                 accuracy: 0.9442856907844543
generator epoch 450 loss: 0.749399849155971                 accuracy: 0.9385713934898376
generator epoch 451 loss: 0.7516483184814453                 accuracy: 0.9435713887214661
generator epoch 452 loss: 0.7547873661586216                 accuracy: 0.9371428489685059
generator epoch 453 loss: 0.7544295401436942                 accuracy: 0.9292857050895691
generator epoch 454 loss: 0.7605497445242746                 accuracy: 0.9342857003211975
generator epoch 455 loss: 0.750083107648577                 accuracy: 0.9442856907844543
generator epoch 456 loss: 0.7556066816057477                 accuracy: 0.9557142853736877
generator epoch 457 loss: 0.7473688868931362                 accuracy: 0.9521428346633911
generator epoch 458 loss: 0.7523114994594029                 accuracy: 0.9485714435577393
generator epoch 459 loss: 0.7511913626534599                 accuracy: 0.947857141494751
generator epoch 460 loss: 0.750220077078683                 accuracy: 0.9435713887214661
generator epoch 461 loss: 0.7557164860316685                 accuracy: 0.9392856955528259
generator epoch 462 loss: 0.7553238734654018                 accuracy: 0.9449999928474426
generator epoch 463 loss: 0.7485528935023716                 accuracy: 0.9571428298950195
generator epoch 464 loss: 0.7552191371372767                 accuracy: 0.925000011920929
generator epoch 465 loss: 0.7514115352085659                 accuracy: 0.9371428489685059
generator epoch 466 loss: 0.7493488329206194                 accuracy: 0.941428542137146
generator epoch 467 loss: 0.7530100551060268                 accuracy: 0.9335713982582092
generator epoch 468 loss: 0.7473293313162668                 accuracy: 0.9528571367263794
generator epoch 469 loss: 0.747354838344029                 accuracy: 0.9449999928474426
generator epoch 470 loss: 0.7523455274309431                 accuracy: 0.9371428489685059
generator epoch 471 loss: 0.7531718074253627                 accuracy: 0.9521428346633911
generator epoch 472 loss: 0.75032412109375                 accuracy: 0.9371428489685059
generator epoch 473 loss: 0.7469322640555246                 accuracy: 0.956428587436676
generator epoch 474 loss: 0.7493909375871931                 accuracy: 0.9321428537368774
generator epoch 475 loss: 0.7497490225655692                 accuracy: 0.9592856764793396
generator epoch 476 loss: 0.7557548200334822                 accuracy: 0.9507142901420593
generator epoch 477 loss: 0.7509223323277064                 accuracy: 0.941428542137146
generator epoch 478 loss: 0.7461056527273996                 accuracy: 0.9492856860160828
generator epoch 479 loss: 0.7444209878104073                 accuracy: 0.9435713887214661
generator epoch 480 loss: 0.7474446794782366                 accuracy: 0.9449999928474426
generator epoch 481 loss: 0.7482467808314732                 accuracy: 0.9350000023841858
generator epoch 482 loss: 0.7500837764195033                 accuracy: 0.9507142901420593
generator epoch 483 loss: 0.7494400464739118                 accuracy: 0.9535714387893677
generator epoch 484 loss: 0.7495327689034598                 accuracy: 0.9571428298950195
generator epoch 485 loss: 0.7542238922119141                 accuracy: 0.947857141494751
generator epoch 486 loss: 0.7540687582833426                 accuracy: 0.941428542137146
generator epoch 487 loss: 0.7481390965053013                 accuracy: 0.9521428346633911
generator epoch 488 loss: 0.7495701987130301                 accuracy: 0.9407142996788025
generator epoch 489 loss: 0.7471658495221819                 accuracy: 0.9435713887214661
generator epoch 490 loss: 0.7540631395612444                 accuracy: 0.9399999976158142
generator epoch 491 loss: 0.7511495335170201                 accuracy: 0.9364285469055176
generator epoch 492 loss: 0.7544441833496094                 accuracy: 0.956428587436676
generator epoch 493 loss: 0.7520740003313338                 accuracy: 0.9378571510314941
generator epoch 494 loss: 0.7498076830182757                 accuracy: 0.9542856812477112
generator epoch 495 loss: 0.7506026654924666                 accuracy: 0.947857141494751
generator epoch 496 loss: 0.7519709751674107                 accuracy: 0.949999988079071
generator epoch 497 loss: 0.7491258418491908                 accuracy: 0.949999988079071
generator epoch 498 loss: 0.7516426374162947                 accuracy: 0.9364285469055176
generator epoch 499 loss: 0.744398131452288                 accuracy: 0.9507142901420593
batch 0 train loss: [0.4724225]
batch 1 train loss: [0.6916656]
batch 2 train loss: [0.5682769]
batch 3 train loss: [0.40839738]
batch 4 train loss: [0.52635294]
batch 5 train loss: [0.45401686]
batch 6 train loss: [0.61043763]
batch 7 train loss: [0.5031724]
batch 8 train loss: [0.6114168]
batch 9 train loss: [0.40217265]
batch 10 train loss: [0.45092052]
batch 11 train loss: [0.56506026]
batch 12 train loss: [0.509887]
batch 13 train loss: [0.4592476]
batch 14 train loss: [0.56281066]
batch 15 train loss: [0.49633244]
batch 16 train loss: [0.5179262]
batch 17 train loss: [0.57876176]
batch 18 train loss: [0.5329943]
batch 19 train loss: [0.5690385]
batch 20 train loss: [0.45719975]
batch 21 train loss: [0.52155894]
batch 22 train loss: [0.5327324]
batch 23 train loss: [0.4918328]
batch 24 train loss: [0.52516496]
batch 25 train loss: [0.4995926]
batch 26 train loss: [0.45395893]
batch 27 train loss: [0.5337268]
batch 28 train loss: [0.43787244]
batch 29 train loss: [0.5303191]
batch 30 train loss: [0.5199563]
batch 31 train loss: [0.47871915]
batch 32 train loss: [0.5884954]
batch 33 train loss: [0.56241477]
batch 34 train loss: [0.5642214]
batch 35 train loss: [0.39838803]
batch 36 train loss: [0.43211764]
batch 37 train loss: [0.5332045]
batch 38 train loss: [0.59969896]
batch 39 train loss: [0.5665612]
batch 40 train loss: [0.52595276]
batch 41 train loss: [0.5627212]
batch 42 train loss: [0.4545198]
batch 43 train loss: [0.5290402]
batch 44 train loss: [0.5469216]
batch 45 train loss: [0.44362664]
batch 46 train loss: [0.3483648]
batch 47 train loss: [0.55558515]
batch 48 train loss: [0.37653396]
batch 49 train loss: [0.45460922]
batch 50 train loss: [0.45755318]
batch 51 train loss: [0.4526741]
batch 52 train loss: [0.45734057]
batch 53 train loss: [0.554742]
batch 54 train loss: [0.5471052]
batch 55 train loss: [0.6206973]
batch 56 train loss: [0.42499784]
batch 57 train loss: [0.42664513]
batch 58 train loss: [0.47798446]
batch 59 train loss: [0.5022136]
batch 60 train loss: [0.48845854]
batch 61 train loss: [0.3487021]
batch 62 train loss: [0.3971354]
batch 63 train loss: [0.5315003]
batch 64 train loss: [0.43730894]
batch 65 train loss: [0.51456696]
batch 66 train loss: [0.54427046]
batch 67 train loss: [0.52362067]
batch 68 train loss: [0.36217555]
batch 69 train loss: [0.46691895]
batch 70 train loss: [0.4718988]
batch 71 train loss: [0.44414872]
batch 72 train loss: [0.57934684]
batch 73 train loss: [0.54518485]
batch 74 train loss: [0.5130179]
batch 75 train loss: [0.4331847]
batch 76 train loss: [0.41403392]
batch 77 train loss: [0.4326575]
batch 78 train loss: [0.5016235]
batch 79 train loss: [0.55122274]
batch 80 train loss: [0.48210818]
batch 81 train loss: [0.4480575]
batch 82 train loss: [0.57028043]
batch 83 train loss: [0.45118108]
batch 84 train loss: [0.46171555]
batch 85 train loss: [0.404444]
batch 86 train loss: [0.45060158]
batch 87 train loss: [0.4457248]
batch 88 train loss: [0.4726643]
batch 89 train loss: [0.40616113]
batch 90 train loss: [0.52109146]
batch 91 train loss: [0.47054648]
batch 92 train loss: [0.4838773]
batch 93 train loss: [0.40440062]
batch 94 train loss: [0.33261296]
batch 95 train loss: [0.44865945]
batch 96 train loss: [0.39374766]
batch 97 train loss: [0.5081171]
batch 98 train loss: [0.43130884]
batch 99 train loss: [0.46673062]
epoch 0 mean train loss: [0.48993894]
Epoch 0/400=>  train_loss: [0.48993894], iou: nan, cd: 2.156704352938627, test_mse: [0.38865617]
CORRECT PROGRAMS: 9797
batch 0 train loss: [0.33608195]
batch 1 train loss: [0.3797306]
batch 2 train loss: [0.39722076]
batch 3 train loss: [0.3270726]
batch 4 train loss: [0.37834653]
batch 5 train loss: [0.49205408]
batch 6 train loss: [0.35666505]
batch 7 train loss: [0.40398473]
batch 8 train loss: [0.47634274]
batch 9 train loss: [0.3195693]
batch 10 train loss: [0.45465952]
batch 11 train loss: [0.4088513]
batch 12 train loss: [0.3490885]
batch 13 train loss: [0.3962366]
batch 14 train loss: [0.4326549]
batch 15 train loss: [0.3869833]
batch 16 train loss: [0.3291789]
batch 17 train loss: [0.38571605]
batch 18 train loss: [0.3861793]
batch 19 train loss: [0.42532876]
batch 20 train loss: [0.44412726]
batch 21 train loss: [0.47984466]
batch 22 train loss: [0.38272843]
batch 23 train loss: [0.4199079]
batch 24 train loss: [0.38067275]
batch 25 train loss: [0.46907437]
batch 26 train loss: [0.487051]
batch 27 train loss: [0.34259596]
batch 28 train loss: [0.40947542]
batch 29 train loss: [0.36728913]
batch 30 train loss: [0.42215833]
batch 31 train loss: [0.4207678]
batch 32 train loss: [0.388802]
batch 33 train loss: [0.4301694]
batch 34 train loss: [0.321382]
batch 35 train loss: [0.47102678]
batch 36 train loss: [0.36160377]
batch 37 train loss: [0.36433572]
batch 38 train loss: [0.34163544]
batch 39 train loss: [0.4365746]
batch 40 train loss: [0.43910936]
batch 41 train loss: [0.43969035]
batch 42 train loss: [0.48143086]
batch 43 train loss: [0.36914796]
batch 44 train loss: [0.3309887]
batch 45 train loss: [0.39080393]
batch 46 train loss: [0.4289651]
batch 47 train loss: [0.4762186]
batch 48 train loss: [0.35484704]
batch 49 train loss: [0.39705262]
batch 50 train loss: [0.39016643]
batch 51 train loss: [0.45166174]
batch 52 train loss: [0.363364]
batch 53 train loss: [0.37322003]
batch 54 train loss: [0.42437747]
batch 55 train loss: [0.38079563]
batch 56 train loss: [0.3560373]
batch 57 train loss: [0.4291376]
batch 58 train loss: [0.4692465]
batch 59 train loss: [0.38695404]
batch 60 train loss: [0.37751296]
batch 61 train loss: [0.40753964]
batch 62 train loss: [0.3705796]
batch 63 train loss: [0.33604056]
batch 64 train loss: [0.34417173]
batch 65 train loss: [0.34208882]
batch 66 train loss: [0.37500313]
batch 67 train loss: [0.36892197]
batch 68 train loss: [0.39926794]
batch 69 train loss: [0.42556888]
batch 70 train loss: [0.43648568]
batch 71 train loss: [0.2996794]
batch 72 train loss: [0.5200378]
batch 73 train loss: [0.47717515]
batch 74 train loss: [0.53437215]
batch 75 train loss: [0.37902224]
batch 76 train loss: [0.4184286]
batch 77 train loss: [0.37933645]
batch 78 train loss: [0.2920129]
batch 79 train loss: [0.38446632]
batch 80 train loss: [0.48693213]
batch 81 train loss: [0.47874188]
batch 82 train loss: [0.48327377]
batch 83 train loss: [0.423719]
batch 84 train loss: [0.37209758]
batch 85 train loss: [0.50952405]
batch 86 train loss: [0.4518586]
batch 87 train loss: [0.40297562]
batch 88 train loss: [0.41276148]
batch 89 train loss: [0.40656325]
batch 90 train loss: [0.3949245]
batch 91 train loss: [0.39685017]
batch 92 train loss: [0.4680118]
batch 93 train loss: [0.49685943]
batch 94 train loss: [0.41417012]
batch 95 train loss: [0.36186877]
batch 96 train loss: [0.36102238]
batch 97 train loss: [0.47832903]
batch 98 train loss: [0.41090074]
batch 99 train loss: [0.51963156]
epoch 1 mean train loss: [0.40695107]
Epoch 1/400=>  train_loss: [0.40695107], iou: nan, cd: 2.160528184935813, test_mse: [0.38103426]
CORRECT PROGRAMS: 9797
batch 0 train loss: [0.39234558]
batch 1 train loss: [0.33060285]
batch 2 train loss: [0.3747911]
batch 3 train loss: [0.32415426]
batch 4 train loss: [0.33673403]
batch 5 train loss: [0.33875695]
batch 6 train loss: [0.33295807]
batch 7 train loss: [0.3971668]
batch 8 train loss: [0.37233093]
batch 9 train loss: [0.4322813]
batch 10 train loss: [0.3486245]
batch 11 train loss: [0.33759674]
batch 12 train loss: [0.36959967]
batch 13 train loss: [0.3108457]
batch 14 train loss: [0.25130114]
batch 15 train loss: [0.37122375]
batch 16 train loss: [0.36354554]
batch 17 train loss: [0.32794306]
batch 18 train loss: [0.42553428]
batch 19 train loss: [0.29003847]
batch 20 train loss: [0.39502776]
batch 21 train loss: [0.3914776]
batch 22 train loss: [0.39969593]
batch 23 train loss: [0.3777764]
batch 24 train loss: [0.36757815]
batch 25 train loss: [0.42043868]
batch 26 train loss: [0.34669673]
batch 27 train loss: [0.41834256]
batch 28 train loss: [0.36551154]
batch 29 train loss: [0.3549638]
batch 30 train loss: [0.39938933]
batch 31 train loss: [0.350599]
batch 32 train loss: [0.36755502]
batch 33 train loss: [0.31103766]
batch 34 train loss: [0.4177798]
batch 35 train loss: [0.3245689]
batch 36 train loss: [0.3913632]
batch 37 train loss: [0.44103935]
batch 38 train loss: [0.32924548]
batch 39 train loss: [0.3017873]
batch 40 train loss: [0.39175254]
batch 41 train loss: [0.45449317]
batch 42 train loss: [0.32531044]
batch 43 train loss: [0.4669937]
batch 44 train loss: [0.35198048]
batch 45 train loss: [0.4037336]
batch 46 train loss: [0.3796536]
batch 47 train loss: [0.42402348]
batch 48 train loss: [0.37814263]
batch 49 train loss: [0.31639084]
batch 50 train loss: [0.34754533]
batch 51 train loss: [0.30880442]
batch 52 train loss: [0.35696605]
batch 53 train loss: [0.3025657]
batch 54 train loss: [0.36693734]
batch 55 train loss: [0.33544394]
batch 56 train loss: [0.3747076]
batch 57 train loss: [0.39172718]
batch 58 train loss: [0.4082983]
batch 59 train loss: [0.40335983]
batch 60 train loss: [0.35670155]
batch 61 train loss: [0.34846362]
batch 62 train loss: [0.45024624]
batch 63 train loss: [0.4261552]
batch 64 train loss: [0.39697802]
batch 65 train loss: [0.3419535]
batch 66 train loss: [0.29676265]
batch 67 train loss: [0.36467877]
batch 68 train loss: [0.4105925]
batch 69 train loss: [0.34263673]
batch 70 train loss: [0.29148722]
batch 71 train loss: [0.3855364]
batch 72 train loss: [0.346571]
batch 73 train loss: [0.3672627]
batch 74 train loss: [0.39807275]
batch 75 train loss: [0.31555283]
batch 76 train loss: [0.26554662]
batch 77 train loss: [0.29188251]
batch 78 train loss: [0.2854708]
batch 79 train loss: [0.42062837]
batch 80 train loss: [0.37915763]
batch 81 train loss: [0.41115293]
batch 82 train loss: [0.36948124]
batch 83 train loss: [0.40944976]
batch 84 train loss: [0.3408337]
batch 85 train loss: [0.30803862]
batch 86 train loss: [0.44759822]
batch 87 train loss: [0.41385958]
batch 88 train loss: [0.33765265]
batch 89 train loss: [0.3715686]
batch 90 train loss: [0.47108555]
batch 91 train loss: [0.33311236]
batch 92 train loss: [0.3119142]
batch 93 train loss: [0.3434364]
batch 94 train loss: [0.45135155]
batch 95 train loss: [0.33659008]
batch 96 train loss: [0.42180964]
batch 97 train loss: [0.28331366]
batch 98 train loss: [0.4114339]
batch 99 train loss: [0.4120749]
epoch 2 mean train loss: [0.36657172]
Epoch 2/400=>  train_loss: [0.36657172], iou: nan, cd: 2.001714355506846, test_mse: [0.36203697]
CORRECT PROGRAMS: 9797
batch 0 train loss: [0.30963397]
batch 1 train loss: [0.359921]
batch 2 train loss: [0.4034638]
batch 3 train loss: [0.2982777]
batch 4 train loss: [0.28724152]
batch 5 train loss: [0.26864845]
batch 6 train loss: [0.31442282]
batch 7 train loss: [0.32563865]
batch 8 train loss: [0.33256498]
batch 9 train loss: [0.34787595]
batch 10 train loss: [0.35202625]
batch 11 train loss: [0.27810097]
batch 12 train loss: [0.33578154]
batch 13 train loss: [0.35512236]
batch 14 train loss: [0.30665222]
batch 15 train loss: [0.29577166]
batch 16 train loss: [0.39753017]
batch 17 train loss: [0.38731804]
batch 18 train loss: [0.2699762]
batch 19 train loss: [0.39388868]
batch 20 train loss: [0.34618488]
batch 21 train loss: [0.379037]
batch 22 train loss: [0.28621206]
batch 23 train loss: [0.3577842]
batch 24 train loss: [0.33732146]
batch 25 train loss: [0.31228662]
batch 26 train loss: [0.31384292]
batch 27 train loss: [0.30981913]
batch 28 train loss: [0.28997082]
batch 29 train loss: [0.32281554]
batch 30 train loss: [0.27343714]
batch 31 train loss: [0.27363095]
batch 32 train loss: [0.2811315]
batch 33 train loss: [0.3795865]
batch 34 train loss: [0.40168965]
batch 35 train loss: [0.30710807]
batch 36 train loss: [0.26964498]
batch 37 train loss: [0.39231053]
batch 38 train loss: [0.41241467]
batch 39 train loss: [0.388652]
batch 40 train loss: [0.33812192]
batch 41 train loss: [0.27925694]
batch 42 train loss: [0.24452901]
batch 43 train loss: [0.31160742]
batch 44 train loss: [0.22961225]
batch 45 train loss: [0.3171434]
batch 46 train loss: [0.37204728]
batch 47 train loss: [0.33715066]
batch 48 train loss: [0.34374133]
batch 49 train loss: [0.39047498]
batch 50 train loss: [0.3917518]
batch 51 train loss: [0.40867898]
batch 52 train loss: [0.369512]
batch 53 train loss: [0.39424798]
batch 54 train loss: [0.4022728]
batch 55 train loss: [0.39420298]
batch 56 train loss: [0.36290458]
batch 57 train loss: [0.36817923]
batch 58 train loss: [0.3285798]
batch 59 train loss: [0.3765605]
batch 60 train loss: [0.2615461]
batch 61 train loss: [0.35758126]
batch 62 train loss: [0.34312597]
batch 63 train loss: [0.3252371]
batch 64 train loss: [0.39594114]
batch 65 train loss: [0.31617367]
batch 66 train loss: [0.30021176]
batch 67 train loss: [0.36286393]
batch 68 train loss: [0.29827106]
batch 69 train loss: [0.36123547]
batch 70 train loss: [0.3379244]
batch 71 train loss: [0.35921305]
batch 72 train loss: [0.27384323]
batch 73 train loss: [0.3082226]
batch 74 train loss: [0.36810365]
batch 75 train loss: [0.3436282]
batch 76 train loss: [0.33995444]
batch 77 train loss: [0.27942884]
batch 78 train loss: [0.28332007]
batch 79 train loss: [0.30887175]
batch 80 train loss: [0.3826481]
batch 81 train loss: [0.308405]
batch 82 train loss: [0.32435864]
batch 83 train loss: [0.322935]
batch 84 train loss: [0.35558483]
batch 85 train loss: [0.37460887]
batch 86 train loss: [0.35709965]
batch 87 train loss: [0.29193607]
batch 88 train loss: [0.30175415]
batch 89 train loss: [0.29039377]
batch 90 train loss: [0.35829538]
batch 91 train loss: [0.35191625]
batch 92 train loss: [0.31912205]
batch 93 train loss: [0.33231133]
batch 94 train loss: [0.36238402]
batch 95 train loss: [0.38000792]
batch 96 train loss: [0.30688897]
batch 97 train loss: [0.35574964]
batch 98 train loss: [0.42132255]
batch 99 train loss: [0.34159634]
epoch 3 mean train loss: [0.33579323]
Epoch 3/400=>  train_loss: [0.33579323], iou: nan, cd: 2.10637352083429, test_mse: [0.36449414]
CORRECT PROGRAMS: 9797
batch 0 train loss: [0.3148844]
batch 1 train loss: [0.32821986]
batch 2 train loss: [0.28478968]
batch 3 train loss: [0.31487417]
batch 4 train loss: [0.3076972]
batch 5 train loss: [0.30430818]
batch 6 train loss: [0.29438394]
batch 7 train loss: [0.30058455]
batch 8 train loss: [0.34542984]
batch 9 train loss: [0.32152122]
batch 10 train loss: [0.38243303]
batch 11 train loss: [0.298572]
batch 12 train loss: [0.33060652]
batch 13 train loss: [0.27966726]
batch 14 train loss: [0.2667822]
batch 15 train loss: [0.26676807]
batch 16 train loss: [0.29647216]
batch 17 train loss: [0.33301893]
batch 18 train loss: [0.30325428]
batch 19 train loss: [0.33230746]
batch 20 train loss: [0.2592638]
batch 21 train loss: [0.22489457]
batch 22 train loss: [0.3049867]
batch 23 train loss: [0.3926029]
batch 24 train loss: [0.34902552]
batch 25 train loss: [0.31759825]
batch 26 train loss: [0.33655348]
batch 27 train loss: [0.29447365]
batch 28 train loss: [0.29546794]
batch 29 train loss: [0.27145857]
batch 30 train loss: [0.33688602]
batch 31 train loss: [0.2923611]
batch 32 train loss: [0.31112367]
batch 33 train loss: [0.31165537]
batch 34 train loss: [0.32716197]
batch 35 train loss: [0.3092081]
batch 36 train loss: [0.25658572]
batch 37 train loss: [0.26363808]
batch 38 train loss: [0.2421048]
batch 39 train loss: [0.31130934]
batch 40 train loss: [0.27418935]
batch 41 train loss: [0.33000585]
batch 42 train loss: [0.35845372]
batch 43 train loss: [0.29385906]
batch 44 train loss: [0.27085012]
batch 45 train loss: [0.34033576]
batch 46 train loss: [0.33295137]
batch 47 train loss: [0.31633794]
batch 48 train loss: [0.28906935]
batch 49 train loss: [0.32460782]
batch 50 train loss: [0.4024666]
batch 51 train loss: [0.35702482]
batch 52 train loss: [0.32376418]
batch 53 train loss: [0.2835562]
batch 54 train loss: [0.28435436]
batch 55 train loss: [0.28949308]
batch 56 train loss: [0.2937597]
batch 57 train loss: [0.31524482]
batch 58 train loss: [0.27540123]
batch 59 train loss: [0.31854403]
batch 60 train loss: [0.33561996]
batch 61 train loss: [0.26354468]
batch 62 train loss: [0.321453]
batch 63 train loss: [0.29965898]
batch 64 train loss: [0.2777797]
batch 65 train loss: [0.34710225]
batch 66 train loss: [0.34806815]
batch 67 train loss: [0.29898685]
batch 68 train loss: [0.2989747]
batch 69 train loss: [0.33866972]
batch 70 train loss: [0.32165718]
batch 71 train loss: [0.2879905]
batch 72 train loss: [0.3819919]
batch 73 train loss: [0.37367895]
batch 74 train loss: [0.29656583]
batch 75 train loss: [0.33901817]
batch 76 train loss: [0.41166076]
batch 77 train loss: [0.29306012]
batch 78 train loss: [0.28696114]
batch 79 train loss: [0.36370245]
batch 80 train loss: [0.27096063]
batch 81 train loss: [0.3077418]
batch 82 train loss: [0.28497308]
batch 83 train loss: [0.31693918]
batch 84 train loss: [0.4098503]
batch 85 train loss: [0.29911482]
batch 86 train loss: [0.2502591]
batch 87 train loss: [0.31030074]
batch 88 train loss: [0.27827156]
batch 89 train loss: [0.29695374]
batch 90 train loss: [0.32506844]
batch 91 train loss: [0.3399865]
batch 92 train loss: [0.2528878]
batch 93 train loss: [0.30072412]
batch 94 train loss: [0.32172513]
batch 95 train loss: [0.3996781]
batch 96 train loss: [0.31457567]
batch 97 train loss: [0.3270413]
batch 98 train loss: [0.27990434]
batch 99 train loss: [0.26096737]
epoch 4 mean train loss: [0.31123275]
Epoch 4/400=>  train_loss: [0.31123275], iou: nan, cd: 1.9519274131153024, test_mse: [0.34473634]
CORRECT PROGRAMS: 9797
batch 0 train loss: [0.23012379]
batch 1 train loss: [0.223546]
batch 2 train loss: [0.2852774]
batch 3 train loss: [0.31812006]
batch 4 train loss: [0.30280343]
batch 5 train loss: [0.2889259]
batch 6 train loss: [0.22062318]
batch 7 train loss: [0.24961449]
batch 8 train loss: [0.2707692]
batch 9 train loss: [0.3089923]
batch 10 train loss: [0.32768002]
batch 11 train loss: [0.2683935]
batch 12 train loss: [0.3122811]
batch 13 train loss: [0.28947324]
batch 14 train loss: [0.26713213]
batch 15 train loss: [0.3519925]
batch 16 train loss: [0.31228295]
batch 17 train loss: [0.27229956]
batch 18 train loss: [0.32062072]
batch 19 train loss: [0.31392932]
batch 20 train loss: [0.27732486]
batch 21 train loss: [0.2862641]
batch 22 train loss: [0.27368113]
batch 23 train loss: [0.3030895]
batch 24 train loss: [0.27795154]
batch 25 train loss: [0.26490632]
batch 26 train loss: [0.29604834]
batch 27 train loss: [0.339441]
batch 28 train loss: [0.31253296]
batch 29 train loss: [0.27362734]
batch 30 train loss: [0.23620848]
batch 31 train loss: [0.27411354]
batch 32 train loss: [0.36323923]
batch 33 train loss: [0.2301898]
batch 34 train loss: [0.2707423]
batch 35 train loss: [0.2681115]
batch 36 train loss: [0.27259988]
batch 37 train loss: [0.3125089]
batch 38 train loss: [0.33906356]
batch 39 train loss: [0.24410373]
batch 40 train loss: [0.3229018]
batch 41 train loss: [0.36406913]
batch 42 train loss: [0.30651832]
batch 43 train loss: [0.25900137]
batch 44 train loss: [0.28025633]
batch 45 train loss: [0.27525753]
batch 46 train loss: [0.26500794]
batch 47 train loss: [0.36025766]
batch 48 train loss: [0.26675698]
batch 49 train loss: [0.28417724]
batch 50 train loss: [0.33944646]
batch 51 train loss: [0.25579423]
batch 52 train loss: [0.28844783]
batch 53 train loss: [0.34025323]
batch 54 train loss: [0.29143116]
batch 55 train loss: [0.2995876]
batch 56 train loss: [0.270442]
batch 57 train loss: [0.29050952]
batch 58 train loss: [0.3089696]
batch 59 train loss: [0.33188707]
batch 60 train loss: [0.24195059]
batch 61 train loss: [0.409537]
batch 62 train loss: [0.32305643]
batch 63 train loss: [0.32060084]
batch 64 train loss: [0.30775657]
batch 65 train loss: [0.2344852]
batch 66 train loss: [0.31407088]
batch 67 train loss: [0.32051483]
batch 68 train loss: [0.35950556]
batch 69 train loss: [0.22000009]
batch 70 train loss: [0.28113008]
batch 71 train loss: [0.31415206]
batch 72 train loss: [0.24717781]
batch 73 train loss: [0.2684892]
batch 74 train loss: [0.36533096]
batch 75 train loss: [0.28590772]
batch 76 train loss: [0.26936707]
batch 77 train loss: [0.2093138]
batch 78 train loss: [0.29572928]
batch 79 train loss: [0.3336734]
batch 80 train loss: [0.26943207]
batch 81 train loss: [0.28275704]
batch 82 train loss: [0.27776742]
batch 83 train loss: [0.26290172]
batch 84 train loss: [0.30620167]
batch 85 train loss: [0.36088932]
batch 86 train loss: [0.29276356]
batch 87 train loss: [0.27806678]
batch 88 train loss: [0.30933616]
batch 89 train loss: [0.31423208]
batch 90 train loss: [0.26354164]
batch 91 train loss: [0.30661398]
batch 92 train loss: [0.4014744]
batch 93 train loss: [0.31886777]
batch 94 train loss: [0.25839934]
batch 95 train loss: [0.28445745]
batch 96 train loss: [0.2995156]
batch 97 train loss: [0.2848706]
batch 98 train loss: [0.3179911]
batch 99 train loss: [0.31063017]
epoch 5 mean train loss: [0.2937406]
Epoch 5/400=>  train_loss: [0.2937406], iou: nan, cd: 1.9541615615264039, test_mse: [0.3473541]
CORRECT PROGRAMS: 9797
batch 0 train loss: [0.2988653]
batch 1 train loss: [0.2613262]
batch 2 train loss: [0.23411395]
batch 3 train loss: [0.24155027]
batch 4 train loss: [0.2992212]
batch 5 train loss: [0.23501867]
batch 6 train loss: [0.2799036]
batch 7 train loss: [0.28267288]
batch 8 train loss: [0.3337062]
batch 9 train loss: [0.23590751]
batch 10 train loss: [0.3191157]
batch 11 train loss: [0.30062196]
batch 12 train loss: [0.2940616]
batch 13 train loss: [0.30302116]
batch 14 train loss: [0.2486241]
batch 15 train loss: [0.27704883]
batch 16 train loss: [0.23052731]
batch 17 train loss: [0.3439873]
batch 18 train loss: [0.26115832]
batch 19 train loss: [0.24434955]
batch 20 train loss: [0.29034656]
batch 21 train loss: [0.2698093]
batch 22 train loss: [0.28273216]
batch 23 train loss: [0.2760587]
batch 24 train loss: [0.26267892]
batch 25 train loss: [0.24464133]
batch 26 train loss: [0.32640183]
batch 27 train loss: [0.39986867]
batch 28 train loss: [0.27646565]
batch 29 train loss: [0.23054767]
batch 30 train loss: [0.35610417]
batch 31 train loss: [0.26885828]
batch 32 train loss: [0.3169745]
batch 33 train loss: [0.2530232]
batch 34 train loss: [0.3014807]
batch 35 train loss: [0.23390521]
batch 36 train loss: [0.24907538]
batch 37 train loss: [0.2833754]
batch 38 train loss: [0.28942853]
batch 39 train loss: [0.23426752]
batch 40 train loss: [0.20498697]
batch 41 train loss: [0.22921051]
batch 42 train loss: [0.20517461]
batch 43 train loss: [0.27840853]
batch 44 train loss: [0.26738396]
batch 45 train loss: [0.20795912]
batch 46 train loss: [0.34288576]
batch 47 train loss: [0.38310152]
batch 48 train loss: [0.26301262]
batch 49 train loss: [0.29742295]
batch 50 train loss: [0.24760427]
batch 51 train loss: [0.30392092]
batch 52 train loss: [0.31405708]
batch 53 train loss: [0.22948594]
batch 54 train loss: [0.31929985]
batch 55 train loss: [0.2779758]
batch 56 train loss: [0.29063836]
batch 57 train loss: [0.33814538]
batch 58 train loss: [0.2469526]
batch 59 train loss: [0.21758696]
batch 60 train loss: [0.29440376]
batch 61 train loss: [0.30791622]
batch 62 train loss: [0.27969277]
batch 63 train loss: [0.2906981]
batch 64 train loss: [0.26441512]
batch 65 train loss: [0.26917922]
batch 66 train loss: [0.2474781]
batch 67 train loss: [0.24168965]
batch 68 train loss: [0.3113606]
batch 69 train loss: [0.26000068]
batch 70 train loss: [0.2656154]
batch 71 train loss: [0.3155648]
batch 72 train loss: [0.28748748]
batch 73 train loss: [0.29907125]
batch 74 train loss: [0.2535395]
batch 75 train loss: [0.32879007]
batch 76 train loss: [0.24370413]
batch 77 train loss: [0.35282698]
batch 78 train loss: [0.26161742]
batch 79 train loss: [0.2530444]
batch 80 train loss: [0.23886694]
batch 81 train loss: [0.29913402]
batch 82 train loss: [0.24599493]
batch 83 train loss: [0.3076224]
batch 84 train loss: [0.2763026]
batch 85 train loss: [0.2013181]
batch 86 train loss: [0.3083429]
batch 87 train loss: [0.30469128]
batch 88 train loss: [0.28101137]
batch 89 train loss: [0.3097148]
batch 90 train loss: [0.24707189]
batch 91 train loss: [0.24755499]
batch 92 train loss: [0.24753699]
batch 93 train loss: [0.26919615]
batch 94 train loss: [0.3210205]
batch 95 train loss: [0.23051709]
batch 96 train loss: [0.23339339]
batch 97 train loss: [0.31287795]
batch 98 train loss: [0.30829182]
batch 99 train loss: [0.2847749]
epoch 6 mean train loss: [0.27739388]
Epoch 6/400=>  train_loss: [0.27739388], iou: nan, cd: 1.9343816240130625, test_mse: [0.3448016]
CORRECT PROGRAMS: 9797
batch 0 train loss: [0.21589139]
batch 1 train loss: [0.20834224]
batch 2 train loss: [0.24883759]
batch 3 train loss: [0.29612064]
batch 4 train loss: [0.26144135]
batch 5 train loss: [0.24863262]
batch 6 train loss: [0.289169]
batch 7 train loss: [0.271491]
batch 8 train loss: [0.28692618]
batch 9 train loss: [0.27749333]
batch 10 train loss: [0.20670299]
batch 11 train loss: [0.21718432]
batch 12 train loss: [0.25033522]
batch 13 train loss: [0.37330452]
batch 14 train loss: [0.25368926]
batch 15 train loss: [0.23777819]
batch 16 train loss: [0.30204815]
batch 17 train loss: [0.318515]
batch 18 train loss: [0.2473063]
batch 19 train loss: [0.20010576]
batch 20 train loss: [0.23088974]
batch 21 train loss: [0.23679975]
batch 22 train loss: [0.27695927]
batch 23 train loss: [0.3224147]
batch 24 train loss: [0.22071983]
batch 25 train loss: [0.3016407]
batch 26 train loss: [0.3446465]
batch 27 train loss: [0.2816279]
batch 28 train loss: [0.25083548]
batch 29 train loss: [0.27666843]
batch 30 train loss: [0.2760106]
batch 31 train loss: [0.2368608]
batch 32 train loss: [0.23333088]
batch 33 train loss: [0.2864769]
batch 34 train loss: [0.28174683]
batch 35 train loss: [0.23489717]
batch 36 train loss: [0.2658621]
batch 37 train loss: [0.24055946]
batch 38 train loss: [0.2671194]
batch 39 train loss: [0.28048825]
batch 40 train loss: [0.25093645]
batch 41 train loss: [0.2890727]
batch 42 train loss: [0.22179508]
batch 43 train loss: [0.32357582]
batch 44 train loss: [0.24524786]
batch 45 train loss: [0.19842397]
batch 46 train loss: [0.2825616]
batch 47 train loss: [0.30529985]
batch 48 train loss: [0.24406643]
batch 49 train loss: [0.2586903]
batch 50 train loss: [0.23134834]
batch 51 train loss: [0.26052105]
batch 52 train loss: [0.30683485]
batch 53 train loss: [0.28490233]
batch 54 train loss: [0.28126281]
batch 55 train loss: [0.24540432]
batch 56 train loss: [0.2835459]
batch 57 train loss: [0.25547445]
batch 58 train loss: [0.23971897]
batch 59 train loss: [0.24505115]
batch 60 train loss: [0.25486115]
batch 61 train loss: [0.22903903]
batch 62 train loss: [0.27547294]
batch 63 train loss: [0.24208136]
batch 64 train loss: [0.289262]
batch 65 train loss: [0.29133964]
batch 66 train loss: [0.27282318]
batch 67 train loss: [0.23241146]
batch 68 train loss: [0.24801297]
batch 69 train loss: [0.25847507]
batch 70 train loss: [0.25018626]
batch 71 train loss: [0.23352066]
batch 72 train loss: [0.33643445]
batch 73 train loss: [0.25705537]
batch 74 train loss: [0.19306387]
batch 75 train loss: [0.29791743]
batch 76 train loss: [0.2815597]
batch 77 train loss: [0.297866]
batch 78 train loss: [0.29169697]
batch 79 train loss: [0.31883255]
batch 80 train loss: [0.30061752]
batch 81 train loss: [0.2262091]
batch 82 train loss: [0.29575846]
batch 83 train loss: [0.3337565]
batch 84 train loss: [0.24494441]
batch 85 train loss: [0.3214382]
batch 86 train loss: [0.2720629]
batch 87 train loss: [0.28697205]
batch 88 train loss: [0.2578922]
batch 89 train loss: [0.24414262]
batch 90 train loss: [0.2816622]
batch 91 train loss: [0.2617482]
batch 92 train loss: [0.26219547]
batch 93 train loss: [0.26261175]
batch 94 train loss: [0.254244]
batch 95 train loss: [0.2659777]
batch 96 train loss: [0.35114938]
batch 97 train loss: [0.22970636]
batch 98 train loss: [0.22789969]
batch 99 train loss: [0.22504172]
epoch 7 mean train loss: [0.26569545]
Epoch 7/400=>  train_loss: [0.26569545], iou: nan, cd: 1.8992244440623913, test_mse: [0.3408982]
CORRECT PROGRAMS: 9797
batch 0 train loss: [0.26198694]
batch 1 train loss: [0.23834075]
batch 2 train loss: [0.2405874]
batch 3 train loss: [0.21447806]
batch 4 train loss: [0.2128895]
batch 5 train loss: [0.23675987]
batch 6 train loss: [0.27966315]
batch 7 train loss: [0.25171417]
batch 8 train loss: [0.28383058]
batch 9 train loss: [0.24016827]
batch 10 train loss: [0.2788614]
batch 11 train loss: [0.21054901]
batch 12 train loss: [0.22275153]
batch 13 train loss: [0.29952273]
batch 14 train loss: [0.23095123]
batch 15 train loss: [0.25622764]
batch 16 train loss: [0.24301249]
batch 17 train loss: [0.25606823]
batch 18 train loss: [0.26178023]
batch 19 train loss: [0.31037605]
batch 20 train loss: [0.22135821]
batch 21 train loss: [0.2596685]
batch 22 train loss: [0.2299998]
batch 23 train loss: [0.24886745]
batch 24 train loss: [0.28297698]
batch 25 train loss: [0.23214269]
batch 26 train loss: [0.23580113]
batch 27 train loss: [0.23391141]
batch 28 train loss: [0.2774437]
batch 29 train loss: [0.21792704]
batch 30 train loss: [0.22670144]
batch 31 train loss: [0.22984037]
batch 32 train loss: [0.23675326]
batch 33 train loss: [0.25832224]
batch 34 train loss: [0.27708748]
batch 35 train loss: [0.22902381]
batch 36 train loss: [0.18935627]
batch 37 train loss: [0.26840046]
batch 38 train loss: [0.2730551]
batch 39 train loss: [0.2200666]
batch 40 train loss: [0.19976553]
batch 41 train loss: [0.28899354]
batch 42 train loss: [0.23015371]
batch 43 train loss: [0.28481182]
batch 44 train loss: [0.26010877]
batch 45 train loss: [0.23216704]
batch 46 train loss: [0.25759953]
batch 47 train loss: [0.24798553]
batch 48 train loss: [0.23509806]
batch 49 train loss: [0.23272614]
batch 50 train loss: [0.28799725]
batch 51 train loss: [0.29058966]
batch 52 train loss: [0.20876864]
batch 53 train loss: [0.2038551]
batch 54 train loss: [0.22721854]
batch 55 train loss: [0.26372173]
batch 56 train loss: [0.21493454]
batch 57 train loss: [0.26925603]
batch 58 train loss: [0.2952021]
batch 59 train loss: [0.26500675]
batch 60 train loss: [0.21178308]
batch 61 train loss: [0.26587856]
batch 62 train loss: [0.27930543]
batch 63 train loss: [0.2902519]
batch 64 train loss: [0.30450138]
batch 65 train loss: [0.30509323]
batch 66 train loss: [0.23037934]
batch 67 train loss: [0.29355985]
batch 68 train loss: [0.2056187]
batch 69 train loss: [0.250197]
batch 70 train loss: [0.31716067]
batch 71 train loss: [0.25793082]
batch 72 train loss: [0.23391087]
batch 73 train loss: [0.26362547]
batch 74 train loss: [0.21948257]
batch 75 train loss: [0.27014226]
batch 76 train loss: [0.28014433]
batch 77 train loss: [0.26598462]
batch 78 train loss: [0.21823527]
batch 79 train loss: [0.27822033]
batch 80 train loss: [0.2507553]
batch 81 train loss: [0.19929604]
batch 82 train loss: [0.2129285]
batch 83 train loss: [0.25348943]
batch 84 train loss: [0.21970536]
batch 85 train loss: [0.22935177]
batch 86 train loss: [0.2140535]
batch 87 train loss: [0.28039134]
batch 88 train loss: [0.2168237]
batch 89 train loss: [0.27883583]
batch 90 train loss: [0.32595262]
batch 91 train loss: [0.22291617]
batch 92 train loss: [0.29963657]
batch 93 train loss: [0.26558122]
batch 94 train loss: [0.28351042]
batch 95 train loss: [0.28235564]
batch 96 train loss: [0.2392319]
batch 97 train loss: [0.26107308]
batch 98 train loss: [0.27986252]
batch 99 train loss: [0.2254669]
epoch 8 mean train loss: [0.2515781]
Epoch 8/400=>  train_loss: [0.2515781], iou: nan, cd: 1.949404933869155, test_mse: [0.35568625]
CORRECT PROGRAMS: 9797
batch 0 train loss: [0.20088495]
batch 1 train loss: [0.23656754]
batch 2 train loss: [0.2326024]
batch 3 train loss: [0.23550303]
batch 4 train loss: [0.31523073]
batch 5 train loss: [0.24846335]
batch 6 train loss: [0.27093524]
batch 7 train loss: [0.17334]
batch 8 train loss: [0.23352551]
batch 9 train loss: [0.20928648]
batch 10 train loss: [0.20174749]
batch 11 train loss: [0.29221264]
batch 12 train loss: [0.20030962]
batch 13 train loss: [0.3075863]
batch 14 train loss: [0.27540565]
batch 15 train loss: [0.23568042]
batch 16 train loss: [0.28901923]
batch 17 train loss: [0.24646333]
batch 18 train loss: [0.22559288]
batch 19 train loss: [0.25913024]
batch 20 train loss: [0.17578863]
batch 21 train loss: [0.21645504]
batch 22 train loss: [0.27913907]
batch 23 train loss: [0.22433642]
batch 24 train loss: [0.27976307]
batch 25 train loss: [0.26227373]
batch 26 train loss: [0.24502659]
batch 27 train loss: [0.22021595]
batch 28 train loss: [0.20237727]
batch 29 train loss: [0.22375585]
batch 30 train loss: [0.239708]
batch 31 train loss: [0.24259034]
batch 32 train loss: [0.15972833]
batch 33 train loss: [0.24897091]
batch 34 train loss: [0.26697868]
batch 35 train loss: [0.22774412]
batch 36 train loss: [0.23968892]
batch 37 train loss: [0.25258324]
batch 38 train loss: [0.24727085]
batch 39 train loss: [0.28451046]
batch 40 train loss: [0.25660345]
batch 41 train loss: [0.20885561]
batch 42 train loss: [0.32593465]
batch 43 train loss: [0.25700685]
batch 44 train loss: [0.22178939]
batch 45 train loss: [0.23594123]
batch 46 train loss: [0.27958906]
batch 47 train loss: [0.30767423]
batch 48 train loss: [0.29845124]
batch 49 train loss: [0.24125534]
batch 50 train loss: [0.23750643]
batch 51 train loss: [0.21992344]
batch 52 train loss: [0.22034134]
batch 53 train loss: [0.22295666]
batch 54 train loss: [0.20878597]
batch 55 train loss: [0.19759277]
batch 56 train loss: [0.19320276]
batch 57 train loss: [0.2003631]
batch 58 train loss: [0.24061792]
batch 59 train loss: [0.27576375]
batch 60 train loss: [0.27903435]
batch 61 train loss: [0.29176927]
batch 62 train loss: [0.2663177]
batch 63 train loss: [0.1946031]
batch 64 train loss: [0.25897905]
batch 65 train loss: [0.27243516]
batch 66 train loss: [0.2553982]
batch 67 train loss: [0.23362783]
batch 68 train loss: [0.27161652]
batch 69 train loss: [0.3114902]
batch 70 train loss: [0.28988597]
batch 71 train loss: [0.23943298]
batch 72 train loss: [0.30577007]
batch 73 train loss: [0.26694873]
batch 74 train loss: [0.21688414]
batch 75 train loss: [0.2349985]
batch 76 train loss: [0.18338619]
batch 77 train loss: [0.24929263]
batch 78 train loss: [0.2526916]
batch 79 train loss: [0.23357166]
batch 80 train loss: [0.2714699]
batch 81 train loss: [0.28775558]
batch 82 train loss: [0.20305482]
batch 83 train loss: [0.23550731]
batch 84 train loss: [0.15126029]
batch 85 train loss: [0.23642075]
batch 86 train loss: [0.2876173]
batch 87 train loss: [0.2663796]
batch 88 train loss: [0.301856]
batch 89 train loss: [0.28069812]
batch 90 train loss: [0.23097664]
batch 91 train loss: [0.23685056]
batch 92 train loss: [0.2802278]
batch 93 train loss: [0.22262761]
batch 94 train loss: [0.27868405]
batch 95 train loss: [0.19996454]
batch 96 train loss: [0.21956177]
batch 97 train loss: [0.22246903]
batch 98 train loss: [0.24651505]
batch 99 train loss: [0.26591128]
epoch 9 mean train loss: [0.2451249]
Epoch 9/400=>  train_loss: [0.2451249], iou: nan, cd: 1.9167457224157833, test_mse: [0.3502605]
CORRECT PROGRAMS: 9797
batch 0 train loss: [0.18513253]
batch 1 train loss: [0.18966652]
batch 2 train loss: [0.19858144]
batch 3 train loss: [0.18333064]
batch 4 train loss: [0.2248971]
batch 5 train loss: [0.23246714]
batch 6 train loss: [0.28915247]
batch 7 train loss: [0.18582854]
batch 8 train loss: [0.21757717]
batch 9 train loss: [0.24843976]
batch 10 train loss: [0.3110007]
batch 11 train loss: [0.16369872]
batch 12 train loss: [0.23057671]
batch 13 train loss: [0.20321386]
batch 14 train loss: [0.23570448]
batch 15 train loss: [0.27695677]
batch 16 train loss: [0.23918808]
batch 17 train loss: [0.23620482]
batch 18 train loss: [0.25960615]
batch 19 train loss: [0.25511742]
batch 20 train loss: [0.19514047]
batch 21 train loss: [0.21872327]
batch 22 train loss: [0.22957326]
batch 23 train loss: [0.28432387]
batch 24 train loss: [0.2878524]
batch 25 train loss: [0.2614201]
batch 26 train loss: [0.24576108]
batch 27 train loss: [0.20523916]
batch 28 train loss: [0.18736796]
batch 29 train loss: [0.31596985]
batch 30 train loss: [0.24343552]
batch 31 train loss: [0.2411466]
batch 32 train loss: [0.21228744]
batch 33 train loss: [0.16852754]
batch 34 train loss: [0.25851676]
batch 35 train loss: [0.18756697]
batch 36 train loss: [0.25383294]
batch 37 train loss: [0.25965255]
batch 38 train loss: [0.20190965]
batch 39 train loss: [0.20769642]
batch 40 train loss: [0.21103437]
batch 41 train loss: [0.21896179]
batch 42 train loss: [0.24924225]
batch 43 train loss: [0.1974524]
batch 44 train loss: [0.24770726]
batch 45 train loss: [0.2125369]
batch 46 train loss: [0.2654098]
batch 47 train loss: [0.22692475]
batch 48 train loss: [0.23804726]
batch 49 train loss: [0.2387954]
batch 50 train loss: [0.21544898]
batch 51 train loss: [0.29408348]
batch 52 train loss: [0.27227744]
batch 53 train loss: [0.2407235]
batch 54 train loss: [0.29813203]
batch 55 train loss: [0.21149223]
batch 56 train loss: [0.27322945]
batch 57 train loss: [0.260558]
batch 58 train loss: [0.24716762]
batch 59 train loss: [0.2698077]
batch 60 train loss: [0.248127]
batch 61 train loss: [0.25843832]
batch 62 train loss: [0.21311906]
batch 63 train loss: [0.22972694]
batch 64 train loss: [0.2502949]
batch 65 train loss: [0.2041976]
batch 66 train loss: [0.24825637]
batch 67 train loss: [0.2470098]
batch 68 train loss: [0.22343834]
batch 69 train loss: [0.2505375]
batch 70 train loss: [0.26856443]
batch 71 train loss: [0.22054371]
batch 72 train loss: [0.22598764]
batch 73 train loss: [0.25821993]
batch 74 train loss: [0.24167101]
batch 75 train loss: [0.28832403]
batch 76 train loss: [0.23430873]
batch 77 train loss: [0.24935558]
batch 78 train loss: [0.23360279]
batch 79 train loss: [0.25018665]
batch 80 train loss: [0.24876818]
batch 81 train loss: [0.23482502]
batch 82 train loss: [0.23897743]
batch 83 train loss: [0.23311181]
batch 84 train loss: [0.24013746]
batch 85 train loss: [0.25666746]
batch 86 train loss: [0.24032666]
batch 87 train loss: [0.21958393]
batch 88 train loss: [0.26577517]
batch 89 train loss: [0.2602572]
batch 90 train loss: [0.19893898]
batch 91 train loss: [0.24180199]
batch 92 train loss: [0.2555931]
batch 93 train loss: [0.216857]
batch 94 train loss: [0.2889343]
batch 95 train loss: [0.24754998]
batch 96 train loss: [0.22159822]
batch 97 train loss: [0.26508534]
batch 98 train loss: [0.2604018]
batch 99 train loss: [0.24769863]
epoch 10 mean train loss: [0.23848118]
Epoch 10/400=>  train_loss: [0.23848118], iou: nan, cd: 1.9187392430688301, test_mse: [0.35061556]
CORRECT PROGRAMS: 9797
batch 0 train loss: [0.2505262]
batch 1 train loss: [0.21885337]
batch 2 train loss: [0.2586206]
batch 3 train loss: [0.18291369]
batch 4 train loss: [0.2212072]
batch 5 train loss: [0.25901458]
batch 6 train loss: [0.1761703]
batch 7 train loss: [0.23142305]
batch 8 train loss: [0.22659752]
batch 9 train loss: [0.22081645]
batch 10 train loss: [0.19216724]
batch 11 train loss: [0.21772572]
batch 12 train loss: [0.2803464]
batch 13 train loss: [0.20653124]
batch 14 train loss: [0.21470536]
batch 15 train loss: [0.24480255]
batch 16 train loss: [0.24952753]
batch 17 train loss: [0.22975042]
batch 18 train loss: [0.28164393]
batch 19 train loss: [0.24460377]
batch 20 train loss: [0.20284382]
batch 21 train loss: [0.2551931]
batch 22 train loss: [0.20163752]
batch 23 train loss: [0.21380718]
batch 24 train loss: [0.21602471]
batch 25 train loss: [0.22205271]
batch 26 train loss: [0.26322663]
batch 27 train loss: [0.21664993]
batch 28 train loss: [0.24783292]
batch 29 train loss: [0.19651811]
batch 30 train loss: [0.27152613]
batch 31 train loss: [0.22731794]
batch 32 train loss: [0.36078185]
batch 33 train loss: [0.16470216]
batch 34 train loss: [0.22978538]
batch 35 train loss: [0.19770283]
batch 36 train loss: [0.2082415]
batch 37 train loss: [0.23536143]
batch 38 train loss: [0.19615506]
batch 39 train loss: [0.21481802]
batch 40 train loss: [0.25703272]
batch 41 train loss: [0.23678212]
batch 42 train loss: [0.20625946]
batch 43 train loss: [0.24486974]
batch 44 train loss: [0.24452622]
batch 45 train loss: [0.23053628]
batch 46 train loss: [0.22398269]
batch 47 train loss: [0.17614545]
batch 48 train loss: [0.2501337]
batch 49 train loss: [0.21965727]
batch 50 train loss: [0.25890127]
batch 51 train loss: [0.23798765]
batch 52 train loss: [0.1867732]
batch 53 train loss: [0.20792715]
batch 54 train loss: [0.1702085]
batch 55 train loss: [0.23602152]
batch 56 train loss: [0.32475993]
batch 57 train loss: [0.26210898]
batch 58 train loss: [0.19756325]
batch 59 train loss: [0.18950628]
batch 60 train loss: [0.21169427]
batch 61 train loss: [0.2001678]
batch 62 train loss: [0.22535053]
batch 63 train loss: [0.2609286]
batch 64 train loss: [0.2335467]
batch 65 train loss: [0.20635526]
batch 66 train loss: [0.20535102]
batch 67 train loss: [0.25731778]
batch 68 train loss: [0.19429682]
batch 69 train loss: [0.14735703]
batch 70 train loss: [0.21026298]
batch 71 train loss: [0.23682824]
batch 72 train loss: [0.24087816]
batch 73 train loss: [0.25097954]
batch 74 train loss: [0.26116657]
batch 75 train loss: [0.2052791]
batch 76 train loss: [0.23755294]
batch 77 train loss: [0.18042454]
batch 78 train loss: [0.21072741]
batch 79 train loss: [0.18572816]
batch 80 train loss: [0.27351934]
batch 81 train loss: [0.22403128]
batch 82 train loss: [0.20440085]
batch 83 train loss: [0.23550531]
batch 84 train loss: [0.26765996]
batch 85 train loss: [0.2551312]
batch 86 train loss: [0.28016356]
batch 87 train loss: [0.19973625]
batch 88 train loss: [0.19735616]
batch 89 train loss: [0.23202069]
batch 90 train loss: [0.2516685]
batch 91 train loss: [0.26400685]
batch 92 train loss: [0.18765011]
batch 93 train loss: [0.21819492]
batch 94 train loss: [0.2397881]
batch 95 train loss: [0.3114478]
batch 96 train loss: [0.2655432]
batch 97 train loss: [0.30664796]
batch 98 train loss: [0.19248433]
batch 99 train loss: [0.2641537]
epoch 11 mean train loss: [0.22945108]
WAKE SLEEP ITERATION 6
Inferring cad batch: 0
Inferring cad batch: 1
Inferring cad batch: 2
Inferring cad batch: 3
Inferring cad batch: 4
Inferring cad batch: 5
Inferring cad batch: 6
Inferring cad batch: 7
Inferring cad batch: 8
Inferring cad batch: 9
Inferring cad batch: 10
Inferring cad batch: 11
Inferring cad batch: 12
Inferring cad batch: 13
Inferring cad batch: 14
Inferring cad batch: 15
Inferring cad batch: 16
Inferring cad batch: 17
Inferring cad batch: 18
Inferring cad batch: 19
Inferring cad batch: 20
Inferring cad batch: 21
Inferring cad batch: 22
Inferring cad batch: 23
Inferring cad batch: 24
Inferring cad batch: 25
Inferring cad batch: 26
Inferring cad batch: 27
Inferring cad batch: 28
Inferring cad batch: 29
Inferring cad batch: 30
Inferring cad batch: 31
Inferring cad batch: 32
Inferring cad average chamfer distance: 1.4053420063061148
0.5986428081635885 1.4053420063061148
generator epoch 0 loss: 1.1407362043108258                 accuracy: 0.8921428322792053
generator epoch 1 loss: 1.039014812360491                 accuracy: 0.8764285445213318
generator epoch 2 loss: 0.9985913835797992                 accuracy: 0.8985714316368103
generator epoch 3 loss: 0.9757066502162388                 accuracy: 0.895714282989502
generator epoch 4 loss: 0.9575987418038504                 accuracy: 0.8949999809265137
generator epoch 5 loss: 0.9454666530064174                 accuracy: 0.895714282989502
generator epoch 6 loss: 0.932345703125                 accuracy: 0.9135714173316956
generator epoch 7 loss: 0.9272664332798549                 accuracy: 0.895714282989502
generator epoch 8 loss: 0.918096826171875                 accuracy: 0.904285728931427
generator epoch 9 loss: 0.9088792733328683                 accuracy: 0.9028571248054504
generator epoch 10 loss: 0.9045649178641183                 accuracy: 0.9149999618530273
generator epoch 11 loss: 0.9008761213030134                 accuracy: 0.9035714268684387
generator epoch 12 loss: 0.893085262625558                 accuracy: 0.8949999809265137
generator epoch 13 loss: 0.8922090410505022                 accuracy: 0.9071428179740906
generator epoch 14 loss: 0.886039523751395                 accuracy: 0.9071428179740906
generator epoch 15 loss: 0.8825230878557477                 accuracy: 0.927142858505249
generator epoch 16 loss: 0.8792357700892857                 accuracy: 0.9099999666213989
generator epoch 17 loss: 0.8774217625209263                 accuracy: 0.9057142734527588
generator epoch 18 loss: 0.8750145350864955                 accuracy: 0.9221428632736206
generator epoch 19 loss: 0.867136634172712                 accuracy: 0.9142857193946838
generator epoch 20 loss: 0.873615149797712                 accuracy: 0.8999999761581421
generator epoch 21 loss: 0.86447824445452                 accuracy: 0.8971428275108337
generator epoch 22 loss: 0.8643386317661831                 accuracy: 0.9149999618530273
generator epoch 23 loss: 0.8600028887067522                 accuracy: 0.9064285755157471
generator epoch 24 loss: 0.8570409197126116                 accuracy: 0.9107142686843872
generator epoch 25 loss: 0.8557084359305246                 accuracy: 0.9149999618530273
generator epoch 26 loss: 0.8557507402692522                 accuracy: 0.9099999666213989
generator epoch 27 loss: 0.8533496956961496                 accuracy: 0.9221428632736206
generator epoch 28 loss: 0.8587947771344866                 accuracy: 0.9257142543792725
generator epoch 29 loss: 0.8526279453822545                 accuracy: 0.8942856788635254
generator epoch 30 loss: 0.8495945007324218                 accuracy: 0.9049999713897705
generator epoch 31 loss: 0.8485498439243861                 accuracy: 0.9114285707473755
generator epoch 32 loss: 0.8453838344029018                 accuracy: 0.9214285612106323
generator epoch 33 loss: 0.846905441720145                 accuracy: 0.9192857146263123
generator epoch 34 loss: 0.8488267185756139                 accuracy: 0.9350000023841858
generator epoch 35 loss: 0.8480731637137277                 accuracy: 0.918571412563324
generator epoch 36 loss: 0.843943075125558                 accuracy: 0.9078571200370789
generator epoch 37 loss: 0.8400339695521764                 accuracy: 0.927142858505249
generator epoch 38 loss: 0.8395951180594308                 accuracy: 0.9235714077949524
generator epoch 39 loss: 0.8384785583496094                 accuracy: 0.9135714173316956
generator epoch 40 loss: 0.8371277457101004                 accuracy: 0.9300000071525574
generator epoch 41 loss: 0.83815869140625                 accuracy: 0.9021428227424622
generator epoch 42 loss: 0.8351408996582032                 accuracy: 0.9257142543792725
generator epoch 43 loss: 0.8344894513811384                 accuracy: 0.9292857050895691
generator epoch 44 loss: 0.8338273646763393                 accuracy: 0.9157142639160156
generator epoch 45 loss: 0.8304488019670759                 accuracy: 0.9278571605682373
generator epoch 46 loss: 0.828250373186384                 accuracy: 0.9164285659790039
generator epoch 47 loss: 0.8259945068359374                 accuracy: 0.9350000023841858
generator epoch 48 loss: 0.8308016191755022                 accuracy: 0.9228571057319641
generator epoch 49 loss: 0.8254414646693639                 accuracy: 0.9257142543792725
generator epoch 50 loss: 0.8295197762625558                 accuracy: 0.9421428442001343
generator epoch 51 loss: 0.8273898733956473                 accuracy: 0.9264285564422607
generator epoch 52 loss: 0.8216284685407366                 accuracy: 0.9049999713897705
generator epoch 53 loss: 0.8213708164760045                 accuracy: 0.9335713982582092
generator epoch 54 loss: 0.8248115243094308                 accuracy: 0.9307142496109009
generator epoch 55 loss: 0.8247667872837612                 accuracy: 0.9200000166893005
generator epoch 56 loss: 0.8232296107700893                 accuracy: 0.9328571557998657
generator epoch 57 loss: 0.8219178702218192                 accuracy: 0.9278571605682373
generator epoch 58 loss: 0.8194242797851562                 accuracy: 0.9264285564422607
generator epoch 59 loss: 0.8258359985351562                 accuracy: 0.8942856788635254
generator epoch 60 loss: 0.8156782932826451                 accuracy: 0.9307142496109009
generator epoch 61 loss: 0.8192435302734375                 accuracy: 0.9214285612106323
generator epoch 62 loss: 0.8248806980678013                 accuracy: 0.9192857146263123
generator epoch 63 loss: 0.8182301034109933                 accuracy: 0.927142858505249
generator epoch 64 loss: 0.8202847473144531                 accuracy: 0.9157142639160156
generator epoch 65 loss: 0.8174899937220982                 accuracy: 0.9228571057319641
generator epoch 66 loss: 0.8208163330078125                 accuracy: 0.9235714077949524
generator epoch 67 loss: 0.8299319056919643                 accuracy: 0.9064285755157471
generator epoch 68 loss: 0.8246853201729911                 accuracy: 0.9064285755157471
generator epoch 69 loss: 0.8222048863002233                 accuracy: 0.9221428632736206
generator epoch 70 loss: 0.8169428388323102                 accuracy: 0.9300000071525574
generator epoch 71 loss: 0.8146782470703124                 accuracy: 0.9242857098579407
generator epoch 72 loss: 0.8127442570277623                 accuracy: 0.9242857098579407
generator epoch 73 loss: 0.8131724714006696                 accuracy: 0.9350000023841858
generator epoch 74 loss: 0.8182856994628906                 accuracy: 0.9192857146263123
generator epoch 75 loss: 0.8122643192836216                 accuracy: 0.9228571057319641
generator epoch 76 loss: 0.8150384878976005                 accuracy: 0.920714259147644
generator epoch 77 loss: 0.8096036603655133                 accuracy: 0.9385713934898376
generator epoch 78 loss: 0.81014287109375                 accuracy: 0.9442856907844543
generator epoch 79 loss: 0.8061101998465402                 accuracy: 0.9399999976158142
generator epoch 80 loss: 0.8094020246233259                 accuracy: 0.9357143044471741
generator epoch 81 loss: 0.8055596775599888                 accuracy: 0.9242857098579407
generator epoch 82 loss: 0.8090608834402901                 accuracy: 0.9092857241630554
generator epoch 83 loss: 0.8025615208217076                 accuracy: 0.925000011920929
generator epoch 84 loss: 0.8047727809361049                 accuracy: 0.9442856907844543
generator epoch 85 loss: 0.8077664895193918                 accuracy: 0.920714259147644
generator epoch 86 loss: 0.807830118233817                 accuracy: 0.9371428489685059
generator epoch 87 loss: 0.8028397408621651                 accuracy: 0.9157142639160156
generator epoch 88 loss: 0.8091000453404018                 accuracy: 0.9192857146263123
generator epoch 89 loss: 0.8030117396763393                 accuracy: 0.9221428632736206
generator epoch 90 loss: 0.8110681435721261                 accuracy: 0.9128571152687073
generator epoch 91 loss: 0.802850927734375                 accuracy: 0.9292857050895691
generator epoch 92 loss: 0.804209801374163                 accuracy: 0.9142857193946838
generator epoch 93 loss: 0.8028126674107143                 accuracy: 0.9300000071525574
generator epoch 94 loss: 0.8045644601004465                 accuracy: 0.9278571605682373
generator epoch 95 loss: 0.8061017918178014                 accuracy: 0.9164285659790039
generator epoch 96 loss: 0.8037743059430803                 accuracy: 0.9342857003211975
generator epoch 97 loss: 0.8058824148995536                 accuracy: 0.9399999976158142
generator epoch 98 loss: 0.8030314339773995                 accuracy: 0.9278571605682373
generator epoch 99 loss: 0.8011901436941964                 accuracy: 0.9214285612106323
generator epoch 100 loss: 0.8046265869140625                 accuracy: 0.9200000166893005
generator epoch 101 loss: 0.803440935407366                 accuracy: 0.9435713887214661
generator epoch 102 loss: 0.8022256382533482                 accuracy: 0.9278571605682373
generator epoch 103 loss: 0.7959244467599051                 accuracy: 0.9128571152687073
generator epoch 104 loss: 0.7982487461635045                 accuracy: 0.9242857098579407
generator epoch 105 loss: 0.7999060660226004                 accuracy: 0.9264285564422607
generator epoch 106 loss: 0.8046221461704799                 accuracy: 0.9157142639160156
generator epoch 107 loss: 0.8126940708705357                 accuracy: 0.9214285612106323
generator epoch 108 loss: 0.8053308057512556                 accuracy: 0.9378571510314941
generator epoch 109 loss: 0.8053508422851563                 accuracy: 0.9257142543792725
generator epoch 110 loss: 0.7991111537388392                 accuracy: 0.9178571105003357
generator epoch 111 loss: 0.798510786655971                 accuracy: 0.9278571605682373
generator epoch 112 loss: 0.7964775765555245                 accuracy: 0.9399999976158142
generator epoch 113 loss: 0.7967711635044643                 accuracy: 0.9428571462631226
generator epoch 114 loss: 0.8023426461356027                 accuracy: 0.927142858505249
generator epoch 115 loss: 0.795151296561105                 accuracy: 0.9421428442001343
generator epoch 116 loss: 0.7971796037946428                 accuracy: 0.9285714030265808
generator epoch 117 loss: 0.7938539677211216                 accuracy: 0.9171428680419922
generator epoch 118 loss: 0.7953030752999442                 accuracy: 0.9300000071525574
generator epoch 119 loss: 0.7958372610909599                 accuracy: 0.9350000023841858
generator epoch 120 loss: 0.792149833897182                 accuracy: 0.9471428394317627
generator epoch 121 loss: 0.7914108171735491                 accuracy: 0.9221428632736206
generator epoch 122 loss: 0.7942474862234933                 accuracy: 0.9342857003211975
generator epoch 123 loss: 0.7908997218540736                 accuracy: 0.9421428442001343
generator epoch 124 loss: 0.7955680986676897                 accuracy: 0.9485714435577393
generator epoch 125 loss: 0.8017632341657366                 accuracy: 0.9285714030265808
generator epoch 126 loss: 0.7954564304896763                 accuracy: 0.9257142543792725
generator epoch 127 loss: 0.7944240225655692                 accuracy: 0.9350000023841858
generator epoch 128 loss: 0.7924686183384486                 accuracy: 0.9442856907844543
generator epoch 129 loss: 0.7919588091169085                 accuracy: 0.9314285516738892
generator epoch 130 loss: 0.7918720498221261                 accuracy: 0.9407142996788025
generator epoch 131 loss: 0.792367227608817                 accuracy: 0.927142858505249
generator epoch 132 loss: 0.797863414655413                 accuracy: 0.9235714077949524
generator epoch 133 loss: 0.795975470842634                 accuracy: 0.9314285516738892
generator epoch 134 loss: 0.7944198660714286                 accuracy: 0.9285714030265808
generator epoch 135 loss: 0.7974743312290736                 accuracy: 0.9285714030265808
generator epoch 136 loss: 0.7921198717389788                 accuracy: 0.9178571105003357
generator epoch 137 loss: 0.788416801234654                 accuracy: 0.9264285564422607
generator epoch 138 loss: 0.7888384312220982                 accuracy: 0.9300000071525574
generator epoch 139 loss: 0.7948145289829799                 accuracy: 0.9292857050895691
generator epoch 140 loss: 0.7989080858503069                 accuracy: 0.9264285564422607
generator epoch 141 loss: 0.7894989292689732                 accuracy: 0.9342857003211975
generator epoch 142 loss: 0.7914730521065848                 accuracy: 0.9364285469055176
generator epoch 143 loss: 0.7898936462402344                 accuracy: 0.9449999928474426
generator epoch 144 loss: 0.7843302716936384                 accuracy: 0.9392856955528259
generator epoch 145 loss: 0.7889381277901786                 accuracy: 0.9392856955528259
generator epoch 146 loss: 0.7943736363002232                 accuracy: 0.9464285373687744
generator epoch 147 loss: 0.7925803427559989                 accuracy: 0.9214285612106323
generator epoch 148 loss: 0.7880319505964006                 accuracy: 0.9235714077949524
generator epoch 149 loss: 0.7962123591831752                 accuracy: 0.9350000023841858
generator epoch 150 loss: 0.7935386614118304                 accuracy: 0.9392856955528259
generator epoch 151 loss: 0.7944565835135323                 accuracy: 0.9314285516738892
generator epoch 152 loss: 0.7901586146763393                 accuracy: 0.9392856955528259
generator epoch 153 loss: 0.79455363507952                 accuracy: 0.9228571057319641
generator epoch 154 loss: 0.7875222856794085                 accuracy: 0.9350000023841858
generator epoch 155 loss: 0.7930646623883929                 accuracy: 0.9357143044471741
generator epoch 156 loss: 0.787134468296596                 accuracy: 0.9264285564422607
generator epoch 157 loss: 0.7874708217075893                 accuracy: 0.9449999928474426
generator epoch 158 loss: 0.7780377711704799                 accuracy: 0.9371428489685059
generator epoch 159 loss: 0.7868790666852679                 accuracy: 0.9200000166893005
generator epoch 160 loss: 0.7968578565325056                 accuracy: 0.9300000071525574
generator epoch 161 loss: 0.7913932098388672                 accuracy: 0.9392856955528259
generator epoch 162 loss: 0.7862289476667131                 accuracy: 0.9371428489685059
generator epoch 163 loss: 0.7841286634172712                 accuracy: 0.9321428537368774
generator epoch 164 loss: 0.7872659031459264                 accuracy: 0.9328571557998657
generator epoch 165 loss: 0.7850239453996931                 accuracy: 0.9321428537368774
generator epoch 166 loss: 0.7889201825823102                 accuracy: 0.9485714435577393
generator epoch 167 loss: 0.7919295135498047                 accuracy: 0.9285714030265808
generator epoch 168 loss: 0.7863410609654018                 accuracy: 0.9300000071525574
generator epoch 169 loss: 0.7902145856584821                 accuracy: 0.9385713934898376
generator epoch 170 loss: 0.7851208125523158                 accuracy: 0.9278571605682373
generator epoch 171 loss: 0.7872208993094308                 accuracy: 0.9514285326004028
generator epoch 172 loss: 0.7850438912527902                 accuracy: 0.9292857050895691
generator epoch 173 loss: 0.7850075020926339                 accuracy: 0.927142858505249
generator epoch 174 loss: 0.7851250117710659                 accuracy: 0.9342857003211975
generator epoch 175 loss: 0.7845330958775112                 accuracy: 0.9314285516738892
generator epoch 176 loss: 0.7849505375453404                 accuracy: 0.9235714077949524
generator epoch 177 loss: 0.787042045375279                 accuracy: 0.9264285564422607
generator epoch 178 loss: 0.7817586338588169                 accuracy: 0.9364285469055176
generator epoch 179 loss: 0.7816970489501953                 accuracy: 0.9399999976158142
generator epoch 180 loss: 0.784436194719587                 accuracy: 0.9285714030265808
generator epoch 181 loss: 0.7862940290178572                 accuracy: 0.9321428537368774
generator epoch 182 loss: 0.7843902566092354                 accuracy: 0.9149999618530273
generator epoch 183 loss: 0.7817506120954241                 accuracy: 0.927142858505249
generator epoch 184 loss: 0.7887705932617187                 accuracy: 0.9357143044471741
generator epoch 185 loss: 0.7844875366210937                 accuracy: 0.949999988079071
generator epoch 186 loss: 0.7804476684570313                 accuracy: 0.9421428442001343
generator epoch 187 loss: 0.7850598916190011                 accuracy: 0.9307142496109009
generator epoch 188 loss: 0.7824812813895089                 accuracy: 0.9514285326004028
generator epoch 189 loss: 0.7838324053083148                 accuracy: 0.9442856907844543
generator epoch 190 loss: 0.7862488124302456                 accuracy: 0.9421428442001343
generator epoch 191 loss: 0.7928273289271763                 accuracy: 0.9335713982582092
generator epoch 192 loss: 0.7839011710030692                 accuracy: 0.9214285612106323
generator epoch 193 loss: 0.7818258108956473                 accuracy: 0.9285714030265808
generator epoch 194 loss: 0.7844129856654576                 accuracy: 0.9171428680419922
generator epoch 195 loss: 0.7852314405168805                 accuracy: 0.9278571605682373
generator epoch 196 loss: 0.7779904039655413                 accuracy: 0.9257142543792725
generator epoch 197 loss: 0.7824043657575335                 accuracy: 0.9392856955528259
generator epoch 198 loss: 0.7838073564801897                 accuracy: 0.9371428489685059
generator epoch 199 loss: 0.7813935847691127                 accuracy: 0.9435713887214661
generator epoch 200 loss: 0.7808179953438895                 accuracy: 0.9435713887214661
generator epoch 201 loss: 0.778163567679269                 accuracy: 0.9485714435577393
generator epoch 202 loss: 0.7768887843540737                 accuracy: 0.9192857146263123
generator epoch 203 loss: 0.7791489340645926                 accuracy: 0.9342857003211975
generator epoch 204 loss: 0.7784992174421038                 accuracy: 0.949999988079071
generator epoch 205 loss: 0.7810481719970703                 accuracy: 0.9449999928474426
generator epoch 206 loss: 0.783723055594308                 accuracy: 0.9492856860160828
generator epoch 207 loss: 0.7803586896623884                 accuracy: 0.9385713934898376
generator epoch 208 loss: 0.7754297712053572                 accuracy: 0.9321428537368774
generator epoch 209 loss: 0.7821630920410156                 accuracy: 0.9292857050895691
generator epoch 210 loss: 0.778908260672433                 accuracy: 0.9342857003211975
generator epoch 211 loss: 0.7777904157366071                 accuracy: 0.9314285516738892
generator epoch 212 loss: 0.7784509063720703                 accuracy: 0.9385713934898376
generator epoch 213 loss: 0.7727744306291853                 accuracy: 0.9449999928474426
generator epoch 214 loss: 0.778605177961077                 accuracy: 0.9435713887214661
generator epoch 215 loss: 0.7753805834089007                 accuracy: 0.9350000023841858
generator epoch 216 loss: 0.7793408918108259                 accuracy: 0.9385713934898376
generator epoch 217 loss: 0.7784500854492188                 accuracy: 0.9300000071525574
generator epoch 218 loss: 0.7807215323311942                 accuracy: 0.9449999928474426
generator epoch 219 loss: 0.7769065268380302                 accuracy: 0.927142858505249
generator epoch 220 loss: 0.7756036080496652                 accuracy: 0.9278571605682373
generator epoch 221 loss: 0.7782595380510603                 accuracy: 0.9335713982582092
generator epoch 222 loss: 0.7780561527797154                 accuracy: 0.941428542137146
generator epoch 223 loss: 0.7800970406668527                 accuracy: 0.9521428346633911
generator epoch 224 loss: 0.7839169407435825                 accuracy: 0.9457142949104309
generator epoch 225 loss: 0.7780096313476562                 accuracy: 0.9428571462631226
generator epoch 226 loss: 0.7769172520228794                 accuracy: 0.9378571510314941
generator epoch 227 loss: 0.7745966958182199                 accuracy: 0.9485714435577393
generator epoch 228 loss: 0.780754789515904                 accuracy: 0.9314285516738892
generator epoch 229 loss: 0.7830542144775391                 accuracy: 0.9407142996788025
generator epoch 230 loss: 0.7766311471121652                 accuracy: 0.9507142901420593
generator epoch 231 loss: 0.7808805454799107                 accuracy: 0.9328571557998657
generator epoch 232 loss: 0.7768551766531808                 accuracy: 0.9264285564422607
generator epoch 233 loss: 0.7737493399483817                 accuracy: 0.9328571557998657
generator epoch 234 loss: 0.7807716365269253                 accuracy: 0.9378571510314941
generator epoch 235 loss: 0.7685713060651507                 accuracy: 0.9350000023841858
generator epoch 236 loss: 0.7741070242745536                 accuracy: 0.947857141494751
generator epoch 237 loss: 0.7792712110246931                 accuracy: 0.9350000023841858
generator epoch 238 loss: 0.7759580980573382                 accuracy: 0.9350000023841858
generator epoch 239 loss: 0.776485181100028                 accuracy: 0.9342857003211975
generator epoch 240 loss: 0.7770187094552177                 accuracy: 0.9392856955528259
generator epoch 241 loss: 0.7802781825474331                 accuracy: 0.9285714030265808
generator epoch 242 loss: 0.7779415915352957                 accuracy: 0.9328571557998657
generator epoch 243 loss: 0.7713309997558594                 accuracy: 0.9385713934898376
generator epoch 244 loss: 0.777701730782645                 accuracy: 0.9307142496109009
generator epoch 245 loss: 0.7770975381033761                 accuracy: 0.9428571462631226
generator epoch 246 loss: 0.777432816859654                 accuracy: 0.9285714030265808
generator epoch 247 loss: 0.7705352957589285                 accuracy: 0.9428571462631226
generator epoch 248 loss: 0.7755570552280971                 accuracy: 0.9214285612106323
generator epoch 249 loss: 0.7796564954485212                 accuracy: 0.949999988079071
generator epoch 250 loss: 0.7768121111188616                 accuracy: 0.9507142901420593
generator epoch 251 loss: 0.7779749114990234                 accuracy: 0.9357143044471741
generator epoch 252 loss: 0.7738632171630859                 accuracy: 0.941428542137146
generator epoch 253 loss: 0.7754285369873047                 accuracy: 0.9292857050895691
generator epoch 254 loss: 0.7777510511125837                 accuracy: 0.925000011920929
generator epoch 255 loss: 0.7718320373535156                 accuracy: 0.9428571462631226
generator epoch 256 loss: 0.7746267028808593                 accuracy: 0.9300000071525574
generator epoch 257 loss: 0.7756178955078125                 accuracy: 0.9392856955528259
generator epoch 258 loss: 0.7680912427629744                 accuracy: 0.927142858505249
generator epoch 259 loss: 0.7702263536725725                 accuracy: 0.9235714077949524
generator epoch 260 loss: 0.773515958077567                 accuracy: 0.9228571057319641
generator epoch 261 loss: 0.7788095807756696                 accuracy: 0.9485714435577393
generator epoch 262 loss: 0.7748964407784599                 accuracy: 0.9421428442001343
generator epoch 263 loss: 0.7743792759486607                 accuracy: 0.9407142996788025
generator epoch 264 loss: 0.7724972869873047                 accuracy: 0.9399999976158142
generator epoch 265 loss: 0.7733163635253906                 accuracy: 0.9407142996788025
generator epoch 266 loss: 0.7714491960797991                 accuracy: 0.9278571605682373
generator epoch 267 loss: 0.7742319732666015                 accuracy: 0.9321428537368774
generator epoch 268 loss: 0.7665687334333148                 accuracy: 0.9328571557998657
generator epoch 269 loss: 0.7700056344168527                 accuracy: 0.925000011920929
generator epoch 270 loss: 0.7749708465576172                 accuracy: 0.9314285516738892
generator epoch 271 loss: 0.7766401650565011                 accuracy: 0.9321428537368774
generator epoch 272 loss: 0.7768750566755023                 accuracy: 0.9485714435577393
generator epoch 273 loss: 0.7723434334891183                 accuracy: 0.925000011920929
generator epoch 274 loss: 0.7735739135742188                 accuracy: 0.9321428537368774
generator epoch 275 loss: 0.7795801609584263                 accuracy: 0.9421428442001343
generator epoch 276 loss: 0.7701497698102678                 accuracy: 0.956428587436676
generator epoch 277 loss: 0.7711663866315569                 accuracy: 0.925000011920929
generator epoch 278 loss: 0.7759408748081752                 accuracy: 0.9528571367263794
generator epoch 279 loss: 0.7788779445103237                 accuracy: 0.9300000071525574
generator epoch 280 loss: 0.7672110530308315                 accuracy: 0.9407142996788025
generator epoch 281 loss: 0.7738022661481585                 accuracy: 0.9449999928474426
generator epoch 282 loss: 0.7664829528808593                 accuracy: 0.9435713887214661
generator epoch 283 loss: 0.7666270050048828                 accuracy: 0.9521428346633911
generator epoch 284 loss: 0.769905419921875                 accuracy: 0.9328571557998657
generator epoch 285 loss: 0.768522214617048                 accuracy: 0.9399999976158142
generator epoch 286 loss: 0.77164388558524                 accuracy: 0.9392856955528259
generator epoch 287 loss: 0.7756083949497767                 accuracy: 0.9392856955528259
generator epoch 288 loss: 0.767245412336077                 accuracy: 0.9392856955528259
generator epoch 289 loss: 0.7710153302873884                 accuracy: 0.9371428489685059
generator epoch 290 loss: 0.7708263453892299                 accuracy: 0.9307142496109009
generator epoch 291 loss: 0.7752514447893415                 accuracy: 0.9314285516738892
generator epoch 292 loss: 0.7703159541538783                 accuracy: 0.9407142996788025
generator epoch 293 loss: 0.7693651384626116                 accuracy: 0.9399999976158142
generator epoch 294 loss: 0.7719379446847098                 accuracy: 0.9514285326004028
generator epoch 295 loss: 0.766546770804269                 accuracy: 0.9328571557998657
generator epoch 296 loss: 0.7669542572021485                 accuracy: 0.9542856812477112
generator epoch 297 loss: 0.7681297058105468                 accuracy: 0.9428571462631226
generator epoch 298 loss: 0.7700530901227679                 accuracy: 0.9457142949104309
generator epoch 299 loss: 0.7674359313964844                 accuracy: 0.9242857098579407
generator epoch 300 loss: 0.7683121760777065                 accuracy: 0.9464285373687744
generator epoch 301 loss: 0.7712445120675223                 accuracy: 0.9507142901420593
generator epoch 302 loss: 0.7674679094587054                 accuracy: 0.947857141494751
generator epoch 303 loss: 0.7709771414620535                 accuracy: 0.9378571510314941
generator epoch 304 loss: 0.7702896109444755                 accuracy: 0.9314285516738892
generator epoch 305 loss: 0.772472913469587                 accuracy: 0.9471428394317627
generator epoch 306 loss: 0.7723859252929688                 accuracy: 0.9371428489685059
generator epoch 307 loss: 0.7656065172467913                 accuracy: 0.9357143044471741
generator epoch 308 loss: 0.772136305454799                 accuracy: 0.9421428442001343
generator epoch 309 loss: 0.7705409759521484                 accuracy: 0.9471428394317627
generator epoch 310 loss: 0.7709099038260324                 accuracy: 0.9407142996788025
generator epoch 311 loss: 0.768780715070452                 accuracy: 0.947857141494751
generator epoch 312 loss: 0.7658550659179687                 accuracy: 0.9464285373687744
generator epoch 313 loss: 0.7727295915876116                 accuracy: 0.9435713887214661
generator epoch 314 loss: 0.7710697723388672                 accuracy: 0.9492856860160828
generator epoch 315 loss: 0.773152383858817                 accuracy: 0.9357143044471741
generator epoch 316 loss: 0.7731843671526227                 accuracy: 0.9314285516738892
generator epoch 317 loss: 0.7721109719412668                 accuracy: 0.9328571557998657
generator epoch 318 loss: 0.7689197923932757                 accuracy: 0.9428571462631226
generator epoch 319 loss: 0.7691585418701172                 accuracy: 0.9357143044471741
generator epoch 320 loss: 0.7753497876848493                 accuracy: 0.9257142543792725
generator epoch 321 loss: 0.771300796508789                 accuracy: 0.9392856955528259
generator epoch 322 loss: 0.7657079153878348                 accuracy: 0.9428571462631226
generator epoch 323 loss: 0.7698835885184152                 accuracy: 0.9449999928474426
generator epoch 324 loss: 0.7698157557896206                 accuracy: 0.941428542137146
generator epoch 325 loss: 0.770616890171596                 accuracy: 0.941428542137146
generator epoch 326 loss: 0.7716500688825335                 accuracy: 0.9442856907844543
generator epoch 327 loss: 0.7704996394566127                 accuracy: 0.9435713887214661
generator epoch 328 loss: 0.7648311117989677                 accuracy: 0.9449999928474426
generator epoch 329 loss: 0.7627763240269252                 accuracy: 0.9214285612106323
generator epoch 330 loss: 0.7692332188197545                 accuracy: 0.9371428489685059
generator epoch 331 loss: 0.7680274819510323                 accuracy: 0.9357143044471741
generator epoch 332 loss: 0.7664158961704799                 accuracy: 0.9421428442001343
generator epoch 333 loss: 0.7751419716971261                 accuracy: 0.9428571462631226
generator epoch 334 loss: 0.76481343863351                 accuracy: 0.9385713934898376
generator epoch 335 loss: 0.7743517761230468                 accuracy: 0.9507142901420593
generator epoch 336 loss: 0.7667482639857701                 accuracy: 0.9285714030265808
generator epoch 337 loss: 0.7638906014578684                 accuracy: 0.9464285373687744
generator epoch 338 loss: 0.7773848148890904                 accuracy: 0.9514285326004028
generator epoch 339 loss: 0.7658810743059431                 accuracy: 0.9485714435577393
generator epoch 340 loss: 0.7682926086425781                 accuracy: 0.9407142996788025
generator epoch 341 loss: 0.7645153477260045                 accuracy: 0.9378571510314941
generator epoch 342 loss: 0.7673209411621094                 accuracy: 0.9371428489685059
generator epoch 343 loss: 0.7695639744349888                 accuracy: 0.9350000023841858
generator epoch 344 loss: 0.7713892970493862                 accuracy: 0.9521428346633911
generator epoch 345 loss: 0.7700909654889788                 accuracy: 0.947857141494751
generator epoch 346 loss: 0.7674683515276227                 accuracy: 0.9300000071525574
generator epoch 347 loss: 0.7723976396833148                 accuracy: 0.9449999928474426
generator epoch 348 loss: 0.7693196498325893                 accuracy: 0.9464285373687744
generator epoch 349 loss: 0.768707727922712                 accuracy: 0.9399999976158142
generator epoch 350 loss: 0.7722446249825614                 accuracy: 0.9449999928474426
generator epoch 351 loss: 0.7641322291782924                 accuracy: 0.9435713887214661
generator epoch 352 loss: 0.7724618726457868                 accuracy: 0.9535714387893677
generator epoch 353 loss: 0.7702396148681641                 accuracy: 0.9342857003211975
generator epoch 354 loss: 0.7651955004010882                 accuracy: 0.9378571510314941
generator epoch 355 loss: 0.7646791024344308                 accuracy: 0.9521428346633911
generator epoch 356 loss: 0.7655354396275111                 accuracy: 0.9428571462631226
generator epoch 357 loss: 0.761810566493443                 accuracy: 0.9435713887214661
generator epoch 358 loss: 0.7640206787109375                 accuracy: 0.9378571510314941
generator epoch 359 loss: 0.7689718479701451                 accuracy: 0.9350000023841858
generator epoch 360 loss: 0.7689344905308315                 accuracy: 0.941428542137146
generator epoch 361 loss: 0.7693932364327567                 accuracy: 0.9371428489685059
generator epoch 362 loss: 0.7645645220075334                 accuracy: 0.9421428442001343
generator epoch 363 loss: 0.7615847957066127                 accuracy: 0.9357143044471741
generator epoch 364 loss: 0.7676567587716239                 accuracy: 0.9342857003211975
generator epoch 365 loss: 0.7735868743896485                 accuracy: 0.925000011920929
generator epoch 366 loss: 0.7692102896554129                 accuracy: 0.9421428442001343
generator epoch 367 loss: 0.7619940699986049                 accuracy: 0.9457142949104309
generator epoch 368 loss: 0.7671862099783762                 accuracy: 0.9399999976158142
generator epoch 369 loss: 0.7605636548723493                 accuracy: 0.9542856812477112
generator epoch 370 loss: 0.7607256958007812                 accuracy: 0.9350000023841858
generator epoch 371 loss: 0.7652234440394811                 accuracy: 0.9257142543792725
generator epoch 372 loss: 0.7626942077636719                 accuracy: 0.9514285326004028
generator epoch 373 loss: 0.7680624646868025                 accuracy: 0.9300000071525574
generator epoch 374 loss: 0.7650979906354631                 accuracy: 0.9471428394317627
generator epoch 375 loss: 0.7664264844621931                 accuracy: 0.9378571510314941
generator epoch 376 loss: 0.7692379002162388                 accuracy: 0.9449999928474426
generator epoch 377 loss: 0.7708941327776228                 accuracy: 0.9421428442001343
generator epoch 378 loss: 0.7659856724330357                 accuracy: 0.9335713982582092
generator epoch 379 loss: 0.7644591674804687                 accuracy: 0.9442856907844543
generator epoch 380 loss: 0.7597066737583705                 accuracy: 0.9457142949104309
generator epoch 381 loss: 0.7615408551897321                 accuracy: 0.9364285469055176
generator epoch 382 loss: 0.7657347080775669                 accuracy: 0.947857141494751
generator epoch 383 loss: 0.7644591225760323                 accuracy: 0.9264285564422607
generator epoch 384 loss: 0.7656198150634765                 accuracy: 0.9314285516738892
generator epoch 385 loss: 0.7644373927525112                 accuracy: 0.941428542137146
generator epoch 386 loss: 0.7584402256556919                 accuracy: 0.9492856860160828
generator epoch 387 loss: 0.7653347752162388                 accuracy: 0.9392856955528259
generator epoch 388 loss: 0.7624122685023716                 accuracy: 0.9542856812477112
generator epoch 389 loss: 0.7610664768763951                 accuracy: 0.9514285326004028
generator epoch 390 loss: 0.7758808458600726                 accuracy: 0.9342857003211975
generator epoch 391 loss: 0.7682358167375837                 accuracy: 0.9528571367263794
generator epoch 392 loss: 0.768225290788923                 accuracy: 0.9442856907844543
generator epoch 393 loss: 0.768640620640346                 accuracy: 0.9449999928474426
generator epoch 394 loss: 0.7629165204729352                 accuracy: 0.947857141494751
generator epoch 395 loss: 0.7631133884974889                 accuracy: 0.9314285516738892
generator epoch 396 loss: 0.7595619210379464                 accuracy: 0.9357143044471741
generator epoch 397 loss: 0.7593782688685826                 accuracy: 0.956428587436676
generator epoch 398 loss: 0.7585850485665457                 accuracy: 0.9457142949104309
generator epoch 399 loss: 0.7589285404750279                 accuracy: 0.949999988079071
generator epoch 400 loss: 0.7683124633789062                 accuracy: 0.9557142853736877
generator epoch 401 loss: 0.7593746189662388                 accuracy: 0.9407142996788025
generator epoch 402 loss: 0.767304465157645                 accuracy: 0.9435713887214661
generator epoch 403 loss: 0.7690247344970703                 accuracy: 0.9464285373687744
generator epoch 404 loss: 0.7715931335449219                 accuracy: 0.9399999976158142
generator epoch 405 loss: 0.7624992937360491                 accuracy: 0.9535714387893677
generator epoch 406 loss: 0.7611592189243862                 accuracy: 0.9371428489685059
generator epoch 407 loss: 0.7633732116699219                 accuracy: 0.9442856907844543
generator epoch 408 loss: 0.7640177389962333                 accuracy: 0.9435713887214661
generator epoch 409 loss: 0.763187240600586                 accuracy: 0.9421428442001343
generator epoch 410 loss: 0.7651062168666295                 accuracy: 0.9442856907844543
generator epoch 411 loss: 0.7647575334821428                 accuracy: 0.9542856812477112
generator epoch 412 loss: 0.7595673801967076                 accuracy: 0.9492856860160828
generator epoch 413 loss: 0.7561500405447824                 accuracy: 0.9300000071525574
generator epoch 414 loss: 0.7667526903424944                 accuracy: 0.9407142996788025
generator epoch 415 loss: 0.7635760027204241                 accuracy: 0.9442856907844543
generator epoch 416 loss: 0.7592710165841239                 accuracy: 0.9457142949104309
generator epoch 417 loss: 0.7589360800606864                 accuracy: 0.9399999976158142
generator epoch 418 loss: 0.7594839634486608                 accuracy: 0.9471428394317627
generator epoch 419 loss: 0.7608267451695033                 accuracy: 0.9307142496109009
generator epoch 420 loss: 0.7596903089250837                 accuracy: 0.9385713934898376
generator epoch 421 loss: 0.7609315826416015                 accuracy: 0.9471428394317627
generator epoch 422 loss: 0.7635889365059989                 accuracy: 0.9514285326004028
generator epoch 423 loss: 0.7591423631940569                 accuracy: 0.9449999928474426
generator epoch 424 loss: 0.7646926256452288                 accuracy: 0.941428542137146
generator epoch 425 loss: 0.7583047825404576                 accuracy: 0.9492856860160828
generator epoch 426 loss: 0.7677266013009207                 accuracy: 0.9449999928474426
generator epoch 427 loss: 0.7639497780936105                 accuracy: 0.9321428537368774
generator epoch 428 loss: 0.762140056501116                 accuracy: 0.9464285373687744
generator epoch 429 loss: 0.7588174072265625                 accuracy: 0.9321428537368774
generator epoch 430 loss: 0.7643054299490792                 accuracy: 0.9285714030265808
generator epoch 431 loss: 0.7644122763497488                 accuracy: 0.947857141494751
generator epoch 432 loss: 0.758554354422433                 accuracy: 0.9350000023841858
generator epoch 433 loss: 0.7610930812290737                 accuracy: 0.9321428537368774
generator epoch 434 loss: 0.7600311135428293                 accuracy: 0.941428542137146
generator epoch 435 loss: 0.767972698538644                 accuracy: 0.9371428489685059
generator epoch 436 loss: 0.7595030744280133                 accuracy: 0.9557142853736877
generator epoch 437 loss: 0.7604191811697824                 accuracy: 0.9342857003211975
generator epoch 438 loss: 0.7623965297154018                 accuracy: 0.9350000023841858
generator epoch 439 loss: 0.7658927769252232                 accuracy: 0.956428587436676
generator epoch 440 loss: 0.7582072810581753                 accuracy: 0.9464285373687744
generator epoch 441 loss: 0.7613190887451172                 accuracy: 0.949999988079071
generator epoch 442 loss: 0.7633113608224051                 accuracy: 0.9514285326004028
generator epoch 443 loss: 0.758384184047154                 accuracy: 0.9457142949104309
generator epoch 444 loss: 0.7677782418387277                 accuracy: 0.949999988079071
generator epoch 445 loss: 0.7590823608398437                 accuracy: 0.9221428632736206
generator epoch 446 loss: 0.7609140921456473                 accuracy: 0.9428571462631226
generator epoch 447 loss: 0.7595460540771485                 accuracy: 0.9457142949104309
generator epoch 448 loss: 0.7613855717250279                 accuracy: 0.9278571605682373
generator epoch 449 loss: 0.7593667920793806                 accuracy: 0.9371428489685059
generator epoch 450 loss: 0.7588660230364118                 accuracy: 0.9514285326004028
generator epoch 451 loss: 0.7662585222516741                 accuracy: 0.9471428394317627
generator epoch 452 loss: 0.7584248626708985                 accuracy: 0.941428542137146
generator epoch 453 loss: 0.7696798793247768                 accuracy: 0.9535714387893677
generator epoch 454 loss: 0.7633715977260045                 accuracy: 0.9449999928474426
generator epoch 455 loss: 0.759059073311942                 accuracy: 0.949999988079071
generator epoch 456 loss: 0.7639159000941685                 accuracy: 0.9357143044471741
generator epoch 457 loss: 0.7603203783307757                 accuracy: 0.9435713887214661
generator epoch 458 loss: 0.7610922310965402                 accuracy: 0.9378571510314941
generator epoch 459 loss: 0.755802154976981                 accuracy: 0.9407142996788025
generator epoch 460 loss: 0.761030959211077                 accuracy: 0.9428571462631226
generator epoch 461 loss: 0.7594932830810547                 accuracy: 0.9514285326004028
generator epoch 462 loss: 0.756297651890346                 accuracy: 0.9571428298950195
generator epoch 463 loss: 0.7587739244733538                 accuracy: 0.9399999976158142
generator epoch 464 loss: 0.764689537702288                 accuracy: 0.9457142949104309
generator epoch 465 loss: 0.7646974862234933                 accuracy: 0.9464285373687744
generator epoch 466 loss: 0.7598083661760603                 accuracy: 0.9549999833106995
generator epoch 467 loss: 0.761581292288644                 accuracy: 0.9435713887214661
generator epoch 468 loss: 0.7621082933698382                 accuracy: 0.9464285373687744
generator epoch 469 loss: 0.760718739100865                 accuracy: 0.9378571510314941
generator epoch 470 loss: 0.7608922437395368                 accuracy: 0.9399999976158142
generator epoch 471 loss: 0.7567023563929967                 accuracy: 0.9385713934898376
generator epoch 472 loss: 0.7594054696219308                 accuracy: 0.9514285326004028
generator epoch 473 loss: 0.7599057364327567                 accuracy: 0.9457142949104309
generator epoch 474 loss: 0.7639093013218471                 accuracy: 0.9557142853736877
generator epoch 475 loss: 0.7676479540143695                 accuracy: 0.9221428632736206
generator epoch 476 loss: 0.7635956909179688                 accuracy: 0.9457142949104309
generator epoch 477 loss: 0.7677125217982701                 accuracy: 0.9642857313156128
generator epoch 478 loss: 0.7564048592703683                 accuracy: 0.9307142496109009
generator epoch 479 loss: 0.7644301740373884                 accuracy: 0.9278571605682373
generator epoch 480 loss: 0.7602075857979911                 accuracy: 0.9421428442001343
generator epoch 481 loss: 0.7570238573346819                 accuracy: 0.9492856860160828
generator epoch 482 loss: 0.7624735804966518                 accuracy: 0.9399999976158142
generator epoch 483 loss: 0.7638216408865792                 accuracy: 0.9399999976158142
generator epoch 484 loss: 0.7634203046526228                 accuracy: 0.9507142901420593
generator epoch 485 loss: 0.7565698333740234                 accuracy: 0.9435713887214661
generator epoch 486 loss: 0.7573445831298828                 accuracy: 0.9364285469055176
generator epoch 487 loss: 0.7548722695486886                 accuracy: 0.947857141494751
generator epoch 488 loss: 0.7569581316266741                 accuracy: 0.9385713934898376
generator epoch 489 loss: 0.7515658556256976                 accuracy: 0.9407142996788025
generator epoch 490 loss: 0.7594335322788783                 accuracy: 0.956428587436676
generator epoch 491 loss: 0.7580786381312778                 accuracy: 0.941428542137146
generator epoch 492 loss: 0.7641032213483538                 accuracy: 0.9350000023841858
generator epoch 493 loss: 0.7559240910121373                 accuracy: 0.9371428489685059
generator epoch 494 loss: 0.7597682124546596                 accuracy: 0.9407142996788025
generator epoch 495 loss: 0.7592642551967076                 accuracy: 0.947857141494751
generator epoch 496 loss: 0.7598952492850167                 accuracy: 0.9535714387893677
generator epoch 497 loss: 0.7563799259730748                 accuracy: 0.956428587436676
generator epoch 498 loss: 0.7558621821812221                 accuracy: 0.9364285469055176
generator epoch 499 loss: 0.7585425510951451                 accuracy: 0.9292857050895691
batch 0 train loss: [0.7260101]
batch 1 train loss: [0.6406912]
batch 2 train loss: [0.550559]
batch 3 train loss: [0.639557]
batch 4 train loss: [0.66271913]
batch 5 train loss: [0.5295423]
batch 6 train loss: [0.6528613]
batch 7 train loss: [0.48353514]
batch 8 train loss: [0.59627575]
batch 9 train loss: [0.5855648]
batch 10 train loss: [0.5278704]
batch 11 train loss: [0.5330554]
batch 12 train loss: [0.4104388]
batch 13 train loss: [0.5172724]
batch 14 train loss: [0.46919614]
batch 15 train loss: [0.46326533]
batch 16 train loss: [0.5236553]
batch 17 train loss: [0.46815833]
batch 18 train loss: [0.48621282]
batch 19 train loss: [0.5303464]
batch 20 train loss: [0.50960684]
batch 21 train loss: [0.5443386]
batch 22 train loss: [0.48327217]
batch 23 train loss: [0.49232966]
batch 24 train loss: [0.5185036]
batch 25 train loss: [0.59904444]
batch 26 train loss: [0.41925418]
batch 27 train loss: [0.47271714]
batch 28 train loss: [0.52093047]
batch 29 train loss: [0.5437985]
batch 30 train loss: [0.52405787]
batch 31 train loss: [0.676246]
batch 32 train loss: [0.6401051]
batch 33 train loss: [0.4896719]
batch 34 train loss: [0.54945034]
batch 35 train loss: [0.4891882]
batch 36 train loss: [0.5513613]
batch 37 train loss: [0.5417422]
batch 38 train loss: [0.46970978]
batch 39 train loss: [0.49575847]
batch 40 train loss: [0.582729]
batch 41 train loss: [0.52018154]
batch 42 train loss: [0.43453315]
batch 43 train loss: [0.64390206]
batch 44 train loss: [0.66237557]
batch 45 train loss: [0.4262904]
batch 46 train loss: [0.39401206]
batch 47 train loss: [0.5000891]
batch 48 train loss: [0.4919386]
batch 49 train loss: [0.49861178]
batch 50 train loss: [0.5129327]
batch 51 train loss: [0.41566756]
batch 52 train loss: [0.63607055]
batch 53 train loss: [0.5115897]
batch 54 train loss: [0.5024352]
batch 55 train loss: [0.5244526]
batch 56 train loss: [0.56270707]
batch 57 train loss: [0.41756758]
batch 58 train loss: [0.4692041]
batch 59 train loss: [0.40525886]
batch 60 train loss: [0.47576955]
batch 61 train loss: [0.47743607]
batch 62 train loss: [0.46509537]
batch 63 train loss: [0.58322686]
batch 64 train loss: [0.44193196]
batch 65 train loss: [0.41757783]
batch 66 train loss: [0.46359998]
batch 67 train loss: [0.4506207]
batch 68 train loss: [0.32991442]
batch 69 train loss: [0.41965073]
batch 70 train loss: [0.5612658]
batch 71 train loss: [0.50106806]
batch 72 train loss: [0.50142384]
batch 73 train loss: [0.50620496]
batch 74 train loss: [0.43087325]
batch 75 train loss: [0.4177882]
batch 76 train loss: [0.5475907]
batch 77 train loss: [0.44789517]
batch 78 train loss: [0.5234977]
batch 79 train loss: [0.5395206]
batch 80 train loss: [0.46333462]
batch 81 train loss: [0.4069726]
batch 82 train loss: [0.42869347]
batch 83 train loss: [0.41999966]
batch 84 train loss: [0.5351355]
batch 85 train loss: [0.5560891]
batch 86 train loss: [0.4802092]
batch 87 train loss: [0.5013319]
batch 88 train loss: [0.48394743]
batch 89 train loss: [0.4455614]
batch 90 train loss: [0.53836626]
batch 91 train loss: [0.47219673]
batch 92 train loss: [0.5734668]
batch 93 train loss: [0.49833488]
batch 94 train loss: [0.50249743]
batch 95 train loss: [0.4836314]
batch 96 train loss: [0.51937056]
batch 97 train loss: [0.49392274]
batch 98 train loss: [0.43010488]
batch 99 train loss: [0.40823445]
epoch 0 mean train loss: [0.5078377]
Epoch 0/400=>  train_loss: [0.5078377], iou: nan, cd: 2.6732961407221363, test_mse: [0.42503566]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.3999373]
batch 1 train loss: [0.426407]
batch 2 train loss: [0.44272956]
batch 3 train loss: [0.38097814]
batch 4 train loss: [0.3828017]
batch 5 train loss: [0.47893295]
batch 6 train loss: [0.36605236]
batch 7 train loss: [0.46685007]
batch 8 train loss: [0.41266984]
batch 9 train loss: [0.42535707]
batch 10 train loss: [0.430834]
batch 11 train loss: [0.4578682]
batch 12 train loss: [0.42601398]
batch 13 train loss: [0.43240798]
batch 14 train loss: [0.39717716]
batch 15 train loss: [0.34580454]
batch 16 train loss: [0.4781757]
batch 17 train loss: [0.3644686]
batch 18 train loss: [0.3382377]
batch 19 train loss: [0.47067767]
batch 20 train loss: [0.38476762]
batch 21 train loss: [0.38387212]
batch 22 train loss: [0.42881778]
batch 23 train loss: [0.43191013]
batch 24 train loss: [0.41763768]
batch 25 train loss: [0.38243666]
batch 26 train loss: [0.5020585]
batch 27 train loss: [0.3983117]
batch 28 train loss: [0.35858795]
batch 29 train loss: [0.46568832]
batch 30 train loss: [0.40175006]
batch 31 train loss: [0.4290114]
batch 32 train loss: [0.28219965]
batch 33 train loss: [0.35030013]
batch 34 train loss: [0.38450137]
batch 35 train loss: [0.38048953]
batch 36 train loss: [0.45730108]
batch 37 train loss: [0.37979138]
batch 38 train loss: [0.48174953]
batch 39 train loss: [0.40817374]
batch 40 train loss: [0.4115235]
batch 41 train loss: [0.4362689]
batch 42 train loss: [0.44362044]
batch 43 train loss: [0.51549494]
batch 44 train loss: [0.43589]
batch 45 train loss: [0.32932422]
batch 46 train loss: [0.36899623]
batch 47 train loss: [0.45239195]
batch 48 train loss: [0.5027142]
batch 49 train loss: [0.46269614]
batch 50 train loss: [0.48833928]
batch 51 train loss: [0.42907318]
batch 52 train loss: [0.40280622]
batch 53 train loss: [0.29472846]
batch 54 train loss: [0.43430263]
batch 55 train loss: [0.4415667]
batch 56 train loss: [0.4425969]
batch 57 train loss: [0.41304824]
batch 58 train loss: [0.45368147]
batch 59 train loss: [0.33427387]
batch 60 train loss: [0.39933768]
batch 61 train loss: [0.4675155]
batch 62 train loss: [0.4229309]
batch 63 train loss: [0.3903844]
batch 64 train loss: [0.3933964]
batch 65 train loss: [0.43811876]
batch 66 train loss: [0.44533476]
batch 67 train loss: [0.43197495]
batch 68 train loss: [0.35620958]
batch 69 train loss: [0.42228073]
batch 70 train loss: [0.37724528]
batch 71 train loss: [0.5289328]
batch 72 train loss: [0.33834824]
batch 73 train loss: [0.45982078]
batch 74 train loss: [0.4253231]
batch 75 train loss: [0.40400591]
batch 76 train loss: [0.40758058]
batch 77 train loss: [0.4126951]
batch 78 train loss: [0.46728554]
batch 79 train loss: [0.4478116]
batch 80 train loss: [0.39052483]
batch 81 train loss: [0.40913174]
batch 82 train loss: [0.4269282]
batch 83 train loss: [0.35888132]
batch 84 train loss: [0.523975]
batch 85 train loss: [0.45825237]
batch 86 train loss: [0.429312]
batch 87 train loss: [0.3793736]
batch 88 train loss: [0.5327491]
batch 89 train loss: [0.3465422]
batch 90 train loss: [0.3960649]
batch 91 train loss: [0.43162277]
batch 92 train loss: [0.40039808]
batch 93 train loss: [0.3638098]
batch 94 train loss: [0.37994727]
batch 95 train loss: [0.45801818]
batch 96 train loss: [0.51124585]
batch 97 train loss: [0.34197778]
batch 98 train loss: [0.39464793]
batch 99 train loss: [0.5317738]
epoch 1 mean train loss: [0.41828796]
Epoch 1/400=>  train_loss: [0.41828796], iou: nan, cd: 2.5050966176351457, test_mse: [0.3857209]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.27882865]
batch 1 train loss: [0.3996433]
batch 2 train loss: [0.46242338]
batch 3 train loss: [0.37534326]
batch 4 train loss: [0.38672072]
batch 5 train loss: [0.3320648]
batch 6 train loss: [0.45079926]
batch 7 train loss: [0.37734196]
batch 8 train loss: [0.31991857]
batch 9 train loss: [0.36713687]
batch 10 train loss: [0.36681345]
batch 11 train loss: [0.3725348]
batch 12 train loss: [0.4064535]
batch 13 train loss: [0.3911127]
batch 14 train loss: [0.37207207]
batch 15 train loss: [0.3668677]
batch 16 train loss: [0.38323602]
batch 17 train loss: [0.31132373]
batch 18 train loss: [0.40677103]
batch 19 train loss: [0.33782014]
batch 20 train loss: [0.376268]
batch 21 train loss: [0.3266328]
batch 22 train loss: [0.38204977]
batch 23 train loss: [0.3528635]
batch 24 train loss: [0.35910073]
batch 25 train loss: [0.3655048]
batch 26 train loss: [0.35068446]
batch 27 train loss: [0.31331438]
batch 28 train loss: [0.37948692]
batch 29 train loss: [0.5613498]
batch 30 train loss: [0.46945673]
batch 31 train loss: [0.4181639]
batch 32 train loss: [0.3250924]
batch 33 train loss: [0.33437797]
batch 34 train loss: [0.3988348]
batch 35 train loss: [0.35524586]
batch 36 train loss: [0.42379194]
batch 37 train loss: [0.3060168]
batch 38 train loss: [0.41575116]
batch 39 train loss: [0.2884056]
batch 40 train loss: [0.36345834]
batch 41 train loss: [0.37461928]
batch 42 train loss: [0.3793331]
batch 43 train loss: [0.32361636]
batch 44 train loss: [0.4308925]
batch 45 train loss: [0.417975]
batch 46 train loss: [0.30669218]
batch 47 train loss: [0.47077236]
batch 48 train loss: [0.3905901]
batch 49 train loss: [0.45175385]
batch 50 train loss: [0.3243534]
batch 51 train loss: [0.38755742]
batch 52 train loss: [0.33625427]
batch 53 train loss: [0.3948042]
batch 54 train loss: [0.42786628]
batch 55 train loss: [0.33205777]
batch 56 train loss: [0.33227915]
batch 57 train loss: [0.38404807]
batch 58 train loss: [0.374514]
batch 59 train loss: [0.45881075]
batch 60 train loss: [0.38656738]
batch 61 train loss: [0.3233169]
batch 62 train loss: [0.3519308]
batch 63 train loss: [0.36468455]
batch 64 train loss: [0.29679462]
batch 65 train loss: [0.2847656]
batch 66 train loss: [0.3561961]
batch 67 train loss: [0.36523184]
batch 68 train loss: [0.2794922]
batch 69 train loss: [0.35811135]
batch 70 train loss: [0.42182487]
batch 71 train loss: [0.3363937]
batch 72 train loss: [0.42350712]
batch 73 train loss: [0.39334312]
batch 74 train loss: [0.4114005]
batch 75 train loss: [0.37013188]
batch 76 train loss: [0.36165726]
batch 77 train loss: [0.44030315]
batch 78 train loss: [0.41808358]
batch 79 train loss: [0.33853978]
batch 80 train loss: [0.3514349]
batch 81 train loss: [0.40539968]
batch 82 train loss: [0.38917878]
batch 83 train loss: [0.34074438]
batch 84 train loss: [0.27517432]
batch 85 train loss: [0.42539927]
batch 86 train loss: [0.35906893]
batch 87 train loss: [0.30598816]
batch 88 train loss: [0.44329292]
batch 89 train loss: [0.388427]
batch 90 train loss: [0.43058968]
batch 91 train loss: [0.44458917]
batch 92 train loss: [0.4421752]
batch 93 train loss: [0.40055588]
batch 94 train loss: [0.38382763]
batch 95 train loss: [0.3419338]
batch 96 train loss: [0.3866028]
batch 97 train loss: [0.35588682]
batch 98 train loss: [0.41331628]
batch 99 train loss: [0.289183]
epoch 2 mean train loss: [0.3748492]
Epoch 2/400=>  train_loss: [0.3748492], iou: nan, cd: 2.4232963174497546, test_mse: [0.36016884]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.3140411]
batch 1 train loss: [0.34958166]
batch 2 train loss: [0.36624324]
batch 3 train loss: [0.3651872]
batch 4 train loss: [0.34423336]
batch 5 train loss: [0.2876631]
batch 6 train loss: [0.30442593]
batch 7 train loss: [0.3652784]
batch 8 train loss: [0.38533637]
batch 9 train loss: [0.38047582]
batch 10 train loss: [0.3848666]
batch 11 train loss: [0.29427993]
batch 12 train loss: [0.32707012]
batch 13 train loss: [0.38048854]
batch 14 train loss: [0.3749027]
batch 15 train loss: [0.3599924]
batch 16 train loss: [0.2789799]
batch 17 train loss: [0.35686138]
batch 18 train loss: [0.35685322]
batch 19 train loss: [0.28799185]
batch 20 train loss: [0.2986823]
batch 21 train loss: [0.3132653]
batch 22 train loss: [0.29580998]
batch 23 train loss: [0.27632457]
batch 24 train loss: [0.31213066]
batch 25 train loss: [0.3738488]
batch 26 train loss: [0.35141996]
batch 27 train loss: [0.37538725]
batch 28 train loss: [0.34722263]
batch 29 train loss: [0.3178842]
batch 30 train loss: [0.31583205]
batch 31 train loss: [0.29792687]
batch 32 train loss: [0.3528191]
batch 33 train loss: [0.3120376]
batch 34 train loss: [0.33246222]
batch 35 train loss: [0.29460776]
batch 36 train loss: [0.34518787]
batch 37 train loss: [0.35872737]
batch 38 train loss: [0.34488553]
batch 39 train loss: [0.30808163]
batch 40 train loss: [0.34079534]
batch 41 train loss: [0.39774126]
batch 42 train loss: [0.40616953]
batch 43 train loss: [0.36704585]
batch 44 train loss: [0.27213255]
batch 45 train loss: [0.29080653]
batch 46 train loss: [0.32277763]
batch 47 train loss: [0.40504125]
batch 48 train loss: [0.35275996]
batch 49 train loss: [0.35850507]
batch 50 train loss: [0.38037565]
batch 51 train loss: [0.3136962]
batch 52 train loss: [0.26584348]
batch 53 train loss: [0.31474692]
batch 54 train loss: [0.37462094]
batch 55 train loss: [0.39876646]
batch 56 train loss: [0.36856142]
batch 57 train loss: [0.35038182]
batch 58 train loss: [0.41622576]
batch 59 train loss: [0.30518025]
batch 60 train loss: [0.42093536]
batch 61 train loss: [0.2900055]
batch 62 train loss: [0.37218538]
batch 63 train loss: [0.35761866]
batch 64 train loss: [0.3706132]
batch 65 train loss: [0.4229867]
batch 66 train loss: [0.35428947]
batch 67 train loss: [0.28132445]
batch 68 train loss: [0.3912228]
batch 69 train loss: [0.37462214]
batch 70 train loss: [0.41655555]
batch 71 train loss: [0.3625997]
batch 72 train loss: [0.3327747]
batch 73 train loss: [0.32057348]
batch 74 train loss: [0.37671813]
batch 75 train loss: [0.34993628]
batch 76 train loss: [0.3516566]
batch 77 train loss: [0.4151303]
batch 78 train loss: [0.42089453]
batch 79 train loss: [0.31989798]
batch 80 train loss: [0.3796877]
batch 81 train loss: [0.3268206]
batch 82 train loss: [0.39408225]
batch 83 train loss: [0.2574584]
batch 84 train loss: [0.31817308]
batch 85 train loss: [0.37583572]
batch 86 train loss: [0.28976727]
batch 87 train loss: [0.32947907]
batch 88 train loss: [0.37927243]
batch 89 train loss: [0.33860466]
batch 90 train loss: [0.34185207]
batch 91 train loss: [0.32525334]
batch 92 train loss: [0.3345885]
batch 93 train loss: [0.3130909]
batch 94 train loss: [0.32166606]
batch 95 train loss: [0.33445886]
batch 96 train loss: [0.36979625]
batch 97 train loss: [0.22341244]
batch 98 train loss: [0.3458885]
batch 99 train loss: [0.37872714]
epoch 3 mean train loss: [0.34371924]
Epoch 3/400=>  train_loss: [0.34371924], iou: nan, cd: 2.418312604172814, test_mse: [0.36264706]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.38992304]
batch 1 train loss: [0.3113495]
batch 2 train loss: [0.23438494]
batch 3 train loss: [0.32617772]
batch 4 train loss: [0.26451182]
batch 5 train loss: [0.3739646]
batch 6 train loss: [0.31849718]
batch 7 train loss: [0.29537874]
batch 8 train loss: [0.36154884]
batch 9 train loss: [0.33341214]
batch 10 train loss: [0.2896143]
batch 11 train loss: [0.3036219]
batch 12 train loss: [0.30728337]
batch 13 train loss: [0.30000377]
batch 14 train loss: [0.28566724]
batch 15 train loss: [0.36152303]
batch 16 train loss: [0.38430032]
batch 17 train loss: [0.34043017]
batch 18 train loss: [0.31938854]
batch 19 train loss: [0.27564323]
batch 20 train loss: [0.26013088]
batch 21 train loss: [0.31035244]
batch 22 train loss: [0.26272362]
batch 23 train loss: [0.31531656]
batch 24 train loss: [0.29853994]
batch 25 train loss: [0.27055892]
batch 26 train loss: [0.31854832]
batch 27 train loss: [0.36798552]
batch 28 train loss: [0.32458296]
batch 29 train loss: [0.27509257]
batch 30 train loss: [0.34120026]
batch 31 train loss: [0.31542945]
batch 32 train loss: [0.28931522]
batch 33 train loss: [0.20683317]
batch 34 train loss: [0.3239309]
batch 35 train loss: [0.3247082]
batch 36 train loss: [0.36698264]
batch 37 train loss: [0.2975151]
batch 38 train loss: [0.29926193]
batch 39 train loss: [0.31529984]
batch 40 train loss: [0.3329353]
batch 41 train loss: [0.38871807]
batch 42 train loss: [0.3712323]
batch 43 train loss: [0.29168662]
batch 44 train loss: [0.32574505]
batch 45 train loss: [0.38391516]
batch 46 train loss: [0.31095386]
batch 47 train loss: [0.29184473]
batch 48 train loss: [0.33825514]
batch 49 train loss: [0.33955202]
batch 50 train loss: [0.3664569]
batch 51 train loss: [0.36029556]
batch 52 train loss: [0.29172164]
batch 53 train loss: [0.34791952]
batch 54 train loss: [0.29987788]
batch 55 train loss: [0.29344803]
batch 56 train loss: [0.3657943]
batch 57 train loss: [0.3367818]
batch 58 train loss: [0.34257856]
batch 59 train loss: [0.27776867]
batch 60 train loss: [0.28763962]
batch 61 train loss: [0.3964073]
batch 62 train loss: [0.36267716]
batch 63 train loss: [0.27709395]
batch 64 train loss: [0.3647956]
batch 65 train loss: [0.34960076]
batch 66 train loss: [0.31832632]
batch 67 train loss: [0.33651417]
batch 68 train loss: [0.35094342]
batch 69 train loss: [0.3686215]
batch 70 train loss: [0.34822398]
batch 71 train loss: [0.38838485]
batch 72 train loss: [0.27708295]
batch 73 train loss: [0.26280314]
batch 74 train loss: [0.34823543]
batch 75 train loss: [0.33759987]
batch 76 train loss: [0.34528777]
batch 77 train loss: [0.35054198]
batch 78 train loss: [0.4384741]
batch 79 train loss: [0.34565216]
batch 80 train loss: [0.24353497]
batch 81 train loss: [0.3115657]
batch 82 train loss: [0.3865781]
batch 83 train loss: [0.3158307]
batch 84 train loss: [0.271356]
batch 85 train loss: [0.3126777]
batch 86 train loss: [0.287353]
batch 87 train loss: [0.3295502]
batch 88 train loss: [0.3223617]
batch 89 train loss: [0.3403424]
batch 90 train loss: [0.31805333]
batch 91 train loss: [0.3060893]
batch 92 train loss: [0.35622483]
batch 93 train loss: [0.2703982]
batch 94 train loss: [0.33451805]
batch 95 train loss: [0.23217346]
batch 96 train loss: [0.30023175]
batch 97 train loss: [0.25720924]
batch 98 train loss: [0.420962]
batch 99 train loss: [0.35142806]
epoch 4 mean train loss: [0.32241756]
Epoch 4/400=>  train_loss: [0.32241756], iou: nan, cd: 2.3200125011329265, test_mse: [0.3416651]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.2885532]
batch 1 train loss: [0.26053655]
batch 2 train loss: [0.3082902]
batch 3 train loss: [0.32944512]
batch 4 train loss: [0.29262897]
batch 5 train loss: [0.35314956]
batch 6 train loss: [0.2602963]
batch 7 train loss: [0.22959621]
batch 8 train loss: [0.2621935]
batch 9 train loss: [0.3369687]
batch 10 train loss: [0.32672513]
batch 11 train loss: [0.26856327]
batch 12 train loss: [0.35286063]
batch 13 train loss: [0.28088826]
batch 14 train loss: [0.35382426]
batch 15 train loss: [0.27102464]
batch 16 train loss: [0.36731568]
batch 17 train loss: [0.28760844]
batch 18 train loss: [0.28272578]
batch 19 train loss: [0.32459912]
batch 20 train loss: [0.25300446]
batch 21 train loss: [0.31393003]
batch 22 train loss: [0.2988535]
batch 23 train loss: [0.27267197]
batch 24 train loss: [0.35495508]
batch 25 train loss: [0.32376632]
batch 26 train loss: [0.31757224]
batch 27 train loss: [0.29656404]
batch 28 train loss: [0.3386079]
batch 29 train loss: [0.27090347]
batch 30 train loss: [0.31726736]
batch 31 train loss: [0.31346834]
batch 32 train loss: [0.3436763]
batch 33 train loss: [0.2210626]
batch 34 train loss: [0.24520783]
batch 35 train loss: [0.32471487]
batch 36 train loss: [0.29829642]
batch 37 train loss: [0.34307793]
batch 38 train loss: [0.27962554]
batch 39 train loss: [0.25849137]
batch 40 train loss: [0.2882402]
batch 41 train loss: [0.26079002]
batch 42 train loss: [0.2386374]
batch 43 train loss: [0.22471035]
batch 44 train loss: [0.35114667]
batch 45 train loss: [0.32304323]
batch 46 train loss: [0.33377388]
batch 47 train loss: [0.31189713]
batch 48 train loss: [0.31274545]
batch 49 train loss: [0.2627966]
batch 50 train loss: [0.33866817]
batch 51 train loss: [0.32759315]
batch 52 train loss: [0.40051195]
batch 53 train loss: [0.3870735]
batch 54 train loss: [0.29097024]
batch 55 train loss: [0.30591497]
batch 56 train loss: [0.3337489]
batch 57 train loss: [0.3172313]
batch 58 train loss: [0.25900057]
batch 59 train loss: [0.30607414]
batch 60 train loss: [0.3203228]
batch 61 train loss: [0.25566882]
batch 62 train loss: [0.34540203]
batch 63 train loss: [0.31054425]
batch 64 train loss: [0.31400573]
batch 65 train loss: [0.3344442]
batch 66 train loss: [0.29488713]
batch 67 train loss: [0.33474067]
batch 68 train loss: [0.2980499]
batch 69 train loss: [0.37907]
batch 70 train loss: [0.28690684]
batch 71 train loss: [0.29702708]
batch 72 train loss: [0.3018746]
batch 73 train loss: [0.3213303]
batch 74 train loss: [0.2784307]
batch 75 train loss: [0.2999782]
batch 76 train loss: [0.36024135]
batch 77 train loss: [0.26559436]
batch 78 train loss: [0.37475964]
batch 79 train loss: [0.33894327]
batch 80 train loss: [0.2996641]
batch 81 train loss: [0.28293568]
batch 82 train loss: [0.28303647]
batch 83 train loss: [0.31301773]
batch 84 train loss: [0.3004388]
batch 85 train loss: [0.24448372]
batch 86 train loss: [0.23396035]
batch 87 train loss: [0.33299428]
batch 88 train loss: [0.28722927]
batch 89 train loss: [0.31835574]
batch 90 train loss: [0.3483704]
batch 91 train loss: [0.29720703]
batch 92 train loss: [0.2541689]
batch 93 train loss: [0.35127795]
batch 94 train loss: [0.23934963]
batch 95 train loss: [0.41660446]
batch 96 train loss: [0.30546054]
batch 97 train loss: [0.31139502]
batch 98 train loss: [0.26229134]
batch 99 train loss: [0.3056015]
epoch 5 mean train loss: [0.30498144]
Epoch 5/400=>  train_loss: [0.30498144], iou: nan, cd: 2.4564311020260585, test_mse: [0.3695639]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.33614072]
batch 1 train loss: [0.27171266]
batch 2 train loss: [0.29472467]
batch 3 train loss: [0.2818853]
batch 4 train loss: [0.23137443]
batch 5 train loss: [0.28196472]
batch 6 train loss: [0.30279014]
batch 7 train loss: [0.36780566]
batch 8 train loss: [0.2365716]
batch 9 train loss: [0.21321657]
batch 10 train loss: [0.28818887]
batch 11 train loss: [0.27543545]
batch 12 train loss: [0.2628253]
batch 13 train loss: [0.2765149]
batch 14 train loss: [0.21194656]
batch 15 train loss: [0.33871782]
batch 16 train loss: [0.33362758]
batch 17 train loss: [0.38446605]
batch 18 train loss: [0.27031955]
batch 19 train loss: [0.24935037]
batch 20 train loss: [0.24240614]
batch 21 train loss: [0.2201241]
batch 22 train loss: [0.24705195]
batch 23 train loss: [0.2873977]
batch 24 train loss: [0.21159668]
batch 25 train loss: [0.26808643]
batch 26 train loss: [0.30738804]
batch 27 train loss: [0.2353817]
batch 28 train loss: [0.27291095]
batch 29 train loss: [0.29290193]
batch 30 train loss: [0.29437232]
batch 31 train loss: [0.29515362]
batch 32 train loss: [0.33750644]
batch 33 train loss: [0.2980392]
batch 34 train loss: [0.26307067]
batch 35 train loss: [0.30688798]
batch 36 train loss: [0.34149662]
batch 37 train loss: [0.24394692]
batch 38 train loss: [0.3324246]
batch 39 train loss: [0.21315314]
batch 40 train loss: [0.24751028]
batch 41 train loss: [0.30670387]
batch 42 train loss: [0.25649318]
batch 43 train loss: [0.3029116]
batch 44 train loss: [0.33288583]
batch 45 train loss: [0.22274666]
batch 46 train loss: [0.2757423]
batch 47 train loss: [0.29418412]
batch 48 train loss: [0.25584573]
batch 49 train loss: [0.21689554]
batch 50 train loss: [0.23899628]
batch 51 train loss: [0.30383435]
batch 52 train loss: [0.33677247]
batch 53 train loss: [0.260406]
batch 54 train loss: [0.29023287]
batch 55 train loss: [0.23397848]
batch 56 train loss: [0.24551627]
batch 57 train loss: [0.3320443]
batch 58 train loss: [0.29258674]
batch 59 train loss: [0.3180829]
batch 60 train loss: [0.27184358]
batch 61 train loss: [0.21329454]
batch 62 train loss: [0.22933312]
batch 63 train loss: [0.27678668]
batch 64 train loss: [0.24694708]
batch 65 train loss: [0.30708027]
batch 66 train loss: [0.3475921]
batch 67 train loss: [0.3319882]
batch 68 train loss: [0.31292352]
batch 69 train loss: [0.28766367]
batch 70 train loss: [0.27960524]
batch 71 train loss: [0.25965983]
batch 72 train loss: [0.28179613]
batch 73 train loss: [0.29568475]
batch 74 train loss: [0.28719246]
batch 75 train loss: [0.2992488]
batch 76 train loss: [0.3077639]
batch 77 train loss: [0.25460204]
batch 78 train loss: [0.2855171]
batch 79 train loss: [0.34095594]
batch 80 train loss: [0.32645708]
batch 81 train loss: [0.27797675]
batch 82 train loss: [0.38310117]
batch 83 train loss: [0.28745025]
batch 84 train loss: [0.28667656]
batch 85 train loss: [0.30034247]
batch 86 train loss: [0.27427492]
batch 87 train loss: [0.273166]
batch 88 train loss: [0.35039276]
batch 89 train loss: [0.30160925]
batch 90 train loss: [0.34011862]
batch 91 train loss: [0.31736574]
batch 92 train loss: [0.3168236]
batch 93 train loss: [0.30435893]
batch 94 train loss: [0.25508267]
batch 95 train loss: [0.28907332]
batch 96 train loss: [0.3154441]
batch 97 train loss: [0.294737]
batch 98 train loss: [0.36466065]
batch 99 train loss: [0.3621162]
epoch 6 mean train loss: [0.28723955]
WAKE SLEEP ITERATION 7
Inferring cad batch: 0
Inferring cad batch: 1
Inferring cad batch: 2
Inferring cad batch: 3
Inferring cad batch: 4
Inferring cad batch: 5
Inferring cad batch: 6
Inferring cad batch: 7
Inferring cad batch: 8
Inferring cad batch: 9
Inferring cad batch: 10
Inferring cad batch: 11
Inferring cad batch: 12
Inferring cad batch: 13
Inferring cad batch: 14
Inferring cad batch: 15
Inferring cad batch: 16
Inferring cad batch: 17
Inferring cad batch: 18
Inferring cad batch: 19
Inferring cad batch: 20
Inferring cad batch: 21
Inferring cad batch: 22
Inferring cad batch: 23
Inferring cad batch: 24
Inferring cad batch: 25
Inferring cad batch: 26
Inferring cad batch: 27
Inferring cad batch: 28
Inferring cad batch: 29
Inferring cad batch: 30
Inferring cad batch: 31
Inferring cad batch: 32
Inferring cad average chamfer distance: 1.3729466980431846
0.6064909677570253 1.3729466980431846
generator epoch 0 loss: 1.0118791617257255                 accuracy: 0.8885714411735535
generator epoch 1 loss: 0.9510693516322545                 accuracy: 0.9064285755157471
generator epoch 2 loss: 0.9251726143973215                 accuracy: 0.8828571438789368
generator epoch 3 loss: 0.9087302943638392                 accuracy: 0.9021428227424622
generator epoch 4 loss: 0.900173734828404                 accuracy: 0.9007142782211304
generator epoch 5 loss: 0.8895518450055804                 accuracy: 0.9064285755157471
generator epoch 6 loss: 0.8787933314732143                 accuracy: 0.9128571152687073
generator epoch 7 loss: 0.8728269731794085                 accuracy: 0.925000011920929
generator epoch 8 loss: 0.8682473798479353                 accuracy: 0.9014285802841187
generator epoch 9 loss: 0.8646786315917969                 accuracy: 0.9071428179740906
generator epoch 10 loss: 0.8572200483049666                 accuracy: 0.9164285659790039
generator epoch 11 loss: 0.8535462672642299                 accuracy: 0.9228571057319641
generator epoch 12 loss: 0.8500809823172433                 accuracy: 0.9278571605682373
generator epoch 13 loss: 0.8482162475585937                 accuracy: 0.9214285612106323
generator epoch 14 loss: 0.8425986894880022                 accuracy: 0.9228571057319641
generator epoch 15 loss: 0.8413775050571987                 accuracy: 0.9221428632736206
generator epoch 16 loss: 0.8384156834193638                 accuracy: 0.9164285659790039
generator epoch 17 loss: 0.8403389718191965                 accuracy: 0.9257142543792725
generator epoch 18 loss: 0.8328978594098773                 accuracy: 0.925000011920929
generator epoch 19 loss: 0.8302625008719308                 accuracy: 0.9092857241630554
generator epoch 20 loss: 0.8319740033830915                 accuracy: 0.9071428179740906
generator epoch 21 loss: 0.8290259460449219                 accuracy: 0.9192857146263123
generator epoch 22 loss: 0.8305580235072545                 accuracy: 0.9242857098579407
generator epoch 23 loss: 0.8303696507045201                 accuracy: 0.9364285469055176
generator epoch 24 loss: 0.8243553911481585                 accuracy: 0.9121428728103638
generator epoch 25 loss: 0.8255373570033482                 accuracy: 0.8992857336997986
generator epoch 26 loss: 0.8220966291155134                 accuracy: 0.9242857098579407
generator epoch 27 loss: 0.8206660749162946                 accuracy: 0.904285728931427
generator epoch 28 loss: 0.8203049726213728                 accuracy: 0.9242857098579407
generator epoch 29 loss: 0.8204994785853794                 accuracy: 0.9142857193946838
generator epoch 30 loss: 0.8182436976841518                 accuracy: 0.925000011920929
generator epoch 31 loss: 0.8162648515973773                 accuracy: 0.9342857003211975
generator epoch 32 loss: 0.8193907156808036                 accuracy: 0.9121428728103638
generator epoch 33 loss: 0.8178025713239397                 accuracy: 0.9149999618530273
generator epoch 34 loss: 0.817588809640067                 accuracy: 0.9350000023841858
generator epoch 35 loss: 0.8062104945591518                 accuracy: 0.9264285564422607
generator epoch 36 loss: 0.8128479125976562                 accuracy: 0.925000011920929
generator epoch 37 loss: 0.8124899605887277                 accuracy: 0.9292857050895691
generator epoch 38 loss: 0.8059869018554687                 accuracy: 0.9092857241630554
generator epoch 39 loss: 0.815392822265625                 accuracy: 0.9221428632736206
generator epoch 40 loss: 0.8068023428780692                 accuracy: 0.918571412563324
generator epoch 41 loss: 0.8080154397147042                 accuracy: 0.9135714173316956
generator epoch 42 loss: 0.8061953011648996                 accuracy: 0.9085714221000671
generator epoch 43 loss: 0.8008817557198661                 accuracy: 0.9228571057319641
generator epoch 44 loss: 0.8070209594726563                 accuracy: 0.920714259147644
generator epoch 45 loss: 0.8066965916224889                 accuracy: 0.927142858505249
generator epoch 46 loss: 0.8009822910853794                 accuracy: 0.9264285564422607
generator epoch 47 loss: 0.8051229989188058                 accuracy: 0.9314285516738892
generator epoch 48 loss: 0.802936190359933                 accuracy: 0.9278571605682373
generator epoch 49 loss: 0.804958216203962                 accuracy: 0.9214285612106323
generator epoch 50 loss: 0.7975912867954799                 accuracy: 0.9285714030265808
generator epoch 51 loss: 0.8035329982212611                 accuracy: 0.9342857003211975
generator epoch 52 loss: 0.7959705043247768                 accuracy: 0.9192857146263123
generator epoch 53 loss: 0.79895201285226                 accuracy: 0.9099999666213989
generator epoch 54 loss: 0.8048502205984933                 accuracy: 0.9407142996788025
generator epoch 55 loss: 0.7931370553152902                 accuracy: 0.927142858505249
generator epoch 56 loss: 0.796876984514509                 accuracy: 0.9292857050895691
generator epoch 57 loss: 0.7980784894670759                 accuracy: 0.9357143044471741
generator epoch 58 loss: 0.7944578125                 accuracy: 0.9471428394317627
generator epoch 59 loss: 0.797185071672712                 accuracy: 0.9314285516738892
generator epoch 60 loss: 0.7928434517996652                 accuracy: 0.9221428632736206
generator epoch 61 loss: 0.7988890860421317                 accuracy: 0.9257142543792725
generator epoch 62 loss: 0.792807819039481                 accuracy: 0.9328571557998657
generator epoch 63 loss: 0.7938709289550782                 accuracy: 0.9300000071525574
generator epoch 64 loss: 0.7894187626429966                 accuracy: 0.9350000023841858
generator epoch 65 loss: 0.795277290562221                 accuracy: 0.9107142686843872
generator epoch 66 loss: 0.7977158525739397                 accuracy: 0.9235714077949524
generator epoch 67 loss: 0.7938423924037389                 accuracy: 0.9342857003211975
generator epoch 68 loss: 0.7914868225097657                 accuracy: 0.9321428537368774
generator epoch 69 loss: 0.7844304146902902                 accuracy: 0.9300000071525574
generator epoch 70 loss: 0.7916684404645647                 accuracy: 0.9278571605682373
generator epoch 71 loss: 0.7941363612583705                 accuracy: 0.9307142496109009
generator epoch 72 loss: 0.7878993072509766                 accuracy: 0.9300000071525574
generator epoch 73 loss: 0.7868707611083985                 accuracy: 0.9300000071525574
generator epoch 74 loss: 0.7889109915597098                 accuracy: 0.9328571557998657
generator epoch 75 loss: 0.78681689453125                 accuracy: 0.9321428537368774
generator epoch 76 loss: 0.7918885624476841                 accuracy: 0.9164285659790039
generator epoch 77 loss: 0.7868644321986608                 accuracy: 0.9228571057319641
generator epoch 78 loss: 0.7886877301897322                 accuracy: 0.949999988079071
generator epoch 79 loss: 0.7887930563790457                 accuracy: 0.9428571462631226
generator epoch 80 loss: 0.786798792375837                 accuracy: 0.9392856955528259
generator epoch 81 loss: 0.7887138929094587                 accuracy: 0.927142858505249
generator epoch 82 loss: 0.7904503958565848                 accuracy: 0.9221428632736206
generator epoch 83 loss: 0.7864064614432199                 accuracy: 0.9264285564422607
generator epoch 84 loss: 0.7880354422433036                 accuracy: 0.9321428537368774
generator epoch 85 loss: 0.7847840959821428                 accuracy: 0.927142858505249
generator epoch 86 loss: 0.7882919041224888                 accuracy: 0.9364285469055176
generator epoch 87 loss: 0.7815378526960101                 accuracy: 0.9307142496109009
generator epoch 88 loss: 0.7772065141950335                 accuracy: 0.9328571557998657
generator epoch 89 loss: 0.7803163609095982                 accuracy: 0.9214285612106323
generator epoch 90 loss: 0.7817451363699777                 accuracy: 0.9242857098579407
generator epoch 91 loss: 0.7844993198939733                 accuracy: 0.9264285564422607
generator epoch 92 loss: 0.7859016906738281                 accuracy: 0.9464285373687744
generator epoch 93 loss: 0.7844140725272042                 accuracy: 0.9285714030265808
generator epoch 94 loss: 0.7801091570172991                 accuracy: 0.9371428489685059
generator epoch 95 loss: 0.7835379433768136                 accuracy: 0.9392856955528259
generator epoch 96 loss: 0.778201937866211                 accuracy: 0.9314285516738892
generator epoch 97 loss: 0.7780493647984096                 accuracy: 0.9321428537368774
generator epoch 98 loss: 0.7810698800223215                 accuracy: 0.949999988079071
generator epoch 99 loss: 0.78123740234375                 accuracy: 0.9428571462631226
generator epoch 100 loss: 0.7807176256452288                 accuracy: 0.9257142543792725
generator epoch 101 loss: 0.7784004778180803                 accuracy: 0.941428542137146
generator epoch 102 loss: 0.7833609104701451                 accuracy: 0.9357143044471741
generator epoch 103 loss: 0.7798008714948381                 accuracy: 0.9200000166893005
generator epoch 104 loss: 0.7850818232945034                 accuracy: 0.9342857003211975
generator epoch 105 loss: 0.7787216321672712                 accuracy: 0.941428542137146
generator epoch 106 loss: 0.7811999263218471                 accuracy: 0.9328571557998657
generator epoch 107 loss: 0.7809341064453125                 accuracy: 0.9342857003211975
generator epoch 108 loss: 0.7824523960658483                 accuracy: 0.9421428442001343
generator epoch 109 loss: 0.7787773088727679                 accuracy: 0.9264285564422607
generator epoch 110 loss: 0.7799521449497768                 accuracy: 0.9464285373687744
generator epoch 111 loss: 0.7774065403529576                 accuracy: 0.9278571605682373
generator epoch 112 loss: 0.7769150700160435                 accuracy: 0.947857141494751
generator epoch 113 loss: 0.7792702065604074                 accuracy: 0.9357143044471741
generator epoch 114 loss: 0.7773434718540737                 accuracy: 0.9335713982582092
generator epoch 115 loss: 0.7833156664167131                 accuracy: 0.9321428537368774
generator epoch 116 loss: 0.7746103376116071                 accuracy: 0.9314285516738892
generator epoch 117 loss: 0.7752606846400669                 accuracy: 0.9228571057319641
generator epoch 118 loss: 0.7761345319475447                 accuracy: 0.9221428632736206
generator epoch 119 loss: 0.7752139038085938                 accuracy: 0.9357143044471741
generator epoch 120 loss: 0.7856706939697266                 accuracy: 0.9300000071525574
generator epoch 121 loss: 0.7770850285121372                 accuracy: 0.9314285516738892
generator epoch 122 loss: 0.7748425384521485                 accuracy: 0.9407142996788025
generator epoch 123 loss: 0.775572140938895                 accuracy: 0.9407142996788025
generator epoch 124 loss: 0.7738865565708706                 accuracy: 0.941428542137146
generator epoch 125 loss: 0.7738220123291015                 accuracy: 0.9307142496109009
generator epoch 126 loss: 0.7804233564104353                 accuracy: 0.9535714387893677
generator epoch 127 loss: 0.7770950243268694                 accuracy: 0.9357143044471741
generator epoch 128 loss: 0.7767109466552734                 accuracy: 0.9357143044471741
generator epoch 129 loss: 0.7872954066685268                 accuracy: 0.9307142496109009
generator epoch 130 loss: 0.7760072030203683                 accuracy: 0.9449999928474426
generator epoch 131 loss: 0.7738576093401228                 accuracy: 0.9242857098579407
generator epoch 132 loss: 0.7712197723388672                 accuracy: 0.9342857003211975
generator epoch 133 loss: 0.771313398524693                 accuracy: 0.9364285469055176
generator epoch 134 loss: 0.7719513262067522                 accuracy: 0.9228571057319641
generator epoch 135 loss: 0.7721558384486608                 accuracy: 0.9307142496109009
generator epoch 136 loss: 0.7768983542306083                 accuracy: 0.949999988079071
generator epoch 137 loss: 0.7724391213553292                 accuracy: 0.9357143044471741
generator epoch 138 loss: 0.7720155857631138                 accuracy: 0.9428571462631226
generator epoch 139 loss: 0.7760395451136998                 accuracy: 0.956428587436676
generator epoch 140 loss: 0.7741986790248326                 accuracy: 0.9485714435577393
generator epoch 141 loss: 0.7657197121756417                 accuracy: 0.947857141494751
generator epoch 142 loss: 0.7764719717843191                 accuracy: 0.925000011920929
generator epoch 143 loss: 0.7690804683140346                 accuracy: 0.9435713887214661
generator epoch 144 loss: 0.7720492680140904                 accuracy: 0.9392856955528259
generator epoch 145 loss: 0.7687874812534877                 accuracy: 0.9421428442001343
generator epoch 146 loss: 0.7722996194022043                 accuracy: 0.9335713982582092
generator epoch 147 loss: 0.7700577174595424                 accuracy: 0.9342857003211975
generator epoch 148 loss: 0.771947361101423                 accuracy: 0.9328571557998657
generator epoch 149 loss: 0.7719843963623046                 accuracy: 0.9321428537368774
generator epoch 150 loss: 0.7705544756208147                 accuracy: 0.9421428442001343
generator epoch 151 loss: 0.7634543204171317                 accuracy: 0.9328571557998657
generator epoch 152 loss: 0.7705878762381417                 accuracy: 0.9357143044471741
generator epoch 153 loss: 0.7672111541748047                 accuracy: 0.9364285469055176
generator epoch 154 loss: 0.765118332345145                 accuracy: 0.9364285469055176
generator epoch 155 loss: 0.7690889530726841                 accuracy: 0.9364285469055176
generator epoch 156 loss: 0.7726911834716796                 accuracy: 0.9357143044471741
generator epoch 157 loss: 0.7694776920863561                 accuracy: 0.9421428442001343
generator epoch 158 loss: 0.7707776310511998                 accuracy: 0.9314285516738892
generator epoch 159 loss: 0.7686685529436383                 accuracy: 0.941428542137146
generator epoch 160 loss: 0.7639444750104631                 accuracy: 0.920714259147644
generator epoch 161 loss: 0.7687674281529018                 accuracy: 0.9385713934898376
generator epoch 162 loss: 0.7683341068812779                 accuracy: 0.9328571557998657
generator epoch 163 loss: 0.7665909349714006                 accuracy: 0.9257142543792725
generator epoch 164 loss: 0.7721199537004744                 accuracy: 0.9300000071525574
generator epoch 165 loss: 0.7669696986607143                 accuracy: 0.9335713982582092
generator epoch 166 loss: 0.7683298701695034                 accuracy: 0.9457142949104309
generator epoch 167 loss: 0.765633498273577                 accuracy: 0.9492856860160828
generator epoch 168 loss: 0.7645741324288504                 accuracy: 0.9514285326004028
generator epoch 169 loss: 0.7666216055733817                 accuracy: 0.9300000071525574
generator epoch 170 loss: 0.7660592363630022                 accuracy: 0.9507142901420593
generator epoch 171 loss: 0.7649467176164899                 accuracy: 0.9364285469055176
generator epoch 172 loss: 0.766967431640625                 accuracy: 0.9464285373687744
generator epoch 173 loss: 0.7615239100864956                 accuracy: 0.9342857003211975
generator epoch 174 loss: 0.7688787466866629                 accuracy: 0.9335713982582092
generator epoch 175 loss: 0.7672867104666574                 accuracy: 0.9328571557998657
generator epoch 176 loss: 0.7649653642926897                 accuracy: 0.9385713934898376
generator epoch 177 loss: 0.7632100319998605                 accuracy: 0.9321428537368774
generator epoch 178 loss: 0.7623477002825055                 accuracy: 0.9464285373687744
generator epoch 179 loss: 0.7680014722551618                 accuracy: 0.927142858505249
generator epoch 180 loss: 0.7625950317382812                 accuracy: 0.9471428394317627
generator epoch 181 loss: 0.7686390577043806                 accuracy: 0.927142858505249
generator epoch 182 loss: 0.7709043038504464                 accuracy: 0.9350000023841858
generator epoch 183 loss: 0.763966903250558                 accuracy: 0.941428542137146
generator epoch 184 loss: 0.762656822858538                 accuracy: 0.9314285516738892
generator epoch 185 loss: 0.7625556958879743                 accuracy: 0.949999988079071
generator epoch 186 loss: 0.7620437364850725                 accuracy: 0.9350000023841858
generator epoch 187 loss: 0.7632801400320871                 accuracy: 0.9449999928474426
generator epoch 188 loss: 0.7675010973249163                 accuracy: 0.9378571510314941
generator epoch 189 loss: 0.7662719120570591                 accuracy: 0.9421428442001343
generator epoch 190 loss: 0.7647274889264788                 accuracy: 0.9092857241630554
generator epoch 191 loss: 0.7607282444545201                 accuracy: 0.9521428346633911
generator epoch 192 loss: 0.7661028673444475                 accuracy: 0.9392856955528259
generator epoch 193 loss: 0.7637190194266184                 accuracy: 0.9457142949104309
generator epoch 194 loss: 0.7618642591203962                 accuracy: 0.9542856812477112
generator epoch 195 loss: 0.7633490766252791                 accuracy: 0.9435713887214661
generator epoch 196 loss: 0.7661877641950334                 accuracy: 0.9321428537368774
generator epoch 197 loss: 0.7674847154889788                 accuracy: 0.9428571462631226
generator epoch 198 loss: 0.7697715275355748                 accuracy: 0.941428542137146
generator epoch 199 loss: 0.7617358132498605                 accuracy: 0.9242857098579407
generator epoch 200 loss: 0.7656057774135044                 accuracy: 0.941428542137146
generator epoch 201 loss: 0.7653812888009207                 accuracy: 0.947857141494751
generator epoch 202 loss: 0.7612675323486328                 accuracy: 0.9471428394317627
generator epoch 203 loss: 0.7609848314557757                 accuracy: 0.9435713887214661
generator epoch 204 loss: 0.7676135057721819                 accuracy: 0.925000011920929
generator epoch 205 loss: 0.7629475904192243                 accuracy: 0.9542856812477112
generator epoch 206 loss: 0.7635209368024554                 accuracy: 0.9407142996788025
generator epoch 207 loss: 0.7614555101667132                 accuracy: 0.9492856860160828
generator epoch 208 loss: 0.7577550484793527                 accuracy: 0.9407142996788025
generator epoch 209 loss: 0.759798934500558                 accuracy: 0.9364285469055176
generator epoch 210 loss: 0.7637437822614397                 accuracy: 0.9485714435577393
generator epoch 211 loss: 0.7591504337855748                 accuracy: 0.9307142496109009
generator epoch 212 loss: 0.7621841513497489                 accuracy: 0.9385713934898376
generator epoch 213 loss: 0.7617440272739955                 accuracy: 0.9435713887214661
generator epoch 214 loss: 0.7593560089111329                 accuracy: 0.9300000071525574
generator epoch 215 loss: 0.7580117497035436                 accuracy: 0.9442856907844543
generator epoch 216 loss: 0.7585488228934152                 accuracy: 0.9492856860160828
generator epoch 217 loss: 0.8067387799944197                 accuracy: 0.9321428537368774
generator epoch 218 loss: 0.7830340894426618                 accuracy: 0.9457142949104309
generator epoch 219 loss: 0.7680450901576451                 accuracy: 0.9399999976158142
generator epoch 220 loss: 0.7635734845842634                 accuracy: 0.927142858505249
generator epoch 221 loss: 0.7608525839669363                 accuracy: 0.9392856955528259
generator epoch 222 loss: 0.7574533434186663                 accuracy: 0.9378571510314941
generator epoch 223 loss: 0.7652549586704799                 accuracy: 0.9342857003211975
generator epoch 224 loss: 0.7595353838239397                 accuracy: 0.9457142949104309
generator epoch 225 loss: 0.7620410029820034                 accuracy: 0.9300000071525574
generator epoch 226 loss: 0.7606318193708147                 accuracy: 0.9364285469055176
generator epoch 227 loss: 0.7641236986432757                 accuracy: 0.9399999976158142
generator epoch 228 loss: 0.764455282156808                 accuracy: 0.9235714077949524
generator epoch 229 loss: 0.7648954772949219                 accuracy: 0.9421428442001343
generator epoch 230 loss: 0.7585059862409319                 accuracy: 0.941428542137146
generator epoch 231 loss: 0.7653405068533761                 accuracy: 0.9364285469055176
generator epoch 232 loss: 0.7770498613630022                 accuracy: 0.9507142901420593
generator epoch 233 loss: 0.7665468235560826                 accuracy: 0.9428571462631226
generator epoch 234 loss: 0.764964539882115                 accuracy: 0.9449999928474426
generator epoch 235 loss: 0.7590680877685547                 accuracy: 0.9514285326004028
generator epoch 236 loss: 0.7608247985839843                 accuracy: 0.9542856812477112
generator epoch 237 loss: 0.7635829916817801                 accuracy: 0.9464285373687744
generator epoch 238 loss: 0.7617088971819197                 accuracy: 0.9364285469055176
generator epoch 239 loss: 0.7562329921177455                 accuracy: 0.9442856907844543
generator epoch 240 loss: 0.7539167105538505                 accuracy: 0.9435713887214661
generator epoch 241 loss: 0.7592432913643973                 accuracy: 0.9507142901420593
generator epoch 242 loss: 0.760262444632394                 accuracy: 0.9385713934898376
generator epoch 243 loss: 0.7569608668736049                 accuracy: 0.9407142996788025
generator epoch 244 loss: 0.7577112139020648                 accuracy: 0.9285714030265808
generator epoch 245 loss: 0.7567009504045759                 accuracy: 0.9471428394317627
generator epoch 246 loss: 0.754097906930106                 accuracy: 0.9328571557998657
generator epoch 247 loss: 0.7612669076102121                 accuracy: 0.9528571367263794
generator epoch 248 loss: 0.7577684923444475                 accuracy: 0.9435713887214661
generator epoch 249 loss: 0.7547424704415457                 accuracy: 0.9442856907844543
generator epoch 250 loss: 0.7581395839146206                 accuracy: 0.9528571367263794
generator epoch 251 loss: 0.7538041830880301                 accuracy: 0.9328571557998657
generator epoch 252 loss: 0.7578959520612444                 accuracy: 0.9321428537368774
generator epoch 253 loss: 0.7526237731933594                 accuracy: 0.9357143044471741
generator epoch 254 loss: 0.7595943324497768                 accuracy: 0.947857141494751
generator epoch 255 loss: 0.7574630279541016                 accuracy: 0.9435713887214661
generator epoch 256 loss: 0.7649398250034877                 accuracy: 0.9492856860160828
generator epoch 257 loss: 0.7538539437430245                 accuracy: 0.9535714387893677
generator epoch 258 loss: 0.7543560939243862                 accuracy: 0.9521428346633911
generator epoch 259 loss: 0.7549899793352399                 accuracy: 0.9435713887214661
generator epoch 260 loss: 0.7552277775355748                 accuracy: 0.9421428442001343
generator epoch 261 loss: 0.7548942487444197                 accuracy: 0.9407142996788025
generator epoch 262 loss: 0.753877348109654                 accuracy: 0.9435713887214661
generator epoch 263 loss: 0.7582164066859653                 accuracy: 0.9578571319580078
generator epoch 264 loss: 0.7522212990897043                 accuracy: 0.9264285564422607
generator epoch 265 loss: 0.760773666381836                 accuracy: 0.9435713887214661
generator epoch 266 loss: 0.7579197017124721                 accuracy: 0.9214285612106323
generator epoch 267 loss: 0.7612245021275111                 accuracy: 0.9371428489685059
generator epoch 268 loss: 0.7542363228934151                 accuracy: 0.9471428394317627
generator epoch 269 loss: 0.7521928030831473                 accuracy: 0.9485714435577393
generator epoch 270 loss: 0.7524067635672433                 accuracy: 0.9442856907844543
generator epoch 271 loss: 0.7579886313302177                 accuracy: 0.9378571510314941
generator epoch 272 loss: 0.7562698303222656                 accuracy: 0.9171428680419922
generator epoch 273 loss: 0.7517330666678292                 accuracy: 0.9364285469055176
generator epoch 274 loss: 0.7528846173967634                 accuracy: 0.9464285373687744
generator epoch 275 loss: 0.7580007533482143                 accuracy: 0.956428587436676
generator epoch 276 loss: 0.7584716975620814                 accuracy: 0.9314285516738892
generator epoch 277 loss: 0.7619856135777064                 accuracy: 0.9321428537368774
generator epoch 278 loss: 0.7550083905901228                 accuracy: 0.9421428442001343
generator epoch 279 loss: 0.7582225978306362                 accuracy: 0.9285714030265808
generator epoch 280 loss: 0.7516746529715401                 accuracy: 0.9442856907844543
generator epoch 281 loss: 0.7518503256661552                 accuracy: 0.9371428489685059
generator epoch 282 loss: 0.7518466727120535                 accuracy: 0.9328571557998657
generator epoch 283 loss: 0.7544217206682478                 accuracy: 0.9442856907844543
generator epoch 284 loss: 0.7537704245431083                 accuracy: 0.941428542137146
generator epoch 285 loss: 0.7485204807826451                 accuracy: 0.9428571462631226
generator epoch 286 loss: 0.7546124223981585                 accuracy: 0.9357143044471741
generator epoch 287 loss: 0.7550982365199498                 accuracy: 0.9392856955528259
generator epoch 288 loss: 0.7558212489536831                 accuracy: 0.9542856812477112
generator epoch 289 loss: 0.7642556797572545                 accuracy: 0.941428542137146
generator epoch 290 loss: 0.760071395438058                 accuracy: 0.925000011920929
generator epoch 291 loss: 0.7632334978376116                 accuracy: 0.9464285373687744
generator epoch 292 loss: 0.7576740491594587                 accuracy: 0.9300000071525574
generator epoch 293 loss: 0.757374070085798                 accuracy: 0.9485714435577393
generator epoch 294 loss: 0.7570623657226563                 accuracy: 0.9442856907844543
generator epoch 295 loss: 0.7608505920410156                 accuracy: 0.9328571557998657
generator epoch 296 loss: 0.7549346836635045                 accuracy: 0.9392856955528259
generator epoch 297 loss: 0.7549115430559431                 accuracy: 0.9378571510314941
generator epoch 298 loss: 0.7577070683070591                 accuracy: 0.941428542137146
generator epoch 299 loss: 0.7534113529750279                 accuracy: 0.9285714030265808
generator epoch 300 loss: 0.7544482386997768                 accuracy: 0.9292857050895691
generator epoch 301 loss: 0.7529504765101841                 accuracy: 0.9507142901420593
generator epoch 302 loss: 0.7549004198346819                 accuracy: 0.9549999833106995
generator epoch 303 loss: 0.759383671787807                 accuracy: 0.9521428346633911
generator epoch 304 loss: 0.755690243094308                 accuracy: 0.9335713982582092
generator epoch 305 loss: 0.7518068965366909                 accuracy: 0.9385713934898376
generator epoch 306 loss: 0.7541725319998605                 accuracy: 0.9335713982582092
generator epoch 307 loss: 0.754744859967913                 accuracy: 0.9385713934898376
generator epoch 308 loss: 0.7534092760358538                 accuracy: 0.9314285516738892
generator epoch 309 loss: 0.7574604775565011                 accuracy: 0.941428542137146
generator epoch 310 loss: 0.7494201272147042                 accuracy: 0.9535714387893677
generator epoch 311 loss: 0.7576943477085658                 accuracy: 0.9557142853736877
generator epoch 312 loss: 0.7555583326067243                 accuracy: 0.9471428394317627
generator epoch 313 loss: 0.7514535143171038                 accuracy: 0.9449999928474426
generator epoch 314 loss: 0.7526484645298549                 accuracy: 0.9485714435577393
generator epoch 315 loss: 0.755121730695452                 accuracy: 0.9514285326004028
generator epoch 316 loss: 0.7570397094726562                 accuracy: 0.9385713934898376
generator epoch 317 loss: 0.7741147652762277                 accuracy: 0.9435713887214661
generator epoch 318 loss: 0.7603780831473215                 accuracy: 0.9385713934898376
generator epoch 319 loss: 0.7528688341413226                 accuracy: 0.9378571510314941
generator epoch 320 loss: 0.7525272565569197                 accuracy: 0.9521428346633911
generator epoch 321 loss: 0.7564115849086217                 accuracy: 0.9514285326004028
generator epoch 322 loss: 0.75582095816476                 accuracy: 0.9492856860160828
generator epoch 323 loss: 0.755578133719308                 accuracy: 0.9521428346633911
generator epoch 324 loss: 0.7512334895542689                 accuracy: 0.949999988079071
generator epoch 325 loss: 0.7517275569370815                 accuracy: 0.9557142853736877
generator epoch 326 loss: 0.7516682730538504                 accuracy: 0.9428571462631226
generator epoch 327 loss: 0.7465604365757533                 accuracy: 0.9492856860160828
generator epoch 328 loss: 0.7515687290736607                 accuracy: 0.9385713934898376
generator epoch 329 loss: 0.7491309343610492                 accuracy: 0.956428587436676
generator epoch 330 loss: 0.750359701538086                 accuracy: 0.9528571367263794
generator epoch 331 loss: 0.7531832026890346                 accuracy: 0.9428571462631226
generator epoch 332 loss: 0.7558392220633371                 accuracy: 0.9435713887214661
generator epoch 333 loss: 0.7503507071358817                 accuracy: 0.9571428298950195
generator epoch 334 loss: 0.7490203831263951                 accuracy: 0.9485714435577393
generator epoch 335 loss: 0.7644451014927456                 accuracy: 0.9407142996788025
generator epoch 336 loss: 0.7519940412248884                 accuracy: 0.9542856812477112
generator epoch 337 loss: 0.7558899091448102                 accuracy: 0.9464285373687744
generator epoch 338 loss: 0.7525891998291016                 accuracy: 0.9407142996788025
generator epoch 339 loss: 0.7525042140415736                 accuracy: 0.9314285516738892
generator epoch 340 loss: 0.7509622933523995                 accuracy: 0.9314285516738892
generator epoch 341 loss: 0.7525799115862165                 accuracy: 0.9492856860160828
generator epoch 342 loss: 0.7555013554164342                 accuracy: 0.9342857003211975
generator epoch 343 loss: 0.749514204624721                 accuracy: 0.9378571510314941
generator epoch 344 loss: 0.7526100847516741                 accuracy: 0.941428542137146
generator epoch 345 loss: 0.7498446319580078                 accuracy: 0.9335713982582092
generator epoch 346 loss: 0.7522926967075892                 accuracy: 0.9364285469055176
generator epoch 347 loss: 0.7488670928955078                 accuracy: 0.9485714435577393
generator epoch 348 loss: 0.7516260088239397                 accuracy: 0.9292857050895691
generator epoch 349 loss: 0.7532104038783483                 accuracy: 0.9614285826683044
generator epoch 350 loss: 0.7497538918631418                 accuracy: 0.9350000023841858
generator epoch 351 loss: 0.7600840196881975                 accuracy: 0.9335713982582092
generator epoch 352 loss: 0.7583963413783482                 accuracy: 0.9449999928474426
generator epoch 353 loss: 0.7545635371616909                 accuracy: 0.9514285326004028
generator epoch 354 loss: 0.7494604069301061                 accuracy: 0.9457142949104309
generator epoch 355 loss: 0.7530790204729353                 accuracy: 0.947857141494751
generator epoch 356 loss: 0.748820445905413                 accuracy: 0.9507142901420593
generator epoch 357 loss: 0.7526958090645927                 accuracy: 0.9442856907844543
generator epoch 358 loss: 0.7463532352992467                 accuracy: 0.9492856860160828
generator epoch 359 loss: 0.7474764378138951                 accuracy: 0.9471428394317627
generator epoch 360 loss: 0.7455796373639788                 accuracy: 0.9585714340209961
generator epoch 361 loss: 0.753995856148856                 accuracy: 0.947857141494751
generator epoch 362 loss: 0.7472278860909598                 accuracy: 0.9471428394317627
generator epoch 363 loss: 0.7455621760777065                 accuracy: 0.9364285469055176
generator epoch 364 loss: 0.7512082811628069                 accuracy: 0.9457142949104309
generator epoch 365 loss: 0.7518377358572824                 accuracy: 0.949999988079071
generator epoch 366 loss: 0.748722239467076                 accuracy: 0.9371428489685059
generator epoch 367 loss: 0.7489532527378627                 accuracy: 0.9428571462631226
generator epoch 368 loss: 0.7520840039934431                 accuracy: 0.9514285326004028
generator epoch 369 loss: 0.7475954916817802                 accuracy: 0.9449999928474426
generator epoch 370 loss: 0.7534750536237445                 accuracy: 0.9471428394317627
generator epoch 371 loss: 0.7500543439592634                 accuracy: 0.941428542137146
generator epoch 372 loss: 0.7567728777204241                 accuracy: 0.9471428394317627
generator epoch 373 loss: 0.7530835728236607                 accuracy: 0.9371428489685059
generator epoch 374 loss: 0.752522567313058                 accuracy: 0.9449999928474426
generator epoch 375 loss: 0.7515002855573382                 accuracy: 0.9342857003211975
generator epoch 376 loss: 0.7430270163399832                 accuracy: 0.9371428489685059
generator epoch 377 loss: 0.749533043561663                 accuracy: 0.9399999976158142
generator epoch 378 loss: 0.7485418138776506                 accuracy: 0.9449999928474426
generator epoch 379 loss: 0.748157876586914                 accuracy: 0.947857141494751
generator epoch 380 loss: 0.7522266767229353                 accuracy: 0.9514285326004028
generator epoch 381 loss: 0.7510371852329799                 accuracy: 0.9442856907844543
generator epoch 382 loss: 0.748579971749442                 accuracy: 0.9507142901420593
generator epoch 383 loss: 0.7491008915492466                 accuracy: 0.9385713934898376
generator epoch 384 loss: 0.7472297419956753                 accuracy: 0.9549999833106995
generator epoch 385 loss: 0.7495596064976283                 accuracy: 0.9485714435577393
generator epoch 386 loss: 0.7512924608503069                 accuracy: 0.9535714387893677
generator epoch 387 loss: 0.7508948944091797                 accuracy: 0.9557142853736877
generator epoch 388 loss: 0.7505274592808314                 accuracy: 0.941428542137146
generator epoch 389 loss: 0.7482217407226562                 accuracy: 0.9442856907844543
generator epoch 390 loss: 0.7524488599504743                 accuracy: 0.9378571510314941
generator epoch 391 loss: 0.7510955501011439                 accuracy: 0.9449999928474426
generator epoch 392 loss: 0.7435335540771484                 accuracy: 0.9421428442001343
generator epoch 393 loss: 0.7504761221749442                 accuracy: 0.9435713887214661
generator epoch 394 loss: 0.745860837663923                 accuracy: 0.9314285516738892
generator epoch 395 loss: 0.7509157618931361                 accuracy: 0.9371428489685059
generator epoch 396 loss: 0.745066832624163                 accuracy: 0.9464285373687744
generator epoch 397 loss: 0.750284812273298                 accuracy: 0.9407142996788025
generator epoch 398 loss: 0.7461893981933594                 accuracy: 0.9307142496109009
generator epoch 399 loss: 0.7471294163295201                 accuracy: 0.949999988079071
generator epoch 400 loss: 0.7403516039167132                 accuracy: 0.9449999928474426
generator epoch 401 loss: 0.7461664154052734                 accuracy: 0.9292857050895691
generator epoch 402 loss: 0.7488473175048828                 accuracy: 0.9421428442001343
generator epoch 403 loss: 0.7464029706682478                 accuracy: 0.9507142901420593
generator epoch 404 loss: 0.7432495679582868                 accuracy: 0.9628571271896362
generator epoch 405 loss: 0.7445745409284319                 accuracy: 0.9642857313156128
generator epoch 406 loss: 0.7453708980015346                 accuracy: 0.9421428442001343
generator epoch 407 loss: 0.7463687870570591                 accuracy: 0.9599999785423279
generator epoch 408 loss: 0.7498597359793526                 accuracy: 0.9528571367263794
generator epoch 409 loss: 0.7449756430489677                 accuracy: 0.949999988079071
generator epoch 410 loss: 0.7456578451974052                 accuracy: 0.9449999928474426
generator epoch 411 loss: 0.7512056671142578                 accuracy: 0.9464285373687744
generator epoch 412 loss: 0.7563009870256696                 accuracy: 0.947857141494751
generator epoch 413 loss: 0.7489508797781808                 accuracy: 0.9449999928474426
generator epoch 414 loss: 0.748450443812779                 accuracy: 0.9535714387893677
generator epoch 415 loss: 0.7477569144112723                 accuracy: 0.9285714030265808
generator epoch 416 loss: 0.7483764208112444                 accuracy: 0.9614285826683044
generator epoch 417 loss: 0.7456419263567243                 accuracy: 0.9292857050895691
generator epoch 418 loss: 0.7480824606759208                 accuracy: 0.947857141494751
generator epoch 419 loss: 0.7477146680559431                 accuracy: 0.9307142496109009
generator epoch 420 loss: 0.7469344029017857                 accuracy: 0.9614285826683044
generator epoch 421 loss: 0.7499056283133371                 accuracy: 0.9449999928474426
generator epoch 422 loss: 0.7484067831856864                 accuracy: 0.9457142949104309
generator epoch 423 loss: 0.7445630410330636                 accuracy: 0.9300000071525574
generator epoch 424 loss: 0.7433961186000279                 accuracy: 0.9421428442001343
generator epoch 425 loss: 0.7517223510742187                 accuracy: 0.9514285326004028
generator epoch 426 loss: 0.7440022866385324                 accuracy: 0.9464285373687744
generator epoch 427 loss: 0.7440877689906529                 accuracy: 0.9407142996788025
generator epoch 428 loss: 0.7478402858189174                 accuracy: 0.9485714435577393
generator epoch 429 loss: 0.7431086678641183                 accuracy: 0.9314285516738892
generator epoch 430 loss: 0.7495810555594308                 accuracy: 0.9342857003211975
generator epoch 431 loss: 0.7503914110456195                 accuracy: 0.9435713887214661
generator epoch 432 loss: 0.7471340266636439                 accuracy: 0.9557142853736877
generator epoch 433 loss: 0.7454873238699776                 accuracy: 0.9428571462631226
generator epoch 434 loss: 0.7457980281284877                 accuracy: 0.9485714435577393
generator epoch 435 loss: 0.7455178475516183                 accuracy: 0.9335713982582092
generator epoch 436 loss: 0.7457966356549944                 accuracy: 0.927142858505249
generator epoch 437 loss: 0.7460396859305245                 accuracy: 0.9428571462631226
generator epoch 438 loss: 0.7466136614118304                 accuracy: 0.9364285469055176
generator epoch 439 loss: 0.7444181117466517                 accuracy: 0.9514285326004028
generator epoch 440 loss: 0.7443126094273158                 accuracy: 0.9350000023841858
generator epoch 441 loss: 0.7509072636195592                 accuracy: 0.9407142996788025
generator epoch 442 loss: 0.7579544124058315                 accuracy: 0.9614285826683044
generator epoch 443 loss: 0.7466680528913225                 accuracy: 0.9464285373687744
generator epoch 444 loss: 0.751806795828683                 accuracy: 0.949999988079071
generator epoch 445 loss: 0.7478292384556362                 accuracy: 0.9535714387893677
generator epoch 446 loss: 0.7438850154331752                 accuracy: 0.9535714387893677
generator epoch 447 loss: 0.745120002092634                 accuracy: 0.9264285564422607
generator epoch 448 loss: 0.7463795453752791                 accuracy: 0.9392856955528259
generator epoch 449 loss: 0.7491928423200335                 accuracy: 0.9421428442001343
generator epoch 450 loss: 0.7478887808663505                 accuracy: 0.9542856812477112
generator epoch 451 loss: 0.743440230015346                 accuracy: 0.9471428394317627
generator epoch 452 loss: 0.7439064640590123                 accuracy: 0.9471428394317627
generator epoch 453 loss: 0.744768008858817                 accuracy: 0.9485714435577393
generator epoch 454 loss: 0.7655877053397042                 accuracy: 0.9507142901420593
generator epoch 455 loss: 0.7467257747105189                 accuracy: 0.9507142901420593
generator epoch 456 loss: 0.7489706739153181                 accuracy: 0.9449999928474426
generator epoch 457 loss: 0.7526815739222935                 accuracy: 0.9557142853736877
generator epoch 458 loss: 0.7523683728899274                 accuracy: 0.9378571510314941
generator epoch 459 loss: 0.74420211050851                 accuracy: 0.9407142996788025
generator epoch 460 loss: 0.742616459437779                 accuracy: 0.9421428442001343
generator epoch 461 loss: 0.7467825217110771                 accuracy: 0.9442856907844543
generator epoch 462 loss: 0.7458714503696987                 accuracy: 0.9457142949104309
generator epoch 463 loss: 0.7481283421107701                 accuracy: 0.9350000023841858
generator epoch 464 loss: 0.7511154445103236                 accuracy: 0.9385713934898376
generator epoch 465 loss: 0.7421810620989119                 accuracy: 0.9671428203582764
generator epoch 466 loss: 0.7463172899518694                 accuracy: 0.9464285373687744
generator epoch 467 loss: 0.7435830980573381                 accuracy: 0.9485714435577393
generator epoch 468 loss: 0.7447473754882813                 accuracy: 0.9492856860160828
generator epoch 469 loss: 0.7484304500034877                 accuracy: 0.9421428442001343
generator epoch 470 loss: 0.7510143062046596                 accuracy: 0.9457142949104309
generator epoch 471 loss: 0.7498536363874163                 accuracy: 0.9507142901420593
generator epoch 472 loss: 0.7581647107805525                 accuracy: 0.927142858505249
generator epoch 473 loss: 0.7638391932896206                 accuracy: 0.9392856955528259
generator epoch 474 loss: 0.7490441650390625                 accuracy: 0.947857141494751
generator epoch 475 loss: 0.7428183894566127                 accuracy: 0.9535714387893677
generator epoch 476 loss: 0.7421566637311663                 accuracy: 0.9350000023841858
generator epoch 477 loss: 0.7464838139125279                 accuracy: 0.9485714435577393
generator epoch 478 loss: 0.7445394365583148                 accuracy: 0.9464285373687744
generator epoch 479 loss: 0.743396637398856                 accuracy: 0.949999988079071
generator epoch 480 loss: 0.7406043212890625                 accuracy: 0.9300000071525574
generator epoch 481 loss: 0.7453285095214843                 accuracy: 0.941428542137146
generator epoch 482 loss: 0.7398758514404297                 accuracy: 0.9507142901420593
generator epoch 483 loss: 0.7416445094517299                 accuracy: 0.9457142949104309
generator epoch 484 loss: 0.7409082916259766                 accuracy: 0.9364285469055176
generator epoch 485 loss: 0.7393689688546317                 accuracy: 0.9542856812477112
generator epoch 486 loss: 0.7434449911934989                 accuracy: 0.9464285373687744
generator epoch 487 loss: 0.7457247227260044                 accuracy: 0.9407142996788025
generator epoch 488 loss: 0.7446911185128349                 accuracy: 0.9464285373687744
generator epoch 489 loss: 0.7474238294328962                 accuracy: 0.9549999833106995
generator epoch 490 loss: 0.7457806884765625                 accuracy: 0.9378571510314941
generator epoch 491 loss: 0.7464645098005023                 accuracy: 0.9350000023841858
generator epoch 492 loss: 0.7373309805733816                 accuracy: 0.9364285469055176
generator epoch 493 loss: 0.7476179007393973                 accuracy: 0.9507142901420593
generator epoch 494 loss: 0.7472779353550503                 accuracy: 0.9350000023841858
generator epoch 495 loss: 0.742224953351702                 accuracy: 0.9364285469055176
generator epoch 496 loss: 0.7504267316545759                 accuracy: 0.9457142949104309
generator epoch 497 loss: 0.74405011945452                 accuracy: 0.9392856955528259
generator epoch 498 loss: 0.7445324236188616                 accuracy: 0.9585714340209961
generator epoch 499 loss: 0.7408252005440848                 accuracy: 0.941428542137146
batch 0 train loss: [0.47622052]
batch 1 train loss: [0.48404098]
batch 2 train loss: [0.44976202]
batch 3 train loss: [0.40131313]
batch 4 train loss: [0.37878266]
batch 5 train loss: [0.44373244]
batch 6 train loss: [0.43704307]
batch 7 train loss: [0.4791247]
batch 8 train loss: [0.5375876]
batch 9 train loss: [0.4318804]
batch 10 train loss: [0.51062125]
batch 11 train loss: [0.4482283]
batch 12 train loss: [0.53829974]
batch 13 train loss: [0.44279853]
batch 14 train loss: [0.59965736]
batch 15 train loss: [0.54984367]
batch 16 train loss: [0.4895571]
batch 17 train loss: [0.5102214]
batch 18 train loss: [0.37897795]
batch 19 train loss: [0.5373952]
batch 20 train loss: [0.51335174]
batch 21 train loss: [0.4974115]
batch 22 train loss: [0.5017202]
batch 23 train loss: [0.5745309]
batch 24 train loss: [0.37170628]
batch 25 train loss: [0.40342984]
batch 26 train loss: [0.42211595]
batch 27 train loss: [0.43661848]
batch 28 train loss: [0.52776766]
batch 29 train loss: [0.43740863]
batch 30 train loss: [0.4611607]
batch 31 train loss: [0.49775782]
batch 32 train loss: [0.46789297]
batch 33 train loss: [0.5546968]
batch 34 train loss: [0.46849284]
batch 35 train loss: [0.58248705]
batch 36 train loss: [0.41979232]
batch 37 train loss: [0.5377508]
batch 38 train loss: [0.56300724]
batch 39 train loss: [0.48627108]
batch 40 train loss: [0.4487081]
batch 41 train loss: [0.6026657]
batch 42 train loss: [0.50751036]
batch 43 train loss: [0.39713672]
batch 44 train loss: [0.45452982]
batch 45 train loss: [0.40460986]
batch 46 train loss: [0.40582687]
batch 47 train loss: [0.49045193]
batch 48 train loss: [0.4715073]
batch 49 train loss: [0.37171215]
batch 50 train loss: [0.4033862]
batch 51 train loss: [0.3892836]
batch 52 train loss: [0.45704013]
batch 53 train loss: [0.41111267]
batch 54 train loss: [0.41296834]
batch 55 train loss: [0.41141292]
batch 56 train loss: [0.3015606]
batch 57 train loss: [0.54186654]
batch 58 train loss: [0.41508391]
batch 59 train loss: [0.36274645]
batch 60 train loss: [0.44926798]
batch 61 train loss: [0.49015602]
batch 62 train loss: [0.37989727]
batch 63 train loss: [0.4481992]
batch 64 train loss: [0.48538712]
batch 65 train loss: [0.47135997]
batch 66 train loss: [0.38727066]
batch 67 train loss: [0.40223727]
batch 68 train loss: [0.4843019]
batch 69 train loss: [0.4605134]
batch 70 train loss: [0.49070352]
batch 71 train loss: [0.43006384]
batch 72 train loss: [0.39162654]
batch 73 train loss: [0.39877227]
batch 74 train loss: [0.43079442]
batch 75 train loss: [0.41126612]
batch 76 train loss: [0.561385]
batch 77 train loss: [0.35833722]
batch 78 train loss: [0.55671066]
batch 79 train loss: [0.46654853]
batch 80 train loss: [0.4510873]
batch 81 train loss: [0.3545415]
batch 82 train loss: [0.39961973]
batch 83 train loss: [0.38084105]
batch 84 train loss: [0.39121917]
batch 85 train loss: [0.51391965]
batch 86 train loss: [0.37230745]
batch 87 train loss: [0.45156437]
batch 88 train loss: [0.3958303]
batch 89 train loss: [0.517034]
batch 90 train loss: [0.53712887]
batch 91 train loss: [0.43536785]
batch 92 train loss: [0.45556763]
batch 93 train loss: [0.4605897]
batch 94 train loss: [0.50492334]
batch 95 train loss: [0.41055173]
batch 96 train loss: [0.45976081]
batch 97 train loss: [0.4458113]
batch 98 train loss: [0.47410765]
batch 99 train loss: [0.5207913]
epoch 0 mean train loss: [0.45798948]
Epoch 0/400=>  train_loss: [0.45798948], iou: nan, cd: 3.0695891491595595, test_mse: [0.44996256]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.49906522]
batch 1 train loss: [0.41976613]
batch 2 train loss: [0.39351025]
batch 3 train loss: [0.33728114]
batch 4 train loss: [0.41092235]
batch 5 train loss: [0.45588762]
batch 6 train loss: [0.3989274]
batch 7 train loss: [0.38202742]
batch 8 train loss: [0.36542228]
batch 9 train loss: [0.3269171]
batch 10 train loss: [0.37018195]
batch 11 train loss: [0.38277453]
batch 12 train loss: [0.33766744]
batch 13 train loss: [0.43087935]
batch 14 train loss: [0.40845793]
batch 15 train loss: [0.46416095]
batch 16 train loss: [0.24568953]
batch 17 train loss: [0.33605853]
batch 18 train loss: [0.3720877]
batch 19 train loss: [0.37589866]
batch 20 train loss: [0.35261217]
batch 21 train loss: [0.42774191]
batch 22 train loss: [0.35860518]
batch 23 train loss: [0.359073]
batch 24 train loss: [0.3953101]
batch 25 train loss: [0.3944091]
batch 26 train loss: [0.32852662]
batch 27 train loss: [0.35548085]
batch 28 train loss: [0.3836226]
batch 29 train loss: [0.40833518]
batch 30 train loss: [0.4619483]
batch 31 train loss: [0.42372376]
batch 32 train loss: [0.3490691]
batch 33 train loss: [0.3874462]
batch 34 train loss: [0.32961008]
batch 35 train loss: [0.30498448]
batch 36 train loss: [0.41251037]
batch 37 train loss: [0.35337594]
batch 38 train loss: [0.4240394]
batch 39 train loss: [0.30645576]
batch 40 train loss: [0.3885561]
batch 41 train loss: [0.4508307]
batch 42 train loss: [0.37899044]
batch 43 train loss: [0.30681837]
batch 44 train loss: [0.40435848]
batch 45 train loss: [0.36375138]
batch 46 train loss: [0.34409627]
batch 47 train loss: [0.35950604]
batch 48 train loss: [0.42507136]
batch 49 train loss: [0.37336698]
batch 50 train loss: [0.4108273]
batch 51 train loss: [0.34939954]
batch 52 train loss: [0.42237344]
batch 53 train loss: [0.35302716]
batch 54 train loss: [0.38976136]
batch 55 train loss: [0.3838928]
batch 56 train loss: [0.46082062]
batch 57 train loss: [0.37096202]
batch 58 train loss: [0.41490796]
batch 59 train loss: [0.34857875]
batch 60 train loss: [0.34373614]
batch 61 train loss: [0.4620784]
batch 62 train loss: [0.43993905]
batch 63 train loss: [0.43170184]
batch 64 train loss: [0.26919055]
batch 65 train loss: [0.41597822]
batch 66 train loss: [0.422583]
batch 67 train loss: [0.4426674]
batch 68 train loss: [0.34640786]
batch 69 train loss: [0.39646813]
batch 70 train loss: [0.3720124]
batch 71 train loss: [0.362446]
batch 72 train loss: [0.29729858]
batch 73 train loss: [0.31198168]
batch 74 train loss: [0.34556255]
batch 75 train loss: [0.33740702]
batch 76 train loss: [0.3641921]
batch 77 train loss: [0.47203612]
batch 78 train loss: [0.32770452]
batch 79 train loss: [0.47186542]
batch 80 train loss: [0.4106371]
batch 81 train loss: [0.44328097]
batch 82 train loss: [0.400722]
batch 83 train loss: [0.39926583]
batch 84 train loss: [0.35282508]
batch 85 train loss: [0.3035044]
batch 86 train loss: [0.4140794]
batch 87 train loss: [0.3420395]
batch 88 train loss: [0.47449517]
batch 89 train loss: [0.42812008]
batch 90 train loss: [0.40702137]
batch 91 train loss: [0.42882589]
batch 92 train loss: [0.43103766]
batch 93 train loss: [0.31680363]
batch 94 train loss: [0.39746794]
batch 95 train loss: [0.41519222]
batch 96 train loss: [0.43328065]
batch 97 train loss: [0.40625182]
batch 98 train loss: [0.30117366]
batch 99 train loss: [0.37125903]
epoch 1 mean train loss: [0.3844089]
Epoch 1/400=>  train_loss: [0.3844089], iou: nan, cd: 2.9300074983672078, test_mse: [0.40475416]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.3698128]
batch 1 train loss: [0.36241776]
batch 2 train loss: [0.33109108]
batch 3 train loss: [0.3417364]
batch 4 train loss: [0.3578998]
batch 5 train loss: [0.28208196]
batch 6 train loss: [0.30478773]
batch 7 train loss: [0.37202868]
batch 8 train loss: [0.29561153]
batch 9 train loss: [0.29662582]
batch 10 train loss: [0.34095675]
batch 11 train loss: [0.3585327]
batch 12 train loss: [0.30211186]
batch 13 train loss: [0.35152942]
batch 14 train loss: [0.33133477]
batch 15 train loss: [0.39547026]
batch 16 train loss: [0.3913729]
batch 17 train loss: [0.48572993]
batch 18 train loss: [0.29760447]
batch 19 train loss: [0.37429294]
batch 20 train loss: [0.34261355]
batch 21 train loss: [0.3455852]
batch 22 train loss: [0.34713513]
batch 23 train loss: [0.34661528]
batch 24 train loss: [0.34822932]
batch 25 train loss: [0.40634516]
batch 26 train loss: [0.320281]
batch 27 train loss: [0.32418355]
batch 28 train loss: [0.35366333]
batch 29 train loss: [0.39378402]
batch 30 train loss: [0.29623246]
batch 31 train loss: [0.36098164]
batch 32 train loss: [0.32276928]
batch 33 train loss: [0.38193715]
batch 34 train loss: [0.32490554]
batch 35 train loss: [0.35509694]
batch 36 train loss: [0.34989607]
batch 37 train loss: [0.35290176]
batch 38 train loss: [0.29079956]
batch 39 train loss: [0.37728578]
batch 40 train loss: [0.2831919]
batch 41 train loss: [0.37733918]
batch 42 train loss: [0.28311247]
batch 43 train loss: [0.33488]
batch 44 train loss: [0.32906064]
batch 45 train loss: [0.29014945]
batch 46 train loss: [0.29311037]
batch 47 train loss: [0.3213551]
batch 48 train loss: [0.3676607]
batch 49 train loss: [0.37815908]
batch 50 train loss: [0.2906152]
batch 51 train loss: [0.33132765]
batch 52 train loss: [0.4001313]
batch 53 train loss: [0.36709973]
batch 54 train loss: [0.34014243]
batch 55 train loss: [0.3045992]
batch 56 train loss: [0.30712476]
batch 57 train loss: [0.3002862]
batch 58 train loss: [0.30530226]
batch 59 train loss: [0.31066805]
batch 60 train loss: [0.34944993]
batch 61 train loss: [0.3950328]
batch 62 train loss: [0.39011392]
batch 63 train loss: [0.32099634]
batch 64 train loss: [0.33885238]
batch 65 train loss: [0.3368526]
batch 66 train loss: [0.3659467]
batch 67 train loss: [0.29049715]
batch 68 train loss: [0.35268793]
batch 69 train loss: [0.35288256]
batch 70 train loss: [0.4151736]
batch 71 train loss: [0.36804894]
batch 72 train loss: [0.33243337]
batch 73 train loss: [0.30743194]
batch 74 train loss: [0.40104967]
batch 75 train loss: [0.28405273]
batch 76 train loss: [0.37400573]
batch 77 train loss: [0.3739755]
batch 78 train loss: [0.3249684]
batch 79 train loss: [0.37249687]
batch 80 train loss: [0.38280722]
batch 81 train loss: [0.39676225]
batch 82 train loss: [0.35954854]
batch 83 train loss: [0.3280324]
batch 84 train loss: [0.30450577]
batch 85 train loss: [0.39458343]
batch 86 train loss: [0.3250044]
batch 87 train loss: [0.31857917]
batch 88 train loss: [0.4191672]
batch 89 train loss: [0.32287943]
batch 90 train loss: [0.39198345]
batch 91 train loss: [0.2712405]
batch 92 train loss: [0.38676345]
batch 93 train loss: [0.30661932]
batch 94 train loss: [0.32616776]
batch 95 train loss: [0.37863985]
batch 96 train loss: [0.3219773]
batch 97 train loss: [0.39215976]
batch 98 train loss: [0.3499388]
batch 99 train loss: [0.45507935]
epoch 2 mean train loss: [0.34578967]
Epoch 2/400=>  train_loss: [0.34578967], iou: nan, cd: 2.9154617546105834, test_mse: [0.3963215]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.3633571]
batch 1 train loss: [0.28010255]
batch 2 train loss: [0.31155217]
batch 3 train loss: [0.3720667]
batch 4 train loss: [0.3320353]
batch 5 train loss: [0.35566205]
batch 6 train loss: [0.25078282]
batch 7 train loss: [0.35071266]
batch 8 train loss: [0.23813292]
batch 9 train loss: [0.31273255]
batch 10 train loss: [0.28802788]
batch 11 train loss: [0.40053445]
batch 12 train loss: [0.28704795]
batch 13 train loss: [0.2543233]
batch 14 train loss: [0.289324]
batch 15 train loss: [0.39397568]
batch 16 train loss: [0.33707026]
batch 17 train loss: [0.29567572]
batch 18 train loss: [0.22170155]
batch 19 train loss: [0.35130364]
batch 20 train loss: [0.27808815]
batch 21 train loss: [0.29356676]
batch 22 train loss: [0.34473488]
batch 23 train loss: [0.2989663]
batch 24 train loss: [0.34605727]
batch 25 train loss: [0.34371626]
batch 26 train loss: [0.25932747]
batch 27 train loss: [0.39485887]
batch 28 train loss: [0.2809922]
batch 29 train loss: [0.26342696]
batch 30 train loss: [0.32917762]
batch 31 train loss: [0.32329318]
batch 32 train loss: [0.3547467]
batch 33 train loss: [0.36368454]
batch 34 train loss: [0.24698211]
batch 35 train loss: [0.2808522]
batch 36 train loss: [0.36886457]
batch 37 train loss: [0.31639084]
batch 38 train loss: [0.3476835]
batch 39 train loss: [0.32464597]
batch 40 train loss: [0.2597753]
batch 41 train loss: [0.25191724]
batch 42 train loss: [0.2834312]
batch 43 train loss: [0.30279338]
batch 44 train loss: [0.26238692]
batch 45 train loss: [0.3546232]
batch 46 train loss: [0.33252499]
batch 47 train loss: [0.30796155]
batch 48 train loss: [0.3392443]
batch 49 train loss: [0.38935247]
batch 50 train loss: [0.39056543]
batch 51 train loss: [0.3649628]
batch 52 train loss: [0.25012088]
batch 53 train loss: [0.27887127]
batch 54 train loss: [0.3120656]
batch 55 train loss: [0.35321084]
batch 56 train loss: [0.3298936]
batch 57 train loss: [0.35643828]
batch 58 train loss: [0.35059753]
batch 59 train loss: [0.42220968]
batch 60 train loss: [0.32673436]
batch 61 train loss: [0.29118627]
batch 62 train loss: [0.3164221]
batch 63 train loss: [0.3483178]
batch 64 train loss: [0.31169257]
batch 65 train loss: [0.35428125]
batch 66 train loss: [0.28812823]
batch 67 train loss: [0.27350193]
batch 68 train loss: [0.3853687]
batch 69 train loss: [0.34352598]
batch 70 train loss: [0.22314812]
batch 71 train loss: [0.33036217]
batch 72 train loss: [0.33671564]
batch 73 train loss: [0.3060401]
batch 74 train loss: [0.3013278]
batch 75 train loss: [0.30316216]
batch 76 train loss: [0.32939917]
batch 77 train loss: [0.33140096]
batch 78 train loss: [0.35192922]
batch 79 train loss: [0.27533835]
batch 80 train loss: [0.3425906]
batch 81 train loss: [0.30356205]
batch 82 train loss: [0.30479646]
batch 83 train loss: [0.3988889]
batch 84 train loss: [0.29769582]
batch 85 train loss: [0.34376115]
batch 86 train loss: [0.37103316]
batch 87 train loss: [0.3150174]
batch 88 train loss: [0.35294506]
batch 89 train loss: [0.34806892]
batch 90 train loss: [0.31043634]
batch 91 train loss: [0.27567646]
batch 92 train loss: [0.36412245]
batch 93 train loss: [0.36066806]
batch 94 train loss: [0.35261637]
batch 95 train loss: [0.28886214]
batch 96 train loss: [0.37145093]
batch 97 train loss: [0.35256892]
batch 98 train loss: [0.34385255]
batch 99 train loss: [0.3218443]
epoch 3 mean train loss: [0.3218757]
Epoch 3/400=>  train_loss: [0.3218757], iou: nan, cd: 2.7189210146714733, test_mse: [0.37446317]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.29625878]
batch 1 train loss: [0.25453216]
batch 2 train loss: [0.2540147]
batch 3 train loss: [0.2175636]
batch 4 train loss: [0.2999657]
batch 5 train loss: [0.2886486]
batch 6 train loss: [0.3105402]
batch 7 train loss: [0.28406736]
batch 8 train loss: [0.3003664]
batch 9 train loss: [0.2547488]
batch 10 train loss: [0.23017783]
batch 11 train loss: [0.28398448]
batch 12 train loss: [0.234556]
batch 13 train loss: [0.28626576]
batch 14 train loss: [0.27323478]
batch 15 train loss: [0.29574534]
batch 16 train loss: [0.30980116]
batch 17 train loss: [0.26838243]
batch 18 train loss: [0.28781834]
batch 19 train loss: [0.27363986]
batch 20 train loss: [0.33318615]
batch 21 train loss: [0.2284035]
batch 22 train loss: [0.33354172]
batch 23 train loss: [0.22715385]
batch 24 train loss: [0.28574297]
batch 25 train loss: [0.28773308]
batch 26 train loss: [0.2864629]
batch 27 train loss: [0.32854602]
batch 28 train loss: [0.25507993]
batch 29 train loss: [0.34184793]
batch 30 train loss: [0.38947433]
batch 31 train loss: [0.2755447]
batch 32 train loss: [0.32482833]
batch 33 train loss: [0.2984116]
batch 34 train loss: [0.33983347]
batch 35 train loss: [0.31989655]
batch 36 train loss: [0.28414923]
batch 37 train loss: [0.27392387]
batch 38 train loss: [0.21275063]
batch 39 train loss: [0.30183274]
batch 40 train loss: [0.27131134]
batch 41 train loss: [0.30669808]
batch 42 train loss: [0.37165797]
batch 43 train loss: [0.26743767]
batch 44 train loss: [0.34316805]
batch 45 train loss: [0.21507096]
batch 46 train loss: [0.3119799]
batch 47 train loss: [0.30576456]
batch 48 train loss: [0.2828165]
batch 49 train loss: [0.27454498]
batch 50 train loss: [0.30521914]
batch 51 train loss: [0.30290735]
batch 52 train loss: [0.31791267]
batch 53 train loss: [0.27267227]
batch 54 train loss: [0.26866752]
batch 55 train loss: [0.3313511]
batch 56 train loss: [0.33033648]
batch 57 train loss: [0.25791866]
batch 58 train loss: [0.2906152]
batch 59 train loss: [0.29478705]
batch 60 train loss: [0.3214588]
batch 61 train loss: [0.35246673]
batch 62 train loss: [0.2886699]
batch 63 train loss: [0.31305805]
batch 64 train loss: [0.25763008]
batch 65 train loss: [0.28465685]
batch 66 train loss: [0.38704953]
batch 67 train loss: [0.31015024]
batch 68 train loss: [0.33699733]
batch 69 train loss: [0.2961074]
batch 70 train loss: [0.30530262]
batch 71 train loss: [0.19944853]
batch 72 train loss: [0.25970897]
batch 73 train loss: [0.29670593]
batch 74 train loss: [0.28846368]
batch 75 train loss: [0.33676723]
batch 76 train loss: [0.2583601]
batch 77 train loss: [0.37657335]
batch 78 train loss: [0.3042635]
batch 79 train loss: [0.27266976]
batch 80 train loss: [0.27655384]
batch 81 train loss: [0.30103827]
batch 82 train loss: [0.24991937]
batch 83 train loss: [0.2926104]
batch 84 train loss: [0.37984955]
batch 85 train loss: [0.31539288]
batch 86 train loss: [0.3751455]
batch 87 train loss: [0.2199049]
batch 88 train loss: [0.37499318]
batch 89 train loss: [0.39683643]
batch 90 train loss: [0.33042738]
batch 91 train loss: [0.40214518]
batch 92 train loss: [0.3574744]
batch 93 train loss: [0.3691212]
batch 94 train loss: [0.3734787]
batch 95 train loss: [0.30907482]
batch 96 train loss: [0.31165478]
batch 97 train loss: [0.32395515]
batch 98 train loss: [0.27296853]
batch 99 train loss: [0.30422378]
epoch 4 mean train loss: [0.2993877]
Epoch 4/400=>  train_loss: [0.2993877], iou: nan, cd: 2.627752699274506, test_mse: [0.35644823]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.27237254]
batch 1 train loss: [0.24820389]
batch 2 train loss: [0.27504498]
batch 3 train loss: [0.30924058]
batch 4 train loss: [0.25835148]
batch 5 train loss: [0.27670532]
batch 6 train loss: [0.24598843]
batch 7 train loss: [0.25373945]
batch 8 train loss: [0.24404785]
batch 9 train loss: [0.35453218]
batch 10 train loss: [0.29290333]
batch 11 train loss: [0.27749172]
batch 12 train loss: [0.30376145]
batch 13 train loss: [0.3085947]
batch 14 train loss: [0.27090347]
batch 15 train loss: [0.26915753]
batch 16 train loss: [0.21991985]
batch 17 train loss: [0.2451404]
batch 18 train loss: [0.30355674]
batch 19 train loss: [0.2822723]
batch 20 train loss: [0.30038437]
batch 21 train loss: [0.25494885]
batch 22 train loss: [0.31435794]
batch 23 train loss: [0.22385044]
batch 24 train loss: [0.24430028]
batch 25 train loss: [0.2674105]
batch 26 train loss: [0.1883342]
batch 27 train loss: [0.36298984]
batch 28 train loss: [0.29889935]
batch 29 train loss: [0.25772244]
batch 30 train loss: [0.25957283]
batch 31 train loss: [0.3056173]
batch 32 train loss: [0.2776937]
batch 33 train loss: [0.38919422]
batch 34 train loss: [0.2523858]
batch 35 train loss: [0.28299332]
batch 36 train loss: [0.3010516]
batch 37 train loss: [0.29389706]
batch 38 train loss: [0.37694833]
batch 39 train loss: [0.22685064]
batch 40 train loss: [0.31866187]
batch 41 train loss: [0.21550965]
batch 42 train loss: [0.28046143]
batch 43 train loss: [0.24700508]
batch 44 train loss: [0.29780874]
batch 45 train loss: [0.30910268]
batch 46 train loss: [0.30193728]
batch 47 train loss: [0.33143392]
batch 48 train loss: [0.22656956]
batch 49 train loss: [0.22915196]
batch 50 train loss: [0.30415377]
batch 51 train loss: [0.23860075]
batch 52 train loss: [0.30757278]
batch 53 train loss: [0.27259964]
batch 54 train loss: [0.24688572]
batch 55 train loss: [0.27220517]
batch 56 train loss: [0.2620069]
batch 57 train loss: [0.353598]
batch 58 train loss: [0.23881167]
batch 59 train loss: [0.26541436]
batch 60 train loss: [0.27889967]
batch 61 train loss: [0.27653337]
batch 62 train loss: [0.32244563]
batch 63 train loss: [0.32557783]
batch 64 train loss: [0.36323112]
batch 65 train loss: [0.3448951]
batch 66 train loss: [0.23401947]
batch 67 train loss: [0.32979357]
batch 68 train loss: [0.3428976]
batch 69 train loss: [0.31721485]
batch 70 train loss: [0.39634144]
batch 71 train loss: [0.25487918]
batch 72 train loss: [0.26344392]
batch 73 train loss: [0.27021036]
batch 74 train loss: [0.29156968]
batch 75 train loss: [0.3073027]
batch 76 train loss: [0.2522266]
batch 77 train loss: [0.41147396]
batch 78 train loss: [0.30680954]
batch 79 train loss: [0.2586366]
batch 80 train loss: [0.33615384]
batch 81 train loss: [0.27549335]
batch 82 train loss: [0.2763285]
batch 83 train loss: [0.29576936]
batch 84 train loss: [0.2559504]
batch 85 train loss: [0.32862827]
batch 86 train loss: [0.285564]
batch 87 train loss: [0.2651179]
batch 88 train loss: [0.3081834]
batch 89 train loss: [0.22183833]
batch 90 train loss: [0.22488226]
batch 91 train loss: [0.33203483]
batch 92 train loss: [0.2433995]
batch 93 train loss: [0.2781265]
batch 94 train loss: [0.24134415]
batch 95 train loss: [0.2705251]
batch 96 train loss: [0.26625055]
batch 97 train loss: [0.22355147]
batch 98 train loss: [0.20664304]
batch 99 train loss: [0.34104505]
epoch 5 mean train loss: [0.28336048]
Epoch 5/400=>  train_loss: [0.28336048], iou: nan, cd: 2.6043935846779394, test_mse: [0.35801116]
CORRECT PROGRAMS: 9663
batch 0 train loss: [0.2686114]
batch 1 train loss: [0.26825768]
batch 2 train loss: [0.32008335]
batch 3 train loss: [0.2517818]
batch 4 train loss: [0.2509898]
batch 5 train loss: [0.2925622]
batch 6 train loss: [0.32601517]
batch 7 train loss: [0.23904377]
batch 8 train loss: [0.28149968]
batch 9 train loss: [0.2861956]
batch 10 train loss: [0.21470755]
batch 11 train loss: [0.28226107]
batch 12 train loss: [0.27742207]
batch 13 train loss: [0.3384083]
batch 14 train loss: [0.23428233]
batch 15 train loss: [0.24241892]
batch 16 train loss: [0.3098898]
batch 17 train loss: [0.1991729]
batch 18 train loss: [0.2686751]
batch 19 train loss: [0.2652185]
batch 20 train loss: [0.20196578]
batch 21 train loss: [0.32820547]
batch 22 train loss: [0.29220665]
batch 23 train loss: [0.29480672]
batch 24 train loss: [0.30148852]
batch 25 train loss: [0.28713742]
batch 26 train loss: [0.32806453]
batch 27 train loss: [0.2568551]
batch 28 train loss: [0.23861423]
batch 29 train loss: [0.23061985]
batch 30 train loss: [0.27505633]
batch 31 train loss: [0.29046592]
batch 32 train loss: [0.21777228]
batch 33 train loss: [0.25429007]
batch 34 train loss: [0.25916755]
batch 35 train loss: [0.2611877]
batch 36 train loss: [0.22364046]
batch 37 train loss: [0.24413018]
batch 38 train loss: [0.2746021]
batch 39 train loss: [0.32390493]
batch 40 train loss: [0.18748192]
batch 41 train loss: [0.30238906]
batch 42 train loss: [0.3042068]
batch 43 train loss: [0.27374673]
batch 44 train loss: [0.3433952]
batch 45 train loss: [0.19876938]
batch 46 train loss: [0.22646955]
batch 47 train loss: [0.26226443]
batch 48 train loss: [0.2866199]
batch 49 train loss: [0.26035795]
batch 50 train loss: [0.2120019]
batch 51 train loss: [0.2579589]
batch 52 train loss: [0.22971347]
batch 53 train loss: [0.24752943]
batch 54 train loss: [0.2693212]
batch 55 train loss: [0.20820194]
batch 56 train loss: [0.25623667]
batch 57 train loss: [0.2628644]
batch 58 train loss: [0.28082985]
batch 59 train loss: [0.29270566]
batch 60 train loss: [0.26693952]
batch 61 train loss: [0.23469415]
batch 62 train loss: [0.294271]
batch 63 train loss: [0.34027454]
batch 64 train loss: [0.2517329]
batch 65 train loss: [0.2460303]
batch 66 train loss: [0.28876415]
batch 67 train loss: [0.3075653]
batch 68 train loss: [0.31146154]
batch 69 train loss: [0.30967876]
batch 70 train loss: [0.27371076]
batch 71 train loss: [0.25141704]
batch 72 train loss: [0.33265364]
batch 73 train loss: [0.32288015]
batch 74 train loss: [0.29952246]
batch 75 train loss: [0.30449194]
batch 76 train loss: [0.260876]
batch 77 train loss: [0.22054097]
batch 78 train loss: [0.3534075]
batch 79 train loss: [0.27922356]
batch 80 train loss: [0.27738243]
batch 81 train loss: [0.29574314]
batch 82 train loss: [0.28736362]
batch 83 train loss: [0.22726814]
batch 84 train loss: [0.24443808]
batch 85 train loss: [0.22076645]
batch 86 train loss: [0.25691605]
batch 87 train loss: [0.34732094]
batch 88 train loss: [0.2717756]
batch 89 train loss: [0.26050958]
batch 90 train loss: [0.25628486]
batch 91 train loss: [0.24370678]
batch 92 train loss: [0.26737922]
batch 93 train loss: [0.24913725]
batch 94 train loss: [0.2643004]
batch 95 train loss: [0.23188949]
batch 96 train loss: [0.25640914]
batch 97 train loss: [0.2791447]
batch 98 train loss: [0.2104875]
batch 99 train loss: [0.2456348]
epoch 6 mean train loss: [0.26908737]
WAKE SLEEP ITERATION 8
Inferring cad batch: 0
Inferring cad batch: 1
Inferring cad batch: 2
Inferring cad batch: 3
Inferring cad batch: 4
Inferring cad batch: 5
Inferring cad batch: 6
Inferring cad batch: 7
Inferring cad batch: 8
Inferring cad batch: 9
Inferring cad batch: 10
Inferring cad batch: 11
Inferring cad batch: 12
Inferring cad batch: 13
Inferring cad batch: 14
